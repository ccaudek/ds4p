
<!DOCTYPE html>


<html lang="it" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Introduzione a Stan &#8212; ds4p</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css?v=ca93fcec" />
    <link rel="stylesheet" type="text/css" href="../_static/exercise.css?v=20b57f81" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=3ee479438cf8b5e0d341"></script>

    <script src="../_static/documentation_options.js?v=8d586cc4"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="../_static/translations.js?v=0173e136"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-TP2WLBPMS6"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-TP2WLBPMS6');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-TP2WLBPMS6');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter_4/15_stan_beta_binomial';</script>
    <link rel="canonical" href="https://ccaudek.github.io/ds4p/chapter_4/15_stan_beta_binomial.html" />
    <link rel="icon" href="../_static/increasing.png"/>
    <link rel="index" title="Indice" href="../genindex.html" />
    <link rel="search" title="Cerca" href="../search.html" />
    <link rel="next" title="✏️ Esercizio" href="E_stan_beta_binomial.html" />
    <link rel="prev" title="Monte Carlo a Catena di Markov" href="10_metropolis.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="it"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="ds4p - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="ds4p - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Cerca" aria-label="Cerca" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Cerca</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Benvenuti
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_1/introduction_chapter_1.html">Python</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/00_prelims.html">Preliminari</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/01_python_1.html">Python (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/02_python_2.html">Python (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_python.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/03_numpy.html">NumPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_numpy.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/04_pandas.html">Pandas (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/05_pandas_aggregate.html">Pandas (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/06_pandas_functions.html">Pandas (3)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_pandas.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/07_matplotlib.html">Matplotlib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/08_seaborn.html">Seaborn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_matplotlib.html">✏️ Esercizi</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_2/introduction_chapter_2.html">Statistica descrittiva</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/00_scientific_method.html">La scienza dei dati e il metodo scientifico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/01_key_notions.html">Concetti chiave</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_key_notions.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/02_measurement.html">La misurazione in psicologia</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_scales.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/03_freq_distr.html">Dati e frequenze</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_sums.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/04_loc_scale.html">Indici di posizione e di scala</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/05_correlation.html">Le relazioni tra variabili</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/06_causality.html">Lo studio delle cause dei fenomeni</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_eda.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_mehr_song_spelke.html">✏️ Esercizi</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_3/introduction_chapter_3.html">Probabilità</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/01_intro_prob.html">Introduzione al calcolo delle probabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/02_conditional_prob.html">Probabilità condizionata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_cond_prob_1.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_cond_prob_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_discrete_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/03_bayes_theorem.html">Il teorema di Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_bayes_theorem.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_bayes_theorem_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/04a_random_var.html">Introduzione alle variabili casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/04b_expval_var.html">Proprietà delle variabili casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_exp_val_variance.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/04c_sampling_distr.html">Stime, stimatori e parametri</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_rv_discrete.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/05_joint_prob.html">Probabilità congiunta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_joint_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_covariance.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/06_density_func.html">La funzione di densità di probabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/07_discr_rv_distr.html">Distribuzioni di v.c. discrete</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_binomial.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/08_cont_rv_distr.html">Distribuzioni di v.c. continue</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_gaussian.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_beta_distr.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/09_likelihood.html">La verosimiglianza</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_likelihood.html">✏️ Esercizi</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="introduction_part_4.html">Inferenza bayesiana</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_intro_bayes.html">Modellazione bayesiana</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_subj_prop.html">Pensare ad una proporzione in termini soggettivi</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_grid_gauss.html">Verosimiglianza Gaussiana: Metodo Basato su Griglia</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_conjugate_families_1.html">Distribuzioni coniugate</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_conjugate_families_1.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="04_conjugate_families_2.html">Distribuzioni coniugate (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_summary_posterior.html">Sintesi a posteriori</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_conjugate.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="06_balance-prior-post.html">L’influenza della distribuzione a priori</a></li>
<li class="toctree-l2"><a class="reference internal" href="10_metropolis.html">Monte Carlo a Catena di Markov</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Introduzione a Stan</a></li>

<li class="toctree-l2"><a class="reference internal" href="E_stan_beta_binomial.html">✏️ Esercizio</a></li>
<li class="toctree-l2"><a class="reference internal" href="16_stan_summary_posterior.html">Metodi di sintesi della distribuzione a posteriori</a></li>
<li class="toctree-l2"><a class="reference internal" href="17_stan_diagnostics.html">Diagnostica delle catene markoviane</a></li>
<li class="toctree-l2"><a class="reference internal" href="18_stan_prediction.html">La predizione bayesiana</a></li>

<li class="toctree-l2"><a class="reference internal" href="19_stan_odds_ratio.html">Analisi bayesiana dell’odds-ratio</a></li>
<li class="toctree-l2"><a class="reference internal" href="22_stan_normal_normal.html">Inferenza bayesiana su una media</a></li>
<li class="toctree-l2"><a class="reference internal" href="23_stan_two_groups.html">Confronto tra due gruppi</a></li>
<li class="toctree-l2"><a class="reference internal" href="24_stan_hier_beta_binom.html">Modello gerarchico beta-binomiale con Stan</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_5/introduction_part_5.html">Analisi della regressione</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_03_reglin_bayesian.html">Analisi bayesiana del modello di regressione lineare bivariato</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_1.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_04_synt_sugar.html">Zucchero sintattico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_05_two_means.html">Confronto tra le medie di due gruppi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_3.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_4.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_06_hier_regr.html">Il modello lineare gerarchico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_07_robust_regr.html">Regressione robusta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_08_specification_error.html">Errore di specificazione</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_09_causal_inference.html">Inferenza causale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_causal_inference.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_22_stan_logistic_regr.html">Regressione logistica con Stan</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_24_stan_mixed_models.html">Modelli misti con Stan</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_25_stan_rct.html">Incorporare dati storici di controllo in una RCT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_26_stan_mediation.html">Modello di mediazione con Stan</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_30_entropy.html">Entropia</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_31_kl.html">La divergenza di Kullback-Leibler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_kl.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_32_stan_loo.html">Validazione Incrociata Leave-One-Out</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_35_missing.html">Dati mancanti</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_40_rescorla_wagner.html">Apprendimento per rinforzo</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_6/introduction_part_6.html">Inferenza frequentista</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/01_intro_frequentist.html">Introduzione all’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_estimation.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/02_conf_interv.html">Intervallo di confidenza</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_conf_interv.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/03_test_ipotesi.html">Significatività statistica</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_t_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_interpretation_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_significato_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/04_two_ind_samples.html">Test t di Student per campioni indipendenti</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_test_media_pop.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_medie_pop_ampie.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_medie_pop_piccoli.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_campioni_appaiati.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_confronto_proporzioni.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/05_crisis.html">La crisi della generalizzabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/06_limiti_stat_frequentista.html">Limiti dell’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/07_effect_size.html">La grandezza dell’effetto</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/09_s_m_errors.html">Crisi della replicabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/10_integrity.html">Integrità della ricerca</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../references/bibliography.html">Bibliografia</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_7/introduction_appendix.html">Appendici</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a00_installation.html">Ambiente di lavoro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a01_markdown.html">Jupyter Notebook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a02_shell.html">La Shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a03_colab_tutorial.html">Colab: un breve tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a04_virtual_env.html">Ambienti virtuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a10_math_symbols.html">Simbologia di base</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a11_numbers.html">Numeri binari, interi, razionali, irrazionali e reali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a12_sum_notation.html">Simbolo di somma (sommatorie)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a13_sets.html">Insiemi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a13a_probability.html">Sigma algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a14_combinatorics.html">Calcolo combinatorio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a15_calculus.html">Per liberarvi dai terrori preliminari</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a20_kde_plot.html">Kernel Density Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a30_prob_tutorial.html">Esercizi di probabilità discreta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a40_rng.html">Generazione di numeri casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a44_montecarlo.html">Simulazione Monte Carlo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a45_mcmc.html">Catene di Markov</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a46_stan.html">Linguaggio Stan</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a50_lin_fun.html">La funzione lineare</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a50_reglin_ml.html">Modello di Regressione Bivariato e ML</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a51_reglin_1.html">Regressione lineare bivariata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a60_ttest_exercises.html">Esercizi sull’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a70_predict_counts.html">La predizione delle frequenze</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/ccaudek/ds4p/blob/main/docs/chapter_4/15_stan_beta_binomial.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Scarica questa pagina">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapter_4/15_stan_beta_binomial.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Scarica il file sorgente"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Stampa in PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Modalità schermo intero"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Cerca" aria-label="Cerca" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Introduzione a Stan</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contenuti </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Introduzione a Stan</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparazione-del-notebook">Preparazione del Notebook</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Introduzione a Stan</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#metodi-monte-carlo-a-catena-di-markov-mcmc">Metodi Monte Carlo a Catena di Markov (MCMC)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stan-e-la-programmazione-probabilistica">Stan e la Programmazione Probabilistica</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#struttura-di-un-programma-stan">Struttura di un Programma Stan</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#esecuzione-di-un-programma-stan">Esecuzione di un Programma Stan</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulazione-avanti-e-problema-inverso">Simulazione Avanti e Problema Inverso</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#simulazione-avanti">Simulazione Avanti</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#esempio-di-simulazione-avanti">Esempio di Simulazione Avanti</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#il-problema-inverso">Il Problema Inverso</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#un-primo-programma-in-stan">Un Primo Programma in Stan</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generazione-di-dati-casuali">Generazione di Dati Casuali</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#organizzazione-di-un-programma-stan">Organizzazione di un Programma Stan</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tipi-di-variabili-in-stan">Tipi di Variabili in Stan</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vincoli-sui-tipi">Vincoli sui Tipi</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#esecuzione-del-programma-stan">Esecuzione del Programma Stan</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#costruzione-del-modello">Costruzione del Modello</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interfaccia-python">Interfaccia Python</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estrazione-dei-risultati">Estrazione dei Risultati</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#integrazione-monte-carlo">Integrazione Monte Carlo</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#esempio-stima-di-pi">Esempio: Stima di <span class="math notranslate nohighlight">\(\pi\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#codice-stan">Codice Stan</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#media-campionaria-dell-indicatore">Media Campionaria dell’Indicatore</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compilazione-e-campionamento">Compilazione e Campionamento</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metodi-monte-carlo-a-catena-di-markov">Metodi Monte Carlo a Catena di Markov</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#catene-di-markov">Catene di Markov</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#esempio-di-catena-di-markov">Esempio di Catena di Markov</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#il-problema-inverso-delle-nascite-di-laplace">Il Problema Inverso delle Nascite di Laplace</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#storia-e-applicazione">Storia e Applicazione</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modello-di-laplace">Modello di Laplace</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#distribuzione-a-priori">Distribuzione a Priori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#distribuzione-a-posteriori">Distribuzione a Posteriori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementazione-in-stan">Implementazione in Stan</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#campionare-dalla-distribuzione-a-posteriori">Campionare dalla Distribuzione a Posteriori</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compilazione-del-codice-stan">Compilazione del Codice Stan</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stime-puntuali-bayesiane">Stime Puntuali Bayesiane</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stimatore-della-media-posteriori">Stimatore della Media Posteriori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stimatore-della-mediana-posteriori-quantili-e-intervalli">Stimatore della Mediana Posteriori, Quantili e Intervalli</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#quantili-e-intervalli-di-credibilita">Quantili e Intervalli di Credibilità</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#quantili">Quantili</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#intervalli-posteriori">Intervalli Posteriori</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#errore-di-stima-e-bias">Errore di Stima e Bias</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stimatore-della-moda-posteriori">Stimatore della Moda Posteriori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#caratteristiche-della-moda-posteriori">Caratteristiche della Moda Posteriori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#funzioni-di-perdita-e-proprieta-degli-stimatori">Funzioni di Perdita e Proprietà degli Stimatori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#proprieta-della-mediana-posteriori">Proprietà della Mediana Posteriori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#concentrazione-sulle-medie-a-posteriori">Concentrazione sulle Medie a Posteriori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#errore-markov-chain-monte-carlo-e-dimensione-del-campione-effettivo">Errore (Markov Chain) Monte Carlo e Dimensione del Campione Effettivo</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#errore-standard-di-monte-carlo-mcmc">Errore Standard di Monte Carlo (MCMC)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#dimensione-del-campione-effettivo">Dimensione del Campione Effettivo</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stima-delle-probabilita-di-evento">Stima delle Probabilità di Evento</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilita-di-evento-tramite-indicatori">Probabilità di Evento tramite Indicatori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#eventi-come-indicatori-in-stan">Eventi come Indicatori in Stan</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#la-risposta-alla-domanda-di-laplace">La Risposta alla Domanda di Laplace</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#statistiche-di-riepilogo-mcmc-da-stan">Statistiche di riepilogo MCMC da Stan</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#riscaldamento-e-monitoraggio-della-convergenza">Riscaldamento e monitoraggio della convergenza</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#riscaldamento">Riscaldamento</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#riduzione-potenziale-della-scala-e-widehat-r">Riduzione potenziale della scala e <span class="math notranslate nohighlight">\(\widehat{R}\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quante-catene-per-quanto-tempo">Quante catene per quanto tempo?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#esecuzione-delle-catene-contemporaneamente">Esecuzione delle catene contemporaneamente</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#matrici-vettori-o-array-in-stan">Matrici, Vettori o Array in Stan</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modello-di-esecuzione-di-stan">Modello di esecuzione di Stan</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dati-e-dati-trasformati">Dati e dati trasformati</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parametri-e-parametri-trasformati">Parametri e Parametri Trasformati</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modello">Modello</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#quantita-generate">Quantità generate</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#informazioni-sull-ambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="introduzione-a-stan">
<span id="cmdstanpy-notebook"></span><h1>Introduzione a Stan<a class="headerlink" href="#introduzione-a-stan" title="Link to this heading">#</a></h1>
<p>Nel presente capitolo, presenteremo un linguaggio di programmazione probabilistica denominato <a class="reference external" href="http://mc-stan.org/">Stan</a>. Stan consente di estrarre campioni da distribuzioni di probabilità mediante la costruzione di una catena di Markov, la cui distribuzione di equilibrio (o stazionaria) coincide con la distribuzione desiderata. Il nome del linguaggio deriva da uno dei pionieri del metodo Monte Carlo, Stanislaw Ulam. Un’introduzione dettagliata al linguaggio Stan è fornita in <a class="reference internal" href="../chapter_7/a46_stan.html#appendix-cmdstanpy"><span class="std std-ref">Linguaggio Stan</span></a>. In questo capitolo, utilizzeremo Stan per fare inferenza su una proporzione.</p>
<p>Il linguaggio di programmazione probabilistica Stan è compatibile con diverse piattaforme e offre varie interfacce (R, Python, Julia). In questo corso, useremo CmdStanPy, un’interfaccia per Stan pensata per gli utenti di Python. CmdStanPy è un pacchetto puramente in Python3 che è un wrapper di CmdStan, l’interfaccia a riga di comando per Stan scritta in C++. Pertanto, oltre a Python3, CmdStanPy richiede un toolchain C++ per compilare ed eseguire i modelli Stan.</p>
<p>La procedura per <a class="reference external" href="https://mc-stan.org/cmdstanpy/installation.html">installare</a> CmdStanPy e i componenti sottostanti di CmdStan dal repository conda-forge è descritta nel capitolo <a class="reference internal" href="../chapter_7/a04_virtual_env.html#appendix-virtual-env"><span class="std std-ref">Ambienti virtuali</span></a>.</p>
<section id="preparazione-del-notebook">
<h2>Preparazione del Notebook<a class="headerlink" href="#preparazione-del-notebook" title="Link to this heading">#</a></h2>
<p>Una volta creato l’ambiente conda <code class="docutils literal notranslate"><span class="pre">cmdstan_env</span></code>, attiviamo il kernel di Visual Studio Code selezionando questo ambiente virtuale. Possiamo quindi caricare i pacchetti necessari.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> ../_config/config.py # Import the configuration settings
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">statistics</span> <span class="k">as</span> <span class="nn">stat</span>
<span class="kn">import</span> <span class="nn">cmdstanpy</span>
<span class="kn">from</span> <span class="nn">cmdstanpy</span> <span class="kn">import</span> <span class="n">CmdStanModel</span>
<span class="n">cmdstanpy</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">get_logger</span><span class="p">()</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id1">
<h2>Introduzione a Stan<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<section id="metodi-monte-carlo-a-catena-di-markov-mcmc">
<h3>Metodi Monte Carlo a Catena di Markov (MCMC)<a class="headerlink" href="#metodi-monte-carlo-a-catena-di-markov-mcmc" title="Link to this heading">#</a></h3>
<p>L’inferenza bayesiana, utilizzata per la stima dei parametri, la previsione e la valutazione della probabilità di eventi, si basa sulle aspettative posteriori. Queste aspettative sono integrali ad alta dimensione sullo spazio dei parametri. Stan, un software avanzato per l’analisi statistica, utilizza il metodo Monte Carlo per risolvere questi integrali complessi. I metodi Monte Carlo si basano sul campionamento casuale per affrontare integrali ad alta dimensione.</p>
<p>Tuttavia, per la maggior parte dei problemi bayesiani, non è possibile usare i metodi Monte Carlo standard poiché non possiamo generare campioni indipendenti dalla densità posteriore di interesse, tranne che per modelli molto semplici con priors coniugati. Pertanto, dobbiamo usare i metodi Monte Carlo a Catena di Markov (MCMC), che producono campioni correlati tra loro. Stan utilizza il Monte Carlo Hamiltoniano (HMC), il metodo MCMC più efficiente e scalabile per le densità target. Altri metodi, come il Metropolis-Hastings e il campionamento Gibbs, sono più semplici ma meno efficienti dell’HMC.</p>
</section>
<section id="stan-e-la-programmazione-probabilistica">
<h3>Stan e la Programmazione Probabilistica<a class="headerlink" href="#stan-e-la-programmazione-probabilistica" title="Link to this heading">#</a></h3>
<p>Stan è un linguaggio di programmazione probabilistica (PPL) progettato per definire modelli statistici complessi e fare inferenza su di essi. Un PPL permette di esprimere modelli probabilistici in modo conciso e di utilizzare algoritmi avanzati per eseguire inferenze. Questo è particolarmente utile nell’inferenza bayesiana, dove aggiorniamo le distribuzioni a priori con dati osservati per ottenere distribuzioni a posteriori.</p>
<section id="struttura-di-un-programma-stan">
<h4>Struttura di un Programma Stan<a class="headerlink" href="#struttura-di-un-programma-stan" title="Link to this heading">#</a></h4>
<p>In Stan è necessario specificare un programma che solitamente è salvato in un file con l’estensione <code class="docutils literal notranslate"><span class="pre">.stan</span></code>. Un programma Stan dichiara variabili e parametri e definisce le distribuzioni a priori dei parametri del modello statistico specificato e la funzione di verosimiglianza. In pratica, ciò significa che un programma Stan descrive come i dati e i parametri interagiscono e quali distribuzioni probabilistiche li governano. Un programma Stan consente di fare inferenza sulle distribuzioni a posteriori dei parametri del modello che vengono inferite dai dati osservati e dalle distribuzioni a priori.</p>
</section>
<section id="esecuzione-di-un-programma-stan">
<h4>Esecuzione di un Programma Stan<a class="headerlink" href="#esecuzione-di-un-programma-stan" title="Link to this heading">#</a></h4>
<p>Un programma Stan utilizza metodi di inferenza avanzati:</p>
<ul class="simple">
<li><p><strong>Campionamento MCMC</strong>: Stan utilizza metodi come il Monte Carlo a Catena di Markov (MCMC) per generare campioni dalle distribuzioni a posteriori.</p></li>
<li><p><strong>Inferenza Variazionale</strong>: Un metodo approssimativo che fornisce stime delle distribuzioni a posteriori.</p></li>
<li><p><strong>Approssimazione di Laplace</strong>: Un altro metodo approssimativo per l’inferenza.</p></li>
</ul>
<p>Stan è disponibile attraverso vari linguaggi di programmazione e strumenti di analisi open-source, tra cui Python, R, e Julia, ed è compatibile con gli strumenti di analisi bayesiana integrati in questi linguaggi. Stan è anche disponibile in ambienti come Mathematica, Stata e MATLAB, anche se queste interfacce sono meno complete.</p>
</section>
</section>
<section id="simulazione-avanti-e-problema-inverso">
<h3>Simulazione Avanti e Problema Inverso<a class="headerlink" href="#simulazione-avanti-e-problema-inverso" title="Link to this heading">#</a></h3>
<p>Stan genera dei dati attraverso procedure pseudo-casuali e questo può essere fatto per le simulazioni in avanti oppure per risolvere il problema inverso.</p>
<section id="simulazione-avanti">
<h4>Simulazione Avanti<a class="headerlink" href="#simulazione-avanti" title="Link to this heading">#</a></h4>
<p>La simulazione avanti consiste nella generazione di dati simulati a partire da un insieme di parametri conosciuti di un modello probabilistico. In altre parole, date certe assunzioni sui parametri di un modello, utilizziamo la simulazione avanti per prevedere i possibili risultati che potrebbero verificarsi.</p>
<p>Ad esempio, consideriamo un trial clinico con <span class="math notranslate nohighlight">\(N\)</span> soggetti e una probabilità <span class="math notranslate nohighlight">\(\theta\)</span> di esito positivo per ciascun soggetto. Se conosciamo il valore di <span class="math notranslate nohighlight">\(\theta\)</span> e il numero di soggetti <span class="math notranslate nohighlight">\(N\)</span>, possiamo usare una distribuzione binomiale per simulare il numero di pazienti che avranno un esito positivo. Questo processo ci permette di generare dati che riflettono le nostre assunzioni sui parametri del modello.</p>
<p>In notazione statistica, questo si esprime come:</p>
<div class="math notranslate nohighlight">
\[
Y \sim \text{Binomiale}(N, \theta)
\]</div>
<p>dove <span class="math notranslate nohighlight">\(Y\)</span> rappresenta il numero di esiti positivi su <span class="math notranslate nohighlight">\(N\)</span> pazienti, con probabilità <span class="math notranslate nohighlight">\(\theta\)</span> di esito positivo per ciascun paziente.</p>
</section>
<section id="esempio-di-simulazione-avanti">
<h4>Esempio di Simulazione Avanti<a class="headerlink" href="#esempio-di-simulazione-avanti" title="Link to this heading">#</a></h4>
<p>Supponiamo di avere <span class="math notranslate nohighlight">\(N = 100\)</span> soggetti in un trial clinico e un tasso di successo <span class="math notranslate nohighlight">\(\theta = 0.3\)</span>. Possiamo simulare un risultato <span class="math notranslate nohighlight">\(Y\)</span> generando casualmente il numero di soggetti con esito positivo. Utilizzando una distribuzione binomiale, possiamo calcolare la probabilità di ottenere esattamente <span class="math notranslate nohighlight">\(y\)</span> esiti positivi su <span class="math notranslate nohighlight">\(N\)</span> tentativi:</p>
<div class="math notranslate nohighlight">
\[
p(Y = y \mid N, \theta) = \binom{N}{y} \cdot \theta^y \cdot (1 - \theta)^{N - y}
\]</div>
<p>Questa espressione ci permette di calcolare la probabilità di ottenere un certo numero di successi, dato il numero di soggetti e la probabilità di successo.</p>
</section>
<section id="il-problema-inverso">
<h4>Il Problema Inverso<a class="headerlink" href="#il-problema-inverso" title="Link to this heading">#</a></h4>
<p>Il problema inverso consiste nello stimare i parametri del modello, come la probabilità di successo <span class="math notranslate nohighlight">\(\theta\)</span>, dato un insieme di dati osservati. Supponiamo di avere i seguenti dati: <span class="math notranslate nohighlight">\(N = 100\)</span> soggetti e <span class="math notranslate nohighlight">\(y = 32\)</span> esiti positivi. Vogliamo stimare <span class="math notranslate nohighlight">\(\theta\)</span>, la probabilità di successo.</p>
<p>In un approccio bayesiano, iniziamo specificando una distribuzione a priori per <span class="math notranslate nohighlight">\(\theta\)</span>. Supponiamo di utilizzare una distribuzione Beta(<span class="math notranslate nohighlight">\(\alpha\)</span>, <span class="math notranslate nohighlight">\(\beta\)</span>) come prior per <span class="math notranslate nohighlight">\(\theta\)</span>, dove <span class="math notranslate nohighlight">\(\alpha\)</span> e <span class="math notranslate nohighlight">\(\beta\)</span> sono parametri scelti in base alle nostre conoscenze precedenti. La distribuzione a posteriori di <span class="math notranslate nohighlight">\(\theta\)</span> data l’osservazione <span class="math notranslate nohighlight">\(y\)</span> è ancora una distribuzione Beta, ma con parametri aggiornati, ovvero:</p>
<div class="math notranslate nohighlight">
\[
\theta \mid y \sim \text{Beta}(\alpha + y, \beta + N - y).
\]</div>
<p>Per esempio, se scegliamo una distribuzione a priori non informativa con <span class="math notranslate nohighlight">\(\alpha = 1\)</span> e <span class="math notranslate nohighlight">\(\beta = 1\)</span>, la distribuzione a posteriori diventa:</p>
<div class="math notranslate nohighlight">
\[
\theta \mid y \sim \text{Beta}(1 + 32, 1 + 100 - 32) = \text{Beta}(33, 69).
\]</div>
<p>Questa distribuzione a posteriori ci fornisce una stima aggiornata della probabilità di successo <span class="math notranslate nohighlight">\(\theta\)</span> considerando i dati osservati. Utilizzando Stan, possiamo ottenere campioni da questa distribuzione a posteriori per calcolare statistiche riassuntive e fare previsioni.</p>
<p>In sintesi, la simulazione avanti e il problema inverso sono due approcci complementari: la simulazione avanti genera dati simulati dai parametri conosciuti, mentre il problema inverso stima i parametri del modello dai dati osservati.</p>
</section>
</section>
</section>
<section id="un-primo-programma-in-stan">
<h2>Un Primo Programma in Stan<a class="headerlink" href="#un-primo-programma-in-stan" title="Link to this heading">#</a></h2>
<section id="generazione-di-dati-casuali">
<h3>Generazione di Dati Casuali<a class="headerlink" href="#generazione-di-dati-casuali" title="Link to this heading">#</a></h3>
<p>Supponiamo di voler generare dei valori casuali <span class="math notranslate nohighlight">\( Y \)</span> da una distribuzione binomiale con parametri <span class="math notranslate nohighlight">\( N \)</span> e <span class="math notranslate nohighlight">\( \theta \)</span>. Ad esempio, possiamo impostare <span class="math notranslate nohighlight">\( \theta = 0.3 \)</span>, per rappresentare una probabilità del 30% di un esito positivo (in statistica, il termine “successo” indica un esito positivo), e possiamo impostare <span class="math notranslate nohighlight">\( N = 100 \)</span>. Il seguente programma Stan può essere utilizzato per generare valori di <span class="math notranslate nohighlight">\( Y \)</span> compresi tra 0 e 100.</p>
<div class="highlight-stan notranslate"><div class="highlight"><pre><span></span><span class="kn">data</span> <span class="p">{</span>
  <span class="kt">int</span><span class="o">&lt;</span><span class="k">lower</span><span class="p">=</span><span class="mf">0</span><span class="o">&gt;</span> <span class="n">N</span><span class="p">;</span>
  <span class="kt">real</span><span class="o">&lt;</span><span class="k">lower</span><span class="p">=</span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="k">upper</span><span class="p">=</span><span class="mf">1</span><span class="o">&gt;</span> <span class="n">theta</span><span class="p">;</span>
<span class="p">}</span>

<span class="kn">generated quantities</span> <span class="p">{</span>
  <span class="kt">int</span><span class="o">&lt;</span><span class="k">lower</span><span class="p">=</span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="k">upper</span><span class="p">=</span><span class="n">N</span><span class="o">&gt;</span> <span class="n">y</span><span class="p">;</span>
  <span class="n">y</span> <span class="o">=</span> <span class="nb">binomial_rng</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">theta</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="organizzazione-di-un-programma-stan">
<h3>Organizzazione di un Programma Stan<a class="headerlink" href="#organizzazione-di-un-programma-stan" title="Link to this heading">#</a></h3>
<p>La prima cosa da notare è che un programma Stan è organizzato in blocchi. Qui abbiamo due blocchi: un <em>blocco dei dati</em> contenente le dichiarazioni delle variabili che devono essere fornite come dati e un <em>blocco delle quantità generate</em>, che non solo dichiara variabili ma assegna loro un valore. In questo programma Stan, la variabile <code class="docutils literal notranslate"><span class="pre">y</span></code> viene assegnata come risultato di una singola estrazione da una distribuzione <span class="math notranslate nohighlight">\(\textrm{binomiale}(N, \theta)\)</span>, che Stan fornisce attraverso la funzione <code class="docutils literal notranslate"><span class="pre">binomial_rng</span></code>.</p>
</section>
<section id="tipi-di-variabili-in-stan">
<h3>Tipi di Variabili in Stan<a class="headerlink" href="#tipi-di-variabili-in-stan" title="Link to this heading">#</a></h3>
<p>La seconda cosa da notare è che tutte le variabili in un programma Stan sono dichiarate con tipi specifici. Stan utilizza la <em>tipizzazione statica</em>, il che significa che, a differenza di Python o R, il tipo di una variabile è dichiarato nel programma prima del suo utilizzo, piuttosto che essere determinato al momento dell’esecuzione in base al valore assegnato. Una volta dichiarato, il tipo di una variabile non cambia mai. Stan utilizza anche la <em>tipizzazione forte</em>, il che significa che, a differenza di C o C++, non è possibile aggirare le restrizioni di tipo per accedere direttamente alla memoria.</p>
<p>Il programma dichiara tre variabili: <code class="docutils literal notranslate"><span class="pre">N</span></code> e <code class="docutils literal notranslate"><span class="pre">y</span></code> di tipo <code class="docutils literal notranslate"><span class="pre">int</span></code> (interi) e <code class="docutils literal notranslate"><span class="pre">theta</span></code> di tipo <code class="docutils literal notranslate"><span class="pre">real</span></code> (numeri reali). Nei computer, gli interi hanno limiti precisi e i numeri reali possono avere errori di calcolo. Stan utilizza numeri reali con precisione doppia (64 bit) secondo lo standard IEEE 754, tranne in alcune operazioni ottimizzate che possono perdere un po” di precisione.</p>
</section>
<section id="vincoli-sui-tipi">
<h3>Vincoli sui Tipi<a class="headerlink" href="#vincoli-sui-tipi" title="Link to this heading">#</a></h3>
<p>Un tipo di variabile può avere dei vincoli. Poiché <code class="docutils literal notranslate"><span class="pre">N</span></code> è un conteggio, deve essere maggiore o uguale a zero, cosa che indichiamo con il vincolo <code class="docutils literal notranslate"><span class="pre">lower=0</span></code>. Allo stesso modo, la variabile <code class="docutils literal notranslate"><span class="pre">y</span></code>, che rappresenta il numero di esiti positivi su <code class="docutils literal notranslate"><span class="pre">N</span></code>, deve essere compresa tra 0 e <code class="docutils literal notranslate"><span class="pre">N</span></code> (inclusi); questo è indicato con il vincolo <code class="docutils literal notranslate"><span class="pre">lower=0,</span> <span class="pre">upper=N</span></code>. Infine, la variabile <code class="docutils literal notranslate"><span class="pre">theta</span></code> è un numero reale e deve essere compresa tra 0 e 1, cosa che indichiamo con il vincolo <code class="docutils literal notranslate"><span class="pre">lower=0,</span> <span class="pre">upper=1</span></code>. Anche se tecnicamente i limiti per i numeri reali sono aperti, in pratica possiamo ottenere valori di 0 o 1 a causa di errori di arrotondamento nei calcoli.</p>
</section>
<section id="esecuzione-del-programma-stan">
<h3>Esecuzione del Programma Stan<a class="headerlink" href="#esecuzione-del-programma-stan" title="Link to this heading">#</a></h3>
<p>La funzione <code class="docutils literal notranslate"><span class="pre">cmdstan_model()</span></code> crea un nuovo oggetto <code class="docutils literal notranslate"><span class="pre">CmdStanModel</span></code> a partire da un file contenente un programma Stan. In background, CmdStan traduce un programma Stan in C++ e creare un eseguibile compilato.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">CmdStanModel</span><span class="p">(</span><span class="n">stan_file</span><span class="o">=</span><span class="s1">&#39;../stan/binomial-rng.stan&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Durante l’esecuzione, il programma Stan compilato richiede i valori di <code class="docutils literal notranslate"><span class="pre">N</span></code> e <code class="docutils literal notranslate"><span class="pre">theta</span></code>. Ad ogni iterazione, il programma campiona un valore di <code class="docutils literal notranslate"><span class="pre">y</span></code> utilizzando il suo generatore di numeri pseudocasuali integrato. I valori di <code class="docutils literal notranslate"><span class="pre">N</span></code> e <code class="docutils literal notranslate"><span class="pre">theta</span></code> devono essere forniti in un dizionario Python.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">theta</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;N&#39;</span><span class="p">:</span> <span class="n">N</span><span class="p">,</span> <span class="s1">&#39;theta&#39;</span><span class="p">:</span> <span class="n">theta</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>Infine campioniamo dal modello utilizzando il metodo <code class="docutils literal notranslate"><span class="pre">sample</span></code> di <code class="docutils literal notranslate"><span class="pre">CmdStanModel</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trace</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span> 
    <span class="n">chains</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">iter_sampling</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
    <span class="n">iter_warmup</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">show_progress</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
    <span class="n">show_console</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="costruzione-del-modello">
<h3>Costruzione del Modello<a class="headerlink" href="#costruzione-del-modello" title="Link to this heading">#</a></h3>
<p>Il costruttore di <code class="docutils literal notranslate"><span class="pre">CmdStanModel</span></code> viene utilizzato per creare un modello a partire da un programma Stan presente nel file specificato. Si consiglia vivamente di utilizzare un file separato per i programmi Stan, in modo da facilitarne la condivisione, permettere l’uso sia di virgolette che di apostrofi e rendere più agevole individuare le linee di riferimento nei messaggi di errore. In pratica, il processo inizia con la traduzione del programma Stan in una classe C++ utilizzando un traduttore specifico. Successivamente, il programma C++ viene compilato, operazione che richiede circa venti secondi.</p>
</section>
<section id="interfaccia-python">
<h3>Interfaccia Python<a class="headerlink" href="#interfaccia-python" title="Link to this heading">#</a></h3>
<p>Nell’interfaccia Python, il metodo <code class="docutils literal notranslate"><span class="pre">sample()</span></code> accetta i seguenti argomenti:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">data</span></code>: i dati letti nel blocco dati del programma Stan,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">seed</span></code>: generatore di numeri pseudocasuali per la riproducibilità,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">chains</span></code>: il numero di simulazioni da eseguire (<code class="docutils literal notranslate"><span class="pre">parallel_chains</span></code> indica quante eseguire in parallelo),</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">iter_sampling</span></code>: numero di estrazioni (cioè, dimensione del campione) da restituire,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">iter_warmup</span></code>: numero di iterazioni di riscaldamento per tarare i parametri dell’algoritmo di campionamento (non necessari qui, quindi impostato a 0),</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">show_progress</span></code>: se <code class="docutils literal notranslate"><span class="pre">True</span></code>, stampa aggiornamenti di progresso,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">show_console</span></code>: apre un monitor di progresso GUI.</p></li>
</ul>
<p>Il risultato della chiamata a <code class="docutils literal notranslate"><span class="pre">sample()</span></code> sull’istanza del modello viene assegnato alla variabile <code class="docutils literal notranslate"><span class="pre">trace</span></code> e contiene le 10 estrazioni richieste con l’argomento <code class="docutils literal notranslate"><span class="pre">iter_sampling</span> <span class="pre">=</span> <span class="pre">10</span></code>.</p>
<p>Quando si chiama <code class="docutils literal notranslate"><span class="pre">model.sample(...)</span></code>, CmdStan esegue Stan come programma C++ autonomo in un processo in background. Questo programma inizia copiando i dati forniti nell’argomento <code class="docutils literal notranslate"><span class="pre">data</span></code> di Python in un file, quindi legge quel file di dati per costruire un oggetto C++ che rappresenta il modello statistico. Poiché il nostro programma Stan ha solo un blocco di quantità generate, l’unico compito rimanente della classe C++ è generare il numero richiesto di estrazioni. Per ciascuna delle estrazioni specificate da <code class="docutils literal notranslate"><span class="pre">iter_sampling</span></code>, Stan utilizza un generatore di numeri pseudocasuali per ottenere un valore dalla distribuzione binomiale specificata.</p>
<p>La generazione di numeri casuali è determinata dal valore <code class="docutils literal notranslate"><span class="pre">seed</span></code> specificato nella chiamata.</p>
</section>
<section id="estrazione-dei-risultati">
<h3>Estrazione dei Risultati<a class="headerlink" href="#estrazione-dei-risultati" title="Link to this heading">#</a></h3>
<p>Una volta completato il campionamento, possiamo estrarre il campione di 10 valori per la variabile scalare <code class="docutils literal notranslate"><span class="pre">y</span></code> sotto forma di array e quindi stampare i loro valori insieme ai valori delle variabili di input.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">trace</span><span class="o">.</span><span class="n">stan_variable</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;N =&quot;</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="s2">&quot;;  theta =&quot;</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="s2">&quot;;  y(0:10) =&quot;</span><span class="p">,</span> <span class="o">*</span><span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>N = 100 ;  theta = 0.3 ;  y(0:10) = 33 36 30 28 37 26 25 19 29 33
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="integrazione-monte-carlo">
<h2>Integrazione Monte Carlo<a class="headerlink" href="#integrazione-monte-carlo" title="Link to this heading">#</a></h2>
<p>Il calcolo bayesiano si basa sulla media delle incertezze nella stima dei parametri. In generale, ciò implica il calcolo di aspettative, che sono medie ponderate con pesi dati dalle densità di probabilità. In questa sezione, introdurremo i metodi Monte Carlo per calcolare un semplice integrale che corrisponde all’aspettativa di una variabile indicatrice discreta. Utilizzeremo l’esempio classico del lancio di freccette su un bersaglio per stimare la costante matematica <span class="math notranslate nohighlight">\(\pi\)</span>.</p>
<section id="esempio-stima-di-pi">
<h3>Esempio: Stima di <span class="math notranslate nohighlight">\(\pi\)</span><a class="headerlink" href="#esempio-stima-di-pi" title="Link to this heading">#</a></h3>
<p>Immaginiamo un quadrato di lato 2 centrato sull’origine. Genereremo punti casuali uniformemente distribuiti all’interno di questo quadrato. Per ogni punto <span class="math notranslate nohighlight">\((x, y)\)</span>, verificheremo se cade all’interno del cerchio di raggio unitario inscritto nel quadrato, cioè se la distanza dall’origine è minore di 1:</p>
<div class="math notranslate nohighlight">
\[
\sqrt{x^2 + y^2} &lt; 1,
\]</div>
<p>che si semplifica a:</p>
<div class="math notranslate nohighlight">
\[
x^2 + y^2 &lt; 1.
\]</div>
<p>La proporzione di tali punti rappresenta la proporzione dell’area del quadrato occupata dal cerchio. Poiché il quadrato ha un’area di 4, l’area del cerchio è pari a 4 volte la proporzione dei punti che cadono all’interno del cerchio.</p>
<p>Quindi, se generiamo un numero sufficiente di punti casuali e contiamo quanti di essi cadono all’interno del cerchio, possiamo stimare <span class="math notranslate nohighlight">\(\pi\)</span> come:</p>
<div class="math notranslate nohighlight">
\[
\pi \approx 4 \times \frac{\text{numero di punti dentro il cerchio}}{\text{numero totale di punti}}.
\]</div>
</section>
<section id="codice-stan">
<h3>Codice Stan<a class="headerlink" href="#codice-stan" title="Link to this heading">#</a></h3>
<p>Esaminiamo il corrispondente codice Stan.</p>
<div class="highlight-stan notranslate"><div class="highlight"><pre><span></span><span class="kn">generated quantities</span> <span class="p">{</span>
  <span class="kt">real</span><span class="o">&lt;</span><span class="k">lower</span><span class="p">=</span><span class="o">-</span><span class="mf">1</span><span class="p">,</span><span class="w"> </span><span class="k">upper</span><span class="p">=</span><span class="mf">1</span><span class="o">&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="nb">uniform_rng</span><span class="p">(</span><span class="o">-</span><span class="mf">1</span><span class="p">,</span> <span class="mf">1</span><span class="p">);</span>
  <span class="kt">real</span><span class="o">&lt;</span><span class="k">lower</span><span class="p">=</span><span class="o">-</span><span class="mf">1</span><span class="p">,</span><span class="w"> </span><span class="k">upper</span><span class="p">=</span><span class="mf">1</span><span class="o">&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">uniform_rng</span><span class="p">(</span><span class="o">-</span><span class="mf">1</span><span class="p">,</span> <span class="mf">1</span><span class="p">);</span>
  <span class="kt">int</span><span class="o">&lt;</span><span class="k">lower</span><span class="p">=</span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="k">upper</span><span class="p">=</span><span class="mf">1</span><span class="o">&gt;</span> <span class="n">inside</span> <span class="o">=</span> <span class="n">x</span><span class="o">^</span><span class="mf">2</span> <span class="o">+</span> <span class="n">y</span><span class="o">^</span><span class="mf">2</span> <span class="o">&lt;</span> <span class="mf">1</span><span class="p">;</span>
  <span class="kt">real</span><span class="o">&lt;</span><span class="k">lower</span><span class="p">=</span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="k">upper</span><span class="p">=</span><span class="mf">4</span><span class="o">&gt;</span> <span class="n">pi</span> <span class="o">=</span> <span class="mf">4</span> <span class="o">*</span> <span class="n">inside</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<ol class="arabic simple">
<li><p><strong>Variabili <code class="docutils literal notranslate"><span class="pre">x</span></code> e <code class="docutils literal notranslate"><span class="pre">y</span></code></strong>:</p>
<ul class="simple">
<li><p>Vengono generate casualmente e uniformemente nell’intervallo <span class="math notranslate nohighlight">\((-1, 1)\)</span>. Questo significa che stiamo campionando punti all’interno di un quadrato di lato 2 centrato sull’origine.</p></li>
</ul>
</li>
<li><p><strong>Variabile <code class="docutils literal notranslate"><span class="pre">inside</span></code></strong>:</p>
<ul class="simple">
<li><p>È un indicatore che verifica se il punto <span class="math notranslate nohighlight">\((x, y)\)</span> cade all’interno del cerchio unitario. La condizione <span class="math notranslate nohighlight">\(x^2 + y^2 &lt; 1\)</span> è vera se il punto <span class="math notranslate nohighlight">\((x, y)\)</span> è all’interno del cerchio di raggio 1 centrato sull’origine, e falsa altrimenti.</p></li>
<li><p>Se la condizione è vera, <code class="docutils literal notranslate"><span class="pre">inside</span></code> è impostato a 1, altrimenti a 0.</p></li>
</ul>
</li>
<li><p><strong>Variabile <code class="docutils literal notranslate"><span class="pre">pi</span></code></strong>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">pi</span></code> viene calcolata come 4 volte il valore di <code class="docutils literal notranslate"><span class="pre">inside</span></code>.</p></li>
</ul>
</li>
</ol>
<p>Il programma Stan genera punti casuali, verifica se cadono all’interno del cerchio e usa la proporzione di punti che cadono all’interno del cerchio per stimare <span class="math notranslate nohighlight">\(\pi\)</span>. Moltiplicando il valore indicatore per 4, otteniamo una stima di <span class="math notranslate nohighlight">\(\pi\)</span> basata su ciascun punto generato. La stima finale di <span class="math notranslate nohighlight">\(\pi\)</span> sarà la media di queste stime su molti punti campionati.</p>
</section>
<section id="media-campionaria-dell-indicatore">
<h3>Media Campionaria dell’Indicatore<a class="headerlink" href="#media-campionaria-dell-indicatore" title="Link to this heading">#</a></h3>
<p>Dopo aver generato un numero sufficiente di punti casuali e aver verificato quanti di essi cadono all’interno del cerchio, calcoliamo la media campionaria dell’indicatore <code class="docutils literal notranslate"><span class="pre">inside</span></code>. Questo indicatore è uguale a 1 se il punto è dentro il cerchio e a 0 se è fuori. La media di questi valori ci dà la proporzione dei punti che cadono dentro il cerchio.</p>
<p>Questa proporzione è una stima della probabilità che un punto casuale sia all’interno del cerchio. Moltiplicando questa proporzione per 4, otteniamo una stima di <span class="math notranslate nohighlight">\(\pi\)</span>.</p>
<p>Matematicamente, possiamo scrivere questo processo come segue:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}[4 \cdot \textrm{I}(\sqrt{X^2 + Y^2} \leq 1)] = \int_{-1}^1 \int_{-1}^1 4 \cdot \textrm{I}(x^2 + y^2 &lt; 1) \, \textrm{d}x \, \textrm{d}y = \pi,
\]</div>
<p>dove <span class="math notranslate nohighlight">\(\textrm{I}()\)</span> è l’indicatore che ritorna 1 se il suo argomento è vero e 0 altrimenti.</p>
<p>In altre parole, stiamo calcolando l’aspettativa di 4 volte l’indicatore che un punto casuale <span class="math notranslate nohighlight">\((x, y)\)</span> cade dentro il cerchio unitario. Questo valore atteso è uguale a <span class="math notranslate nohighlight">\(\pi\)</span>, il che ci permette di stimare <span class="math notranslate nohighlight">\(\pi\)</span> usando i metodi Monte Carlo.</p>
</section>
<section id="compilazione-e-campionamento">
<h3>Compilazione e Campionamento<a class="headerlink" href="#compilazione-e-campionamento" title="Link to this heading">#</a></h3>
<p>Compiliamo e poi campioniamo dal modello, prendendo un campione di dimensione <span class="math notranslate nohighlight">\(M = 10,000\)</span> estrazioni.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">M</span> <span class="o">=</span> <span class="mi">10_000</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">CmdStanModel</span><span class="p">(</span><span class="n">stan_file</span><span class="o">=</span><span class="s1">&#39;../stan/monte-carlo-pi.stan&#39;</span><span class="p">)</span>

<span class="n">sample</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
    <span class="n">chains</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">iter_warmup</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">iter_sampling</span><span class="o">=</span><span class="n">M</span><span class="p">,</span>
    <span class="n">show_progress</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">show_console</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">123</span>
<span class="p">)</span>

<span class="n">x_draws</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">stan_variable</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">y_draws</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">stan_variable</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">inside_draws</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">stan_variable</span><span class="p">(</span><span class="s1">&#39;inside&#39;</span><span class="p">)</span>
<span class="n">pi_draws</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">stan_variable</span><span class="p">(</span><span class="s1">&#39;pi&#39;</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;N&#39;</span><span class="p">:</span> <span class="mi">1000</span><span class="p">,</span> <span class="s1">&#39;x&#39;</span><span class="p">:</span> <span class="n">x_draws</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="n">y_draws</span><span class="p">,</span> <span class="s1">&#39;inside&#39;</span><span class="p">:</span> <span class="n">inside_draws</span><span class="p">})</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;inside&#39;</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Monte Carlo Simulation of Pi Estimation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">,</span> <span class="n">adjustable</span><span class="o">=</span><span class="s1">&#39;box&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/f0471f6afa3060e9958c54e2ce8bd8cdd4c38f39e4e1f382d6d88c036d1cf9b2.png"><img alt="../_images/f0471f6afa3060e9958c54e2ce8bd8cdd4c38f39e4e1f382d6d88c036d1cf9b2.png" src="../_images/f0471f6afa3060e9958c54e2ce8bd8cdd4c38f39e4e1f382d6d88c036d1cf9b2.png" style="width: 530px; height: 496px;" /></a>
</div>
</div>
<p>Successivamente, calcoliamo la media campionaria dell’indicatore dentro-il-cerchio, che produce una stima della probabilità che un punto sia dentro il cerchio:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Pr_is_inside</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">inside_draws</span><span class="p">)</span>
<span class="n">pi_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">pi_draws</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pr[Y is inside circle] = </span><span class="si">{</span><span class="n">Pr_is_inside</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;estimate for pi = </span><span class="si">{</span><span class="n">pi_hat</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pr[Y is inside circle] = 0.786;
estimate for pi = 3.144
</pre></div>
</div>
</div>
</div>
<p>Il valore esatto di <span class="math notranslate nohighlight">\(\pi\)</span> fino a tre cifre decimali è <span class="math notranslate nohighlight">\(3,142\)</span>. Con il nostro metodo, ci avviciniamo a questo valore, ma non lo raggiungiamo esattamente, il che è tipico dei metodi Monte Carlo. Aumentando il numero di estrazioni, l’errore diminuisce. Teoricamente, con un numero sufficiente di estrazioni, possiamo ottenere qualsiasi precisione desiderata; tuttavia, in pratica, dobbiamo accontentarci di pochi decimali di accuratezza nelle nostre stime Monte Carlo. Questo di solito non è un problema, poiché l’incertezza statistica tende a dominare rispetto all’imprecisione numerica nella maggior parte delle applicazioni.</p>
</section>
</section>
<section id="metodi-monte-carlo-a-catena-di-markov">
<h2>Metodi Monte Carlo a Catena di Markov<a class="headerlink" href="#metodi-monte-carlo-a-catena-di-markov" title="Link to this heading">#</a></h2>
<p>Nelle sezioni precedenti, abbiamo visto come generare un campione eseguendo una serie di estrazioni indipendenti e calcolare la media dei risultati per ottenere stime delle aspettative.</p>
<p>Nei moderni modelli bayesiani, raramente è possibile generare estrazioni indipendenti dalle distribuzioni di interesse. Questo rende i semplici metodi Monte Carlo non applicabili. Solo in rari casi, con modelli molto semplici, è possibile ottenere estrazioni indipendenti, ma questi casi sono limitati (Diaconis e Ylvisaker 1979). Prima della rivoluzione dei metodi Monte Carlo a catena di Markov (MCMC) negli anni “90, l’inferenza bayesiana era per lo più limitata a questi modelli semplici.</p>
<p>L’introduzione dei metodi MCMC ha rivoluzionato l’inferenza bayesiana. Questi metodi permettono di generare campioni da distribuzioni complesse dove non è possibile ottenere estrazioni indipendenti. Tra questi, il metodo Hamiltonian Monte Carlo (HMC) è particolarmente efficiente e scalabile, grazie all’uso della differenziazione automatica. HMC è implementato in Stan e ha ampliato notevolmente la gamma di modelli che possono essere analizzati in tempi ragionevoli.</p>
<section id="catene-di-markov">
<h3>Catene di Markov<a class="headerlink" href="#catene-di-markov" title="Link to this heading">#</a></h3>
<p>Nei metodi Monte Carlo a catena di Markov, ogni estrazione dipende dall’estrazione precedente. Una sequenza di variabili casuali in cui ciascuna dipende solo dalla variabile precedente è chiamata catena di Markov. In altre parole, una catena di Markov è una sequenza di variabili casuali dove ogni variabile è condizionatamente indipendente dalle precedenti, dato il valore della variabile immediatamente precedente.</p>
</section>
<section id="esempio-di-catena-di-markov">
<h3>Esempio di Catena di Markov<a class="headerlink" href="#esempio-di-catena-di-markov" title="Link to this heading">#</a></h3>
<p>Consideriamo un esempio semplice con tre catene di Markov, tutte con una distribuzione stazionaria di <span class="math notranslate nohighlight">\(\theta = 0.5\)</span>. Questo significa che, col tempo, la distribuzione delle estrazioni converge a una distribuzione Bernoulli con parametro <span class="math notranslate nohighlight">\(\theta\)</span> pari a 0.5. La media a lungo termine delle estrazioni si avvicinerà a 0.5, poiché questo è il valore atteso di una variabile Bernoulli con parametro <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<p>Ecco un programma Stan che implementa una catena di Markov:</p>
<div class="highlight-stan notranslate"><div class="highlight"><pre><span></span><span class="kn">data</span> <span class="p">{</span>
  <span class="kt">int</span><span class="o">&lt;</span><span class="k">lower</span><span class="p">=</span><span class="mf">0</span><span class="o">&gt;</span> <span class="n">M</span><span class="p">;</span>
  <span class="kt">real</span><span class="o">&lt;</span><span class="k">lower</span><span class="p">=</span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="k">upper</span><span class="p">=</span><span class="mf">1</span><span class="o">&gt;</span> <span class="n">rho</span><span class="p">;</span>  <span class="c1">// probabilità di rimanere nello stesso stato</span>
<span class="p">}</span>
<span class="kn">generated quantities</span> <span class="p">{</span>
  <span class="kt">array</span><span class="p">[</span><span class="n">M</span><span class="p">]</span> <span class="kt">int</span><span class="o">&lt;</span><span class="k">lower</span><span class="p">=</span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="k">upper</span><span class="p">=</span><span class="mf">1</span><span class="o">&gt;</span> <span class="n">y</span><span class="p">;</span>  <span class="c1">// Catena di Markov</span>
  <span class="n">y</span><span class="p">[</span><span class="mf">1</span><span class="p">]</span> <span class="o">=</span> <span class="nb">bernoulli_rng</span><span class="p">(</span><span class="mf">0.5</span><span class="p">);</span>
  <span class="k">for</span> <span class="p">(</span><span class="n">m</span> <span class="k">in</span> <span class="mf">2</span><span class="o">:</span><span class="n">M</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">y</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="o">=</span> <span class="nb">bernoulli_rng</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">m</span> <span class="o">-</span> <span class="mf">1</span><span class="p">]</span> <span class="o">?</span> <span class="n">rho</span> <span class="o">:</span> <span class="mf">1</span> <span class="o">-</span> <span class="n">rho</span><span class="p">);</span>
  <span class="p">}</span> 
<span class="p">}</span>
</pre></div>
</div>
<p>In questo programma, <code class="docutils literal notranslate"><span class="pre">y[m]</span></code> viene assegnato utilizzando un’operazione ternaria. Se <code class="docutils literal notranslate"><span class="pre">y[m</span> <span class="pre">-</span> <span class="pre">1]</span></code> è 1, <code class="docutils literal notranslate"><span class="pre">y[m]</span></code> è assegnato a <code class="docutils literal notranslate"><span class="pre">bernoulli_rng(rho)</span></code>, altrimenti è assegnato a <code class="docutils literal notranslate"><span class="pre">bernoulli_rng(1</span> <span class="pre">-</span> <span class="pre">rho)</span></code>. Questo crea una catena di Markov dove la probabilità di rimanere nello stesso stato è <code class="docutils literal notranslate"><span class="pre">rho</span></code>.</p>
<p>In conclusione, i metodi Monte Carlo a catena di Markov, come l’Hamiltonian Monte Carlo, hanno ampliato notevolmente le capacità dell’inferenza bayesiana, permettendo di affrontare modelli complessi che non possono essere analizzati con semplici estrazioni indipendenti.</p>
</section>
</section>
<section id="il-problema-inverso-delle-nascite-di-laplace">
<h2>Il Problema Inverso delle Nascite di Laplace<a class="headerlink" href="#il-problema-inverso-delle-nascite-di-laplace" title="Link to this heading">#</a></h2>
<p>Quando si dispone di un modello che genera dati a partire dai parametri, il problema inverso consiste nell’inferire i valori dei parametri dai dati osservati. Questo tipo di problema richiede di ragionare a ritroso dalle osservazioni, attraverso il modello di misurazione e il modello diretto, per stimare parametri come, ad esempio, la probabilità di successo. La risoluzione dei problemi inversi è uno degli ambiti in cui le statistiche bayesiane eccellono.</p>
<section id="storia-e-applicazione">
<h3>Storia e Applicazione<a class="headerlink" href="#storia-e-applicazione" title="Link to this heading">#</a></h3>
<p>Un decennio dopo la pubblicazione della regola di Bayes, Laplace utilizzò la funzione beta di Eulero per derivare formalmente la distribuzione a posteriori. In questa sezione, analizzeremo il problema di Laplace utilizzando Stan.</p>
<p>Laplace raccolse dati sul sesso dei bambini nati vivi a Parigi tra il 1745 e il 1770:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Sesso</p></th>
<th class="head"><p>Nascite vive</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Femmina</p></td>
<td><p>105.287</p></td>
</tr>
<tr class="row-odd"><td><p>Maschio</p></td>
<td><p>110.312</p></td>
</tr>
</tbody>
</table>
</div>
<p>Laplace si chiese se, sulla base di questi dati, la probabilità di nascita dei maschi fosse superiore a quella delle femmine.</p>
</section>
<section id="modello-di-laplace">
<h3>Modello di Laplace<a class="headerlink" href="#modello-di-laplace" title="Link to this heading">#</a></h3>
<p>Laplace adottò la seguente distribuzione campionaria per modellare il numero di maschi nati su un totale di <span class="math notranslate nohighlight">\( N \)</span> nascite:</p>
<div class="math notranslate nohighlight">
\[
y \sim \text{binomiale}(N, \theta),
\]</div>
<p>dove <span class="math notranslate nohighlight">\( N \)</span> è il numero totale di nascite, <span class="math notranslate nohighlight">\( \theta \)</span> è la probabilità di nascita di un maschio e <span class="math notranslate nohighlight">\( y \)</span> è il numero di nascite maschili.</p>
</section>
<section id="distribuzione-a-priori">
<h3>Distribuzione a Priori<a class="headerlink" href="#distribuzione-a-priori" title="Link to this heading">#</a></h3>
<p>Laplace utilizzò la seguente distribuzione a priori per <span class="math notranslate nohighlight">\( \theta \)</span>:</p>
<div class="math notranslate nohighlight">
\[
\theta \sim \text{beta}(1, 1),
\]</div>
<p>dove la distribuzione <span class="math notranslate nohighlight">\(\text{beta}(1, 1)\)</span> è uniforme sull’intervallo <span class="math notranslate nohighlight">\(\theta \in (0, 1)\)</span> poiché la densità è proporzionale a una costante:</p>
<div class="math notranslate nohighlight">
\[
\text{beta}(\theta \mid 1, 1) \propto \theta^{1 - 1} \cdot (1 - \theta)^{1 - 1} = 1.
\]</div>
</section>
<section id="distribuzione-a-posteriori">
<h3>Distribuzione a Posteriori<a class="headerlink" href="#distribuzione-a-posteriori" title="Link to this heading">#</a></h3>
<p>Il modello di Laplace è abbastanza semplice da permettere una soluzione analitica della distribuzione a posteriori:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
    p(\theta \mid y, N) &amp;\propto p(y \mid N, \theta) \cdot p(\theta) \\
    &amp;= \text{binomiale}(y \mid N, \theta) \cdot \text{beta}(\theta \mid 1, 1) \\
    &amp;\propto \theta^y \cdot (1 - \theta)^{N - y} \cdot \theta^{1 - 1} \cdot (1 - \theta)^{1 - 1} \\
    &amp;= \theta^{y} \cdot (1 - \theta)^{N - y} \\
    &amp;\propto \text{beta}(\theta \mid y + 1, N - y + 1).
\end{aligned}
\end{split}\]</div>
<p>Quindi, possiamo concludere che:</p>
<div class="math notranslate nohighlight">
\[
p(\theta \mid y, N) = \text{beta}(\theta \mid y + 1, N - y + 1).
\]</div>
</section>
<section id="implementazione-in-stan">
<h3>Implementazione in Stan<a class="headerlink" href="#implementazione-in-stan" title="Link to this heading">#</a></h3>
<p>A differenza del primo modello Stan che abbiamo visto, che generava solo dati, il seguente programma Stan richiede che vengano forniti dati, specificamente il numero di nascite maschili (<span class="math notranslate nohighlight">\( y \)</span>) e il numero totale di nascite (<span class="math notranslate nohighlight">\( N \)</span>). Il modello ci permetterà di stimare la probabilità di nascita di un maschio (<span class="math notranslate nohighlight">\( \theta \)</span>) e la probabilità che nascano più maschi che femmine (<span class="math notranslate nohighlight">\( \theta &gt; 0.5 \)</span>).</p>
<p>Ecco come possiamo specificare il modello Stan:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stan_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
    <span class="n">project_directory</span><span class="p">,</span> <span class="s1">&#39;stan&#39;</span><span class="p">,</span> <span class="s1">&#39;sex-ratio.stan&#39;</span><span class="p">)</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">stan_file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>data {
  int&lt;lower = 0&gt; N;
  int&lt;lower = 0, upper = N&gt; y;
  int&lt;lower = 0&gt; alpha_prior;
  int&lt;lower = 0&gt; beta_prior;
}
parameters {
  real&lt;lower=0, upper=1&gt; theta;
}
model {
  theta ~ beta(alpha_prior, beta_prior);
  y ~ binomial(N, theta);
}
generated quantities {
  int&lt;lower=0, upper=1&gt; boys_gt_girls = theta &gt; 0.5;
}
</pre></div>
</div>
</div>
</div>
<p>In questo programma Stan, vediamo che sia il numero totale di nascite (<span class="math notranslate nohighlight">\( N \)</span>) sia il numero di nascite maschili (<span class="math notranslate nohighlight">\( y \)</span>) sono forniti come dati. Poi ci sono due blocchi aggiuntivi: un <em>blocco dei parametri</em>, usato per dichiarare valori sconosciuti (qui, solo il tasso di nascite maschili <span class="math notranslate nohighlight">\( \theta \)</span>), e un <em>blocco del modello</em>, dove specifichiamo la distribuzione a priori e la verosimiglianza. La distribuzione a posteriori viene calcolata da Stan combinando queste due componenti. Inoltre, c’è un <strong>blocco delle quantità generate</strong> dove viene calcolata una variabile booleana che indica se la probabilità di nascita dei maschi <span class="math notranslate nohighlight">\(\theta\)</span> è maggiore di 0.5.</p>
<p>Il modello di Laplace e la sua implementazione in Stan ci permettono di affrontare il problema inverso delle nascite, inferendo la probabilità di nascita di un maschio dai dati osservati. Utilizzando le tecniche bayesiane, possiamo stimare non solo la probabilità di nascita di un maschio, ma anche la probabilità che nascano più maschi che femmine.</p>
</section>
</section>
<section id="campionare-dalla-distribuzione-a-posteriori">
<h2>Campionare dalla Distribuzione a Posteriori<a class="headerlink" href="#campionare-dalla-distribuzione-a-posteriori" title="Link to this heading">#</a></h2>
<p>Quando eseguiamo un programma Stan, esso genera una serie di campioni casuali che approssimano la distribuzione a posteriori. Con il proseguire delle estrazioni, questi campioni tendono a diventare sempre più simili a veri campioni della distribuzione a posteriori, fino a diventare numericamente indistinguibili da essa.</p>
<p>Stan utilizza un algoritmo Markov Chain Monte Carlo (MCMC), che può introdurre autocorrelazione nei campioni della distribuzione a posteriori. In altre parole, i campioni non sono indipendenti tra loro, ma ogni campione è correlato (o anti-correlato) con il campione precedente.</p>
<p>L’autocorrelazione non introduce bias nelle stime Monte Carlo, ma i campioni positivamente autocorrelati, che si osservano nei modelli più complessi, aumentano la varianza delle stime rispetto ai campioni indipendenti. Questo incremento della varianza aumenta l’errore quadratico medio atteso, che è una combinazione di errore dovuto al bias (qui nullo) e alla varianza. Al contrario, nei modelli molto semplici, l’autocorrelazione negativa riduce la varianza rispetto ai campioni indipendenti, riducendo quindi l’errore quadratico medio atteso.</p>
<p>Per affrontare problemi ad alta dimensionalità, Duane et al. (1987) hanno introdotto l’algoritmo Hamiltonian Monte Carlo (HMC) che migliora l’efficienza del campionamento. Per Stan, Hoffman e Gelman (2014) hanno sviluppato una versione adattiva dell’HMC chiamata No-U-Turn Sampler (NUTS), successivamente migliorata da Betancourt (2017a). NUTS può essere estremamente efficiente, generando campioni anti-correlati che possono portare a stime Monte Carlo più precise rispetto ai campioni indipendenti.</p>
<section id="compilazione-del-codice-stan">
<h3>Compilazione del Codice Stan<a class="headerlink" href="#compilazione-del-codice-stan" title="Link to this heading">#</a></h3>
<p>Per utilizzare Stan, dobbiamo compilare il codice del modello. Questo crea un file eseguibile che, nel nostro caso, abbiamo chiamato <code class="docutils literal notranslate"><span class="pre">model</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">CmdStanModel</span><span class="p">(</span><span class="n">stan_file</span><span class="o">=</span><span class="n">stan_file</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>I dati devono essere contenuti in un dizionario.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">boys</span> <span class="o">=</span> <span class="mi">110312</span>
<span class="n">girls</span> <span class="o">=</span> <span class="mi">105287</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;N&#39;</span><span class="p">:</span> <span class="n">boys</span> <span class="o">+</span> <span class="n">girls</span><span class="p">,</span> 
    <span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="n">boys</span><span class="p">,</span>
    <span class="s2">&quot;alpha_prior&quot;</span> <span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;beta_prior&quot;</span> <span class="p">:</span> <span class="mi">1</span>
    <span class="p">}</span>

<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;N&#39;: 215599, &#39;y&#39;: 110312, &#39;alpha_prior&#39;: 1, &#39;beta_prior&#39;: 1}
</pre></div>
</div>
</div>
</div>
<p>Possiamo ora eseguire il campionamento MCMC con la seguente chiamata.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
    <span class="n">iter_warmup</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
    <span class="n">iter_sampling</span> <span class="o">=</span> <span class="mi">10_000</span><span class="p">,</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="mi">123</span><span class="p">,</span>
    <span class="n">show_progress</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
    <span class="n">show_console</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Il metodo <code class="docutils literal notranslate"><span class="pre">$sample()</span></code> viene applicato al file eseguibile del modello Stan che abbiamo compilato e nominato <code class="docutils literal notranslate"><span class="pre">model</span></code>.</p>
<p>Avendo assunto una distribuzione a priori per il parametro <span class="math notranslate nohighlight">\(\theta\)</span>, l’algoritmo procede in maniera ciclica, aggiornando la distribuzione a priori di <span class="math notranslate nohighlight">\(\theta\)</span> condizionandola ai valori già generati. Dopo un certo numero di iterazioni, l’algoritmo raggiunge la convergenza, e i valori estratti possono essere considerati campioni dalla distribuzione a posteriori di <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<p>All’inizio del campionamento, la distribuzione dei campioni può essere significativamente diversa dalla distribuzione stazionaria. Questo periodo iniziale è chiamato «burn-in». Durante il burn-in, i campioni possono non rappresentare accuratamente la distribuzione a posteriori e sono tipicamente scartati. Man mano che il numero di iterazioni aumenta, la distribuzione dei campioni si avvicina sempre più alla distribuzione target.</p>
<p>Dopo aver eseguito il modello in Stan, otteniamo una serie di campioni <span class="math notranslate nohighlight">\( \theta^{(m)} \)</span> dalla distribuzione a posteriori <span class="math notranslate nohighlight">\( p(\theta \mid N, y) \)</span>. Ogni campione rappresenta un possibile valore di <span class="math notranslate nohighlight">\( \theta \)</span> compatibile con i dati osservati <span class="math notranslate nohighlight">\( y \)</span>. Procediamo quindi a estrarre i campioni a posteriori per le variabili <code class="docutils literal notranslate"><span class="pre">theta</span></code> e <code class="docutils literal notranslate"><span class="pre">boys_gt_girls</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">theta_draws</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">stan_variable</span><span class="p">(</span><span class="s1">&#39;theta&#39;</span><span class="p">)</span>
<span class="n">boys_gt_girls_draws</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">stan_variable</span><span class="p">(</span><span class="s1">&#39;boys_gt_girls&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Tracciando un istogramma di questi campioni, possiamo visualizzare dove i valori di <span class="math notranslate nohighlight">\( \theta \)</span> sono più probabili e comprendere meglio la forma della distribuzione a posteriori. L’istogramma ci fornisce diverse informazioni:</p>
<ul class="simple">
<li><p><strong>Valore più probabile di <span class="math notranslate nohighlight">\( \theta \)</span></strong>: Questo è il valore intorno al quale i campioni sono più concentrati, noto come la moda della distribuzione.</p></li>
<li><p><strong>Distribuzione dei possibili valori di <span class="math notranslate nohighlight">\( \theta \)</span></strong>: Questo ci dà un’idea dell’incertezza nella stima di <span class="math notranslate nohighlight">\( \theta \)</span>.</p></li>
</ul>
<p>Se l’istogramma è stretto e concentrato attorno a un valore specifico, significa che c’è poca incertezza nella stima di <span class="math notranslate nohighlight">\( \theta \)</span>. In altre parole, possiamo essere abbastanza sicuri che il valore vero di <span class="math notranslate nohighlight">\( \theta \)</span> sia vicino a questo valore.</p>
<p>Se l’istogramma è largo e distribuito, significa che c’è maggiore incertezza nella stima di <span class="math notranslate nohighlight">\( \theta \)</span>. Questo indica che i dati osservati non forniscono una stima precisa e che il valore di <span class="math notranslate nohighlight">\( \theta \)</span> potrebbe variare notevolmente.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">theta_draws</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Aggiunta di titolo e etichette agli assi</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Istogramma della distribizione a posteriori di theta&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Valori&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequenza&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/80b6dee059d2a198a3398fab7bb5d976ebfa7fb1532285cd04b70bb088ad05a4.png"><img alt="../_images/80b6dee059d2a198a3398fab7bb5d976ebfa7fb1532285cd04b70bb088ad05a4.png" src="../_images/80b6dee059d2a198a3398fab7bb5d976ebfa7fb1532285cd04b70bb088ad05a4.png" style="width: 731px; height: 491px;" /></a>
</div>
</div>
</section>
</section>
<section id="stime-puntuali-bayesiane">
<h2>Stime Puntuali Bayesiane<a class="headerlink" href="#stime-puntuali-bayesiane" title="Link to this heading">#</a></h2>
<p>In termini bayesiani, una <em>stima puntuale</em> per un parametro <span class="math notranslate nohighlight">\(\Theta\)</span> condizionato sui dati osservati <span class="math notranslate nohighlight">\(Y = y\)</span> è un singolo valore <span class="math notranslate nohighlight">\(\hat{\theta} \in \mathbb{R}^D\)</span> che riassume la distribuzione a posteriori <span class="math notranslate nohighlight">\(p(\theta \mid y)\)</span>. La notazione <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> è convenzionale nella statistica per indicare una stima di un parametro <span class="math notranslate nohighlight">\(\theta\)</span>. In questa sezione definiamo tre stimatori e discutiamo come i due stimatori bayesiani minimizzino una <em>funzione di perdita</em> tra il valore vero e la stima. Torneremo alla funzione di perdita e alle proprietà degli stimatori dopo averli definiti.</p>
<section id="stimatore-della-media-posteriori">
<h3>Stimatore della Media Posteriori<a class="headerlink" href="#stimatore-della-media-posteriori" title="Link to this heading">#</a></h3>
<p>La stima puntuale bayesiana più comune per un parametro è la media posteriori,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\widehat{\theta}
&amp;= \mathbb{E}[\Theta \mid Y = y] \\
&amp;= \int_{\Theta} \theta \cdot p(\theta \mid y) \, \textrm{d}\theta \\
&amp;= \lim_{M \rightarrow \infty} \, \frac{1}{M} \sum_{m=1}^M \theta^{(m)} \\
&amp;\approx \frac{1}{M} \sum_{m=1}^M \theta^{(m)},
\end{align}
\end{split}\]</div>
<p>dove nelle ultime due righe, ogni estrazione è distribuita approssimativamente secondo la distribuzione a posteriori,</p>
<div class="math notranslate nohighlight">
\[
\theta^{(m)} \sim p(\theta \mid y).
\]</div>
<p>Abbiamo introdotto la notazione di <em>aspettativa condizionale</em> nella prima riga di questa definizione. Le aspettative sono semplicemente medie ponderate, con i pesi dati da una densità di probabilità. L’inferenza bayesiana coinvolge aspettative sulla distribuzione a posteriori, la cui notazione concisa è quella dell”<em>aspettativa condizionale</em>,</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}\!
\left[ f(\Theta) \mid Y = y \right]
= \int_{\mathbb{R^N}} f(\theta) \cdot p_{\Theta \mid Y}(\theta \mid y) \, \textrm{d}\theta,
\]</div>
<p>dove <span class="math notranslate nohighlight">\(\Theta\)</span> e <span class="math notranslate nohighlight">\(Y\)</span> sono variabili casuali, mentre <span class="math notranslate nohighlight">\(\theta\)</span> e <span class="math notranslate nohighlight">\(y\)</span> sono variabili vincolate ordinarie.</p>
<p>Per il modello di Laplace, la stima per il tasso di nascite maschili <span class="math notranslate nohighlight">\(\theta\)</span> condizionata sui dati di nascita <span class="math notranslate nohighlight">\(y\)</span> è calcolata come la media campionaria delle estrazioni per <code class="docutils literal notranslate"><span class="pre">theta</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">theta_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">theta_draws</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;estimated theta = </span><span class="si">{</span><span class="n">theta_hat</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>estimated theta = 0.512
</pre></div>
</div>
</div>
</div>
</section>
<section id="stimatore-della-mediana-posteriori-quantili-e-intervalli">
<h3>Stimatore della Mediana Posteriori, Quantili e Intervalli<a class="headerlink" href="#stimatore-della-mediana-posteriori-quantili-e-intervalli" title="Link to this heading">#</a></h3>
<p>Un’alternativa popolare alla stima puntuale bayesiana è la <em>mediana posteriori</em>, <span class="math notranslate nohighlight">\(\theta^+\)</span>. La mediana è il valore tale che, per ogni dimensione <span class="math notranslate nohighlight">\(d \in 1{:}D\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\Pr[\Theta_d \leq \theta^+_d] = \frac{1}{2}.
\]</div>
<p>In altre parole, la mediana è il valore che divide la distribuzione a posteriori in due parti uguali: il 50% dei campioni è al di sotto della mediana e il 50% è al di sopra. La mediana posteriori può essere calcolata prendendo la mediana dei campioni dalla distribuzione a posteriori.</p>
<p>Ecco come calcolare la mediana posteriori utilizzando Python:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">theta_plus</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">theta_draws</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;estimated (median) theta = </span><span class="si">{</span><span class="n">theta_plus</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>estimated (median) theta = 0.512
</pre></div>
</div>
</div>
</div>
<p>Poiché la distribuzione a posteriori per i dati di Laplace è quasi simmetrica, la media posteriori e la mediana posteriori sono molto simili.</p>
</section>
<section id="quantili-e-intervalli-di-credibilita">
<h3>Quantili e Intervalli di Credibilità<a class="headerlink" href="#quantili-e-intervalli-di-credibilita" title="Link to this heading">#</a></h3>
<p>Oltre alla mediana, possiamo anche calcolare i quantili e gli intervalli di credibilità per fornire ulteriori informazioni sulla distribuzione a posteriori. I quantili sono valori che dividono la distribuzione in intervalli con una probabilità specificata. Gli intervalli di credibilità indicano l’intervallo entro il quale cade una certa percentuale della distribuzione a posteriori.</p>
<section id="quantili">
<h4>Quantili<a class="headerlink" href="#quantili" title="Link to this heading">#</a></h4>
<p>Ad esempio, se vogliamo calcolare il quantile al 95% della distribuzione a posteriori, possiamo semplicemente prendere il valore che si trova al 95° percentile nella sequenza ordinata dei campioni. Di seguito sono riportati i quantili al 5% e al 95% della distribuzione a posteriori di Laplace, calcolati utilizzando i quantili empirici.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">quantile_05</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_draws</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span>
<span class="n">quantile_95</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_draws</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&quot;&quot;0.05 quantile = </span><span class="si">{</span><span class="n">quantile_05</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">;</span>
<span class="s2">0.95 quantile = </span><span class="si">{</span><span class="n">quantile_95</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.05 quantile = 0.510;
0.95 quantile = 0.513
</pre></div>
</div>
</div>
</div>
</section>
<section id="intervalli-posteriori">
<h4>Intervalli Posteriori<a class="headerlink" href="#intervalli-posteriori" title="Link to this heading">#</a></h4>
<p>Insieme, il quantile al 5% e al 95% ci forniscono i limiti del nostro <em>intervallo di probabilità centrale</em> al 90%. Questo intervallo è definito come l’intervallo che contiene il 90% della massa di probabilità a posteriori, con il 5% della massa rimanente al di sotto dell’intervallo e il 5% al di sopra.</p>
</section>
</section>
<section id="errore-di-stima-e-bias">
<h3>Errore di Stima e Bias<a class="headerlink" href="#errore-di-stima-e-bias" title="Link to this heading">#</a></h3>
<p>L”<em>errore</em> di una stima è la differenza tra la stima stessa e il valore vero del parametro,</p>
<div class="math notranslate nohighlight">
\[
\textrm{err} = \hat{\theta} - \theta.
\]</div>
<p>La nostra stima <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> è implicitamente una funzione dei dati <span class="math notranslate nohighlight">\(y\)</span>, quindi anche l’errore dipende dai dati. Possiamo rendere esplicita questa dipendenza scrivendo</p>
<div class="math notranslate nohighlight">
\[
\text{err}(y) = \hat{\theta}(y) - \theta.
\]</div>
<p>Il <em>bias</em> di uno stimatore è definito come l’errore atteso, cioè la media dell’errore rispetto alla distribuzione dei dati per la variabile casuale <span class="math notranslate nohighlight">\(Y\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\text{bias}
&amp;= \mathbb{E}[\text{err}(Y)] \\
&amp;= \mathbb{E}[\hat{\theta}(Y) - \theta] \\
&amp;= \int_Y (\hat{\theta}(y) - \theta) \, \text{d}y.
\end{align}
\end{split}\]</div>
<p>In altre parole, il bias misura quanto, in media, la stima <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> si discosta dal valore vero <span class="math notranslate nohighlight">\(\theta\)</span> considerando tutte le possibili realizzazioni dei dati <span class="math notranslate nohighlight">\(Y\)</span>. Un bias nullo indica che lo stimatore è corretto in media, cioè non tende a sovrastimare o sottostimare il valore vero del parametro.</p>
</section>
<section id="stimatore-della-moda-posteriori">
<h3>Stimatore della Moda Posteriori<a class="headerlink" href="#stimatore-della-moda-posteriori" title="Link to this heading">#</a></h3>
<p>Uno stimatore popolare, sebbene non strettamente bayesiano, è la moda a posteriori, che rappresenta il valore del parametro <span class="math notranslate nohighlight">\(\theta\)</span> per cui la densità a posteriori è massima. Formalmente, è definita come:</p>
<div class="math notranslate nohighlight">
\[ \theta^* = \text{arg max}_\theta \ p(\theta \mid y). \]</div>
<p>La stima <span class="math notranslate nohighlight">\(\theta^*\)</span> è spesso chiamata stima MAP (Maximum A Posteriori). La moda a posteriori non è considerata un vero stimatore bayesiano perché non tiene conto dell’incertezza nella stessa misura in cui lo fanno altri metodi bayesiani. In altre parole, non minimizza una funzione di perdita basata sui valori veri dei parametri, ma cerca semplicemente il valore più probabile dato i dati osservati.</p>
</section>
<section id="caratteristiche-della-moda-posteriori">
<h3>Caratteristiche della Moda Posteriori<a class="headerlink" href="#caratteristiche-della-moda-posteriori" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Non considera l’incertezza</strong>: La stima MAP si focalizza solo sul valore più probabile della distribuzione a posteriori, senza tenere conto della variabilità dei dati.</p></li>
<li><p><strong>Massimo della densità a posteriori</strong>: La moda a posteriori rappresenta il punto in cui la densità a posteriori raggiunge il suo massimo.</p></li>
<li><p><strong>Possibili limitazioni</strong>: La stima MAP potrebbe non esistere in alcuni casi, come nei modelli in cui la densità cresce senza limiti. Questo può accadere, ad esempio, nei modelli bayesiani gerarchici o in distribuzioni semplici come la distribuzione esponenziale con parametro 1 (<span class="math notranslate nohighlight">\(\textrm{esponenziale}(1)\)</span>).</p></li>
</ul>
</section>
<section id="funzioni-di-perdita-e-proprieta-degli-stimatori">
<h3>Funzioni di Perdita e Proprietà degli Stimatori<a class="headerlink" href="#funzioni-di-perdita-e-proprieta-degli-stimatori" title="Link to this heading">#</a></h3>
<p>La media a posteriori è uno stimatore bayesiano popolare per due ragioni principali. Primo, è uno stimatore non distorto, il che significa che ha un bias nullo. Secondo, ha l’errore quadratico medio atteso minimo tra tutti gli stimatori non distorti. L’errore quadratico di una stima è definito come:</p>
<div class="math notranslate nohighlight">
\[ \text{err}^2(y) = \left(\hat{\theta}(y) - \theta\right)^2. \]</div>
<p>Questa è una funzione di perdita, che misura la differenza tra una stima <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> e il valore vero <span class="math notranslate nohighlight">\(\theta\)</span>. Tuttavia, la media a posteriori potrebbe non esistere se la distribuzione a posteriori ha code molto ampie, come accade nella distribuzione di Cauchy standard.</p>
</section>
<section id="proprieta-della-mediana-posteriori">
<h3>Proprietà della Mediana Posteriori<a class="headerlink" href="#proprieta-della-mediana-posteriori" title="Link to this heading">#</a></h3>
<p>La mediana a posteriori <span class="math notranslate nohighlight">\(\theta^+\)</span> ha tre proprietà interessanti:</p>
<ol class="arabic simple">
<li><p><strong>Sempre ben definita</strong>: La mediana a posteriori è sempre ben definita, anche per densità con poli o code molto ampie.</p></li>
<li><p><strong>Minimizzazione dell’errore assoluto atteso</strong>: La mediana minimizza l’errore assoluto atteso, il che la rende robusta.</p></li>
<li><p><strong>Robustezza ai valori anomali</strong>: La mediana è meno sensibile ai valori anomali rispetto alla media, perché minimizza l’errore assoluto anziché l’errore quadrato.</p></li>
</ol>
</section>
<section id="concentrazione-sulle-medie-a-posteriori">
<h3>Concentrazione sulle Medie a Posteriori<a class="headerlink" href="#concentrazione-sulle-medie-a-posteriori" title="Link to this heading">#</a></h3>
<p>In questa introduzione a Stan, ci concentreremo principalmente sulle medie a posteriori. La media a posteriori non solo fornisce una stima non distorta, ma minimizza anche l’errore quadratico medio atteso, rendendola uno strumento potente per l’inferenza bayesiana. Tuttavia, è importante essere consapevoli delle sue limitazioni, specialmente in presenza di distribuzioni a posteriori con code molto ampie.</p>
</section>
<section id="errore-markov-chain-monte-carlo-e-dimensione-del-campione-effettivo">
<h3>Errore (Markov Chain) Monte Carlo e Dimensione del Campione Effettivo<a class="headerlink" href="#errore-markov-chain-monte-carlo-e-dimensione-del-campione-effettivo" title="Link to this heading">#</a></h3>
<p>Quando utilizziamo un campionatore di catene di Markov per stimare parametri, otteniamo una sequenza di campioni casuali. Questa sequenza è essa stessa una variabile casuale, perché è composta da molte variabili casuali. A causa di questa natura casuale, ogni esecuzione del campionatore può produrre risultati leggermente diversi, introducendo quello che è noto come errore Monte Carlo.</p>
<p>L’errore Monte Carlo è l’errore introdotto dal fatto che utilizziamo solo un numero finito di campioni (<span class="math notranslate nohighlight">\( M \)</span>) per stimare i parametri. Questo tipo di errore si verifica perché, con un numero limitato di campioni, non possiamo catturare perfettamente l’intera distribuzione a posteriori.</p>
<section id="errore-standard-di-monte-carlo-mcmc">
<h4>Errore Standard di Monte Carlo (MCMC)<a class="headerlink" href="#errore-standard-di-monte-carlo-mcmc" title="Link to this heading">#</a></h4>
<p>Stan riporta l’errore standard di Monte Carlo (MCMC) insieme alle stime della media. L’errore standard MCMC per un parametro scalare <span class="math notranslate nohighlight">\( \theta_d \)</span> è definito come:</p>
<div class="math notranslate nohighlight">
\[
\text{mcmc-se} = \frac{\textrm{sd}[\Theta_d \mid Y = y]}{\sqrt{N^{\text{eff}}}},
\]</div>
<p>dove:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\text{sd}[\Theta_d \mid Y = y]\)</span> è la deviazione standard del parametro <span class="math notranslate nohighlight">\( \theta_d \)</span> nella distribuzione a posteriori.</p></li>
<li><p><span class="math notranslate nohighlight">\(N^{\text{eff}}\)</span> è la dimensione del campione effettivo, che riflette il numero di campioni indipendenti equivalenti ottenuti dal campionatore.</p></li>
</ul>
</section>
<section id="dimensione-del-campione-effettivo">
<h4>Dimensione del Campione Effettivo<a class="headerlink" href="#dimensione-del-campione-effettivo" title="Link to this heading">#</a></h4>
<p>Nel classico teorema del limite centrale, la dimensione del campione (numero di estrazioni indipendenti) appare al posto di <span class="math notranslate nohighlight">\(N^{\text{eff}}\)</span>. Tuttavia, nel contesto delle catene di Markov, i campioni successivi sono correlati tra loro. La dimensione del campione effettivo (<span class="math notranslate nohighlight">\(N^{\text{eff}}\)</span>) tiene conto di questa correlazione e rappresenta il numero di estrazioni indipendenti che porterebbero allo stesso errore delle nostre estrazioni correlate.</p>
<p>La dimensione del campione effettivo per un campione di dimensione <span class="math notranslate nohighlight">\( M \)</span> è definita come:</p>
<div class="math notranslate nohighlight">
\[
N^{\text{eff}} = \frac{M}{\text{IAT}},
\]</div>
<p>dove <span class="math notranslate nohighlight">\(\text{IAT}\)</span> è il tempo di autocorrelazione integrata. Sebbene non sia definito formalmente qui, può essere considerato come l’intervallo tra estrazioni effettivamente indipendenti nella nostra catena di Markov. Se l’autocorrelazione è bassa, <span class="math notranslate nohighlight">\(\text{IAT}\)</span> sarà vicino a 1; se l’autocorrelazione è alta, <span class="math notranslate nohighlight">\(\text{IAT}\)</span> sarà molto più alto.</p>
<p>In sintesi, <span class="math notranslate nohighlight">\(N^{\text{eff}}\)</span> rappresenta il numero di estrazioni indipendenti che porterebbero allo stesso errore delle estrazioni correlate della nostra catena di Markov.</p>
<p>In conclusione, l’errore standard di Monte Carlo (MCMC) fornisce una misura di quanto varierebbero le nostre stime se ripetessimo il processo di campionamento più volte. È un indicatore dell’affidabilità delle nostre stime, tenendo conto della casualità introdotta dall’utilizzo di un numero finito di campioni. Conoscere questo errore ci aiuta a valutare la precisione delle nostre stime e a comprendere meglio l’incertezza associata ai risultati ottenuti tramite il campionamento di catene di Markov.</p>
</section>
</section>
</section>
<section id="stima-delle-probabilita-di-evento">
<h2>Stima delle Probabilità di Evento<a class="headerlink" href="#stima-delle-probabilita-di-evento" title="Link to this heading">#</a></h2>
<p>Laplace non cercava semplicemente un valore specifico per <span class="math notranslate nohighlight">\(\theta\)</span>. Voleva sapere qual era la probabilità che <span class="math notranslate nohighlight">\(\theta\)</span> fosse maggiore di <span class="math notranslate nohighlight">\(\frac{1}{2}\)</span> dopo aver osservato <span class="math notranslate nohighlight">\(y\)</span> nascite maschili su un totale di <span class="math notranslate nohighlight">\(N\)</span> nascite. In termini di teoria della probabilità, voleva stimare la probabilità di un evento.</p>
<p>Un sottoinsieme di parametri è noto come <em>evento</em>. Possiamo convertire le condizioni sui parametri in eventi. Ad esempio, la condizione <span class="math notranslate nohighlight">\(\theta &gt; \frac{1}{2}\)</span> può essere espressa come l’evento:</p>
<div class="math notranslate nohighlight">
\[ A = \left\{ \theta \in \Theta : \theta &gt; \frac{1}{2} \right\}. \]</div>
<p>Data una misura di probabilità, la probabilità dell’evento <span class="math notranslate nohighlight">\(A\)</span>, ossia che il tasso di nascite maschili sia superiore a quello delle nascite femminili, sarà ben definita. Poiché possiamo convertire le condizioni in eventi, possiamo trattarle come tali. Questo ci permette di scrivere <span class="math notranslate nohighlight">\(\Pr\!\left[\Theta &gt; \frac{1}{2} \, \big| \, N, y\right]\)</span> per indicare la probabilità dell’evento <span class="math notranslate nohighlight">\(\Theta &gt; \frac{1}{2}\)</span>.</p>
<section id="probabilita-di-evento-tramite-indicatori">
<h3>Probabilità di Evento tramite Indicatori<a class="headerlink" href="#probabilita-di-evento-tramite-indicatori" title="Link to this heading">#</a></h3>
<p>La <em>funzione indicatrice</em> <span class="math notranslate nohighlight">\(\textrm{I}\)</span> assegna il valore 1 alle proposizioni vere e 0 a quelle false. Ad esempio, <span class="math notranslate nohighlight">\(\textrm{I}(\theta &gt; \frac{1}{2}) = 1\)</span> se la proposizione <span class="math notranslate nohighlight">\(\theta &gt; \frac{1}{2}\)</span> è vera, cioè quando <span class="math notranslate nohighlight">\(\theta\)</span> è maggiore di un mezzo.</p>
<p>Le <em>probabilità di evento</em> sono definite come aspettative condizionali posteriori delle funzioni indicatrici per eventi:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\Pr[\Theta &gt; 0.5 \mid N, y]
&amp;= \mathbb{E}\!\left[\textrm{I}[\Theta &gt; 0.5] \mid N, y\right] \\
&amp;= \int_{\Theta} \textrm{I}(\theta &gt; 0.5) \cdot p(\theta \mid N, y) \, \textrm{d}\theta \\
&amp;\approx \frac{1}{M} \sum_{m=1}^M \textrm{I}(\theta^{(m)} &gt; 0.5),
\end{align}
\end{split}\]</div>
<p>dove <span class="math notranslate nohighlight">\(\theta^{(m)}\)</span> rappresenta i campioni dalla distribuzione a posteriori <span class="math notranslate nohighlight">\(p(\theta \mid N, y)\)</span> per <span class="math notranslate nohighlight">\(m = 1, 2, \ldots, M\)</span>.</p>
</section>
<section id="eventi-come-indicatori-in-stan">
<h3>Eventi come Indicatori in Stan<a class="headerlink" href="#eventi-come-indicatori-in-stan" title="Link to this heading">#</a></h3>
<p>In Stan, possiamo codificare direttamente il valore della funzione indicatrice e assegnarlo a una variabile nel blocco delle quantità generate.</p>
<div class="highlight-stan notranslate"><div class="highlight"><pre><span></span><span class="kn">generated quantities</span> <span class="p">{</span>
  <span class="kt">int</span><span class="o">&lt;</span><span class="k">lower</span><span class="p">=</span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="k">upper</span><span class="p">=</span><span class="mf">1</span><span class="o">&gt;</span> <span class="n">boys_gt_girls</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Le espressioni condizionali come <code class="docutils literal notranslate"><span class="pre">theta</span> <span class="pre">&gt;</span> <span class="pre">0.5</span></code> assumono il valore 1 se sono vere e 0 se sono false. In notazione matematica, scriveremmo <span class="math notranslate nohighlight">\(\textrm{I}(\theta &gt; 0.5)\)</span>, che assume valore 1 se <span class="math notranslate nohighlight">\(\theta &gt; 0.5\)</span> e 0 altrimenti. In Stan, come in C++, trattiamo <code class="docutils literal notranslate"><span class="pre">&gt;</span></code> come un operatore binario che restituisce 0 o 1, quindi scriviamo semplicemente <code class="docutils literal notranslate"><span class="pre">theta</span> <span class="pre">&gt;</span> <span class="pre">0.5</span></code>.</p>
</section>
<section id="la-risposta-alla-domanda-di-laplace">
<h3>La Risposta alla Domanda di Laplace<a class="headerlink" href="#la-risposta-alla-domanda-di-laplace" title="Link to this heading">#</a></h3>
<p>La media a posteriori della variabile <code class="docutils literal notranslate"><span class="pre">boys_gt_girls</span></code> è quindi la nostra stima per <span class="math notranslate nohighlight">\(\Pr[\theta &gt; 0.5 \mid N, y]\)</span>. È essenzialmente 1. Stampando a 15 cifre decimali, vediamo</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Pr_boy_gt_girl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">boys_gt_girls_draws</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;estimated Pr[boy more likely] = </span><span class="si">{</span><span class="n">Pr_boy_gt_girl</span><span class="si">:</span><span class="s2">.15f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>estimated Pr[boy more likely] = 1.000000000000000
</pre></div>
</div>
</div>
</div>
<p>Il valore 1 restituito come stima solleva l’importante problema della precisione numerica. Come possiamo vedere dall’istogramma, tutti i nostri campioni per <span class="math notranslate nohighlight">\(\theta\)</span> sono maggiori di <span class="math notranslate nohighlight">\(\frac{1}{2}\)</span>.</p>
<p>Laplace calcolò il risultato analiticamente, che è</p>
<div class="math notranslate nohighlight">
\[
\Pr\!\left[\Theta &gt; \frac{1}{2} \ \bigg| \ N, y\right] \approx 1 - 10^{-27}.
\]</div>
<p>Quindi avremmo bisogno di un numero astronomico di campioni a posteriori prima di generare un valore di <span class="math notranslate nohighlight">\(\theta\)</span> inferiore a <span class="math notranslate nohighlight">\(\frac{1}{2}\)</span>. Come detto, la risposta di 1.0 è molto vicina alla risposta vera e ben entro il nostro errore Monte Carlo atteso.</p>
</section>
<section id="statistiche-di-riepilogo-mcmc-da-stan">
<h3>Statistiche di riepilogo MCMC da Stan<a class="headerlink" href="#statistiche-di-riepilogo-mcmc-da-stan" title="Link to this heading">#</a></h3>
<p>Con Stan, possiamo ottenere un riepilogo completo della variabile <span class="math notranslate nohighlight">\(\theta\)</span> nella distribuzione a posteriori. Per fare ciò, basta chiamare la funzione <code class="docutils literal notranslate"><span class="pre">.summary()</span></code> sul campione. Questo riepilogo include tutte le statistiche rilevanti.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">sig_figs</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Mean</th>
      <th>MCSE</th>
      <th>StdDev</th>
      <th>5%</th>
      <th>50%</th>
      <th>95%</th>
      <th>N_Eff</th>
      <th>N_Eff/s</th>
      <th>R_hat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>lp__</th>
      <td>-149000.000</td>
      <td>0.004770</td>
      <td>6.720000e-01</td>
      <td>-149000.00</td>
      <td>-149000.000</td>
      <td>-149000.000</td>
      <td>19800.0</td>
      <td>83400.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>theta</th>
      <td>0.512</td>
      <td>0.000009</td>
      <td>1.090000e-03</td>
      <td>0.51</td>
      <td>0.512</td>
      <td>0.513</td>
      <td>13700.0</td>
      <td>57600.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>boys_gt_girls</th>
      <td>1.000</td>
      <td>NaN</td>
      <td>9.380000e-14</td>
      <td>1.00</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>L’istruzione <code class="docutils literal notranslate"><span class="pre">print(sample.diagnose())</span></code> in Stan viene utilizzata per eseguire una diagnosi completa del campionamento MCMC. Questa funzione fornisce una serie di statistiche diagnostiche che aiutano a valutare la qualità e la convergenza del campionamento.</p>
<p>Questi sono alcuni degli aspetti che possono essere diagnosticati:</p>
<ol class="arabic simple">
<li><p><strong>Convergenza</strong>: La diagnosi verifica se le catene di Markov sono convergenti, ad esempio controllando il valore di <span class="math notranslate nohighlight">\(\hat{R}\)</span>. Un valore di <span class="math notranslate nohighlight">\(\hat{R}\)</span> vicino a 1 indica che le catene sono ben mescolate e convergenti.</p></li>
<li><p><strong>Autocorrelazione</strong>: Fornisce informazioni sull’autocorrelazione delle catene, che può influire sull’efficienza del campionamento. Bassa autocorrelazione è desiderabile per ottenere campioni indipendenti.</p></li>
<li><p><strong>Efficienza del campionamento</strong>: Viene calcolata la dimensione del campione effettivo (<span class="math notranslate nohighlight">\(N_{\text{eff}}\)</span>), che indica quanti campioni indipendenti equivarrebbero ai campioni correlati ottenuti.</p></li>
<li><p><strong>Varianza e Deviazione Standard</strong>: Viene riportata la varianza e la deviazione standard dei campioni, aiutando a comprendere la distribuzione a posteriori del parametro.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">diagnose</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Processing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8yv13mzb/sex-ratiok33ghb34/sex-ratio-20240616094604_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8yv13mzb/sex-ratiok33ghb34/sex-ratio-20240616094604_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8yv13mzb/sex-ratiok33ghb34/sex-ratio-20240616094604_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8yv13mzb/sex-ratiok33ghb34/sex-ratio-20240616094604_4.csv

Checking sampler transitions treedepth.
Treedepth satisfactory for all transitions.

Checking sampler transitions for divergences.
No divergent transitions found.

Checking E-BFMI - sampler transitions HMC potential energy.
E-BFMI satisfactory.

Effective sample size satisfactory.

Split R-hat values satisfactory all parameters.

Processing complete, no problems detected.
</pre></div>
</div>
</div>
</div>
<p>Un grafico con le tracce si ottiene nel modo seguente:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;theta&quot;</span><span class="p">),</span> <span class="n">combined</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/8990e6c33b1de580ad9bf03e78443dac38130952e0bbcfb57774bf339b06e326.png"><img alt="../_images/8990e6c33b1de580ad9bf03e78443dac38130952e0bbcfb57774bf339b06e326.png" src="../_images/8990e6c33b1de580ad9bf03e78443dac38130952e0bbcfb57774bf339b06e326.png" style="width: 1211px; height: 211px;" /></a>
</div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="riscaldamento-e-monitoraggio-della-convergenza">
<h1>Riscaldamento e monitoraggio della convergenza<a class="headerlink" href="#riscaldamento-e-monitoraggio-della-convergenza" title="Link to this heading">#</a></h1>
<p>Quando si eseguono catene di Markov, è importante assicurarsi che i campioni siano approssimativamente estratti dalla distribuzione a posteriori. Un modo standard per monitorare la convergenza è avviare più catene di Markov con inizializzazioni diverse (idealmente scelte da una distribuzione iniziale diffusa) e misurare se stanno producendo campioni dalla stessa distribuzione.</p>
<section id="riscaldamento">
<h2>Riscaldamento<a class="headerlink" href="#riscaldamento" title="Link to this heading">#</a></h2>
<p>Durante le fasi iniziali di riscaldamento, Stan cerca di trovare la regione di alta probabilità da cui campionare, adattare una buona dimensione del passo e stimare la varianza a posteriori. La varianza stimata viene utilizzata per migliorare l’efficienza del campionatore, un processo chiamato «precondizionamento». Precondizionare significa ridimensionare i parametri per rendere il campionamento più efficiente.</p>
<p>Stan può anche stimare una matrice di covarianza completa, che rappresenta le relazioni tra tutti i parametri. Utilizzando questa matrice, Stan può effettuare rotazioni e ridimensionamenti dei parametri per campionare in modo più efficace. In questo contesto, «rotazione e scalatura» si riferiscono alla trasformazione dei parametri in una nuova base (rotazione) e alla regolazione delle loro scale (scalatura) per facilitare il campionamento, rendendolo più rapido e affidabile. Per ulteriori dettagli su questi processi, si può fare riferimento a Neal (2011).</p>
<p>Il riscaldamento converge quando la dimensione del passo e le stime della covarianza a posteriori diventano stabili. Con più catene, è possibile verificare che tutte convergano verso una dimensione del passo e una stima della covarianza simili. A meno che non ci siano problemi, generalmente non misuriamo la convergenza dell’adattamento, ma piuttosto se otteniamo campioni a posteriori ragionevoli dopo il riscaldamento.</p>
<p>Durante la fase di riscaldamento, Stan non produce una catena di Markov coerente perché utilizza la memoria per adattarsi alle condizioni del modello. Questo adattamento serve a trovare i migliori parametri di campionamento. Tuttavia, una volta terminato il riscaldamento e iniziata la fase di campionamento, Stan inizia a produrre una vera e propria catena di Markov.</p>
<p>Le nostre analisi a posteriori si baseranno esclusivamente sui campioni generati durante questa fase di campionamento, non sui campioni raccolti durante il riscaldamento. È comunque possibile salvare ed esaminare i campioni del riscaldamento per comprendere meglio come il processo di adattamento è avvenuto e se ci sono stati problemi.</p>
</section>
<section id="riduzione-potenziale-della-scala-e-widehat-r">
<h2>Riduzione potenziale della scala e <span class="math notranslate nohighlight">\(\widehat{R}\)</span><a class="headerlink" href="#riduzione-potenziale-della-scala-e-widehat-r" title="Link to this heading">#</a></h2>
<p>Stan utilizza la statistica di <em>riduzione potenziale della scala</em> <span class="math notranslate nohighlight">\(\widehat{R}\)</span> (pronunciata «R hat»). Dato un insieme di catene di Markov, Stan divide ciascuna di esse a metà per assicurarsi che la prima metà e la seconda metà della catena concordino, quindi calcola le varianze all’interno di ciascuna catena e tra tutte le catene e le confronta. La statistica <span class="math notranslate nohighlight">\(\widehat{R}\)</span> converge a 1 quando le catene di Markov convergono alla stessa distribuzione.</p>
</section>
<section id="quante-catene-per-quanto-tempo">
<h2>Quante catene per quanto tempo?<a class="headerlink" href="#quante-catene-per-quanto-tempo" title="Link to this heading">#</a></h2>
<p>Una semplice regola empirica consiste nell’eseguire quattro catene finché <span class="math notranslate nohighlight">\(\widehat{R} \leq 1.01\)</span> e la dimensione campionaria effettiva (ESS) è superiore a 100. La raccomandazione di avere una dimensione campionaria effettiva di «soli» 100 è dovuta al fatto che questo valore implica un errore standard pari a <span class="math notranslate nohighlight">\(\frac{1}{10}\)</span> della deviazione standard. Poiché la deviazione standard a posteriori rappresenta l’incertezza residua, calcolare le medie con una precisione maggiore è raramente utile.</p>
<p>Il modo più semplice per ottenere <span class="math notranslate nohighlight">\(\widehat{R} \leq 1.01\)</span> e <span class="math notranslate nohighlight">\(N_{\text{eff}} &gt; 100\)</span> è iniziare con 100 iterazioni di riscaldamento e 100 iterazioni di campionamento. Se i valori di <span class="math notranslate nohighlight">\(\widehat{R}\)</span> sono troppo alti o se la dimensione campionaria effettiva è troppo bassa, raddoppiare il numero di iterazioni di riscaldamento e di campionamento e riprovare. Eseguire più iterazioni di riscaldamento è importante perché il campionamento non sarà efficiente se il riscaldamento non è convergente. Utilizzare lo stesso numero di iterazioni di riscaldamento e di campionamento può comportare un costo massimo doppio rispetto alle impostazioni ottimali, che non sono note in anticipo.</p>
<p>Anche se si utilizzano più di quattro catene, è necessario assicurarsi che la dimensione campionaria effettiva sia almeno 25 per catena. Non è tanto per l’inferenza, quanto per garantire la fiducia nello stimatore della dimensione campionaria effettiva, che non è affidabile se è molto inferiore. Un modo per verificare l’adeguatezza dello stimatore ESS è raddoppiare il numero di campioni e assicurarsi che anche l’ESS raddoppi. Se ciò non accade, significa che la prima stima dell’ESS non è affidabile.</p>
</section>
<section id="esecuzione-delle-catene-contemporaneamente">
<h2>Esecuzione delle catene contemporaneamente<a class="headerlink" href="#esecuzione-delle-catene-contemporaneamente" title="Link to this heading">#</a></h2>
<p>È possibile impostare il numero di catene da eseguire utilizzando l’argomento <code class="docutils literal notranslate"><span class="pre">chains</span></code> del metodo <code class="docutils literal notranslate"><span class="pre">sample()</span></code>. Inoltre, è possibile controllare quante catene possono essere eseguite contemporaneamente con l’argomento <code class="docutils literal notranslate"><span class="pre">parallel_cores</span></code> (che per default è impostato su 1, ovvero esecuzione sequenziale).</p>
<p>Se il numero massimo di catene parallele è impostato troppo basso, le risorse della CPU potrebbero non essere sfruttate appieno. Al contrario, se è impostato troppo alto, la CPU o la memoria potrebbero diventare il collo di bottiglia, rallentando le prestazioni complessive rispetto all’esecuzione con un numero inferiore di catene parallele.</p>
<p>In progetti personali sul nostro hardware, l’obiettivo è solitamente ottenere la massima dimensione campionaria effettiva nel minor tempo possibile. Tuttavia, a volte è necessario lasciare abbastanza potenza di elaborazione per continuare a lavorare su altre attività come documenti, email, ecc.</p>
<section id="matrici-vettori-o-array-in-stan">
<h3>Matrici, Vettori o Array in Stan<a class="headerlink" href="#matrici-vettori-o-array-in-stan" title="Link to this heading">#</a></h3>
<p>Stan offre vari tipi di dati per gestire operazioni di algebra lineare e per definire strutture di dati più generali come gli array. Capire le differenze tra questi tipi è fondamentale per sapere cosa possiamo fare con essi e per ottimizzare la velocità di esecuzione del nostro modello.</p>
<ol class="arabic">
<li><p><strong>Tipi di base per l’algebra lineare</strong>:</p>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">vector</span></code></strong>: un vettore colonna di dimensione N.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">row_vector</span></code></strong>: un vettore riga di dimensione N.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">matrix</span></code></strong>: una matrice di dimensioni N1 × N2.</p></li>
</ul>
</li>
<li><p><strong>Array</strong>:</p>
<ul class="simple">
<li><p>Gli array possono essere creati con qualsiasi tipo di elemento e possono avere più dimensioni. Ad esempio:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">array[N]</span> <span class="pre">real</span> <span class="pre">a;</span></code> definisce un array unidimensionale di numeri reali.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">array[N1,</span> <span class="pre">N2]</span> <span class="pre">real</span> <span class="pre">m;</span></code> definisce un array bidimensionale di numeri reali.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Intercambiabilità e limitazioni</strong>:</p>
<ul class="simple">
<li><p>Anche se possiamo usare sia <code class="docutils literal notranslate"><span class="pre">vector</span></code> che <code class="docutils literal notranslate"><span class="pre">array</span></code> per contenitori unidimensionali, l’algebra matriciale (come la moltiplicazione) è definita solo per vettori e matrici, non per array.</p></li>
<li><p>Alcune funzioni, come <code class="docutils literal notranslate"><span class="pre">normal_lpdf</span></code>, accettano sia vettori che array.</p></li>
</ul>
</li>
<li><p><strong>Esempi pratici</strong>:</p>
<ul>
<li><p>Quando definiamo una media (<code class="docutils literal notranslate"><span class="pre">mu</span></code>) come somma di un parametro (<code class="docutils literal notranslate"><span class="pre">alpha</span></code>) e il prodotto di un vettore di carichi (<code class="docutils literal notranslate"><span class="pre">c_load</span></code>) con un coefficiente (<code class="docutils literal notranslate"><span class="pre">beta</span></code>), dobbiamo usare i vettori:</p>
<div class="highlight-stan notranslate"><div class="highlight"><pre><span></span><span class="kt">vector</span><span class="p">[</span><span class="n">N</span><span class="p">]</span> <span class="n">mu</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">+</span> <span class="n">c_load</span> <span class="o">*</span> <span class="n">beta</span><span class="p">;</span>
</pre></div>
</div>
</li>
<li><p>Per utilizzare un generatore di numeri casuali (_rng) in modo vettoriale, dobbiamo usare un array:</p>
<div class="highlight-stan notranslate"><div class="highlight"><pre><span></span><span class="kt">array</span><span class="p">[</span><span class="n">N</span><span class="p">]</span> <span class="kt">real</span> <span class="n">p_size_pred</span> <span class="o">=</span> <span class="nb">normal_rng</span><span class="p">(</span><span class="n">alpha</span> <span class="o">+</span> <span class="n">c_load</span> <span class="o">*</span> <span class="n">beta</span><span class="p">,</span> <span class="n">sigma</span><span class="p">);</span>
</pre></div>
</div>
</li>
</ul>
</li>
</ol>
<p>In sintesi, la scelta tra <code class="docutils literal notranslate"><span class="pre">vector</span></code>, <code class="docutils literal notranslate"><span class="pre">row_vector</span></code>, <code class="docutils literal notranslate"><span class="pre">matrix</span></code> e <code class="docutils literal notranslate"><span class="pre">array</span></code> dipende dalle operazioni che si desidera eseguire e dalle specifiche esigenze del modello. Scegliere il tipo di dato appropriato permette di sfruttare appieno le funzionalità di Stan e ottimizzare le prestazioni del modello.</p>
</section>
</section>
<section id="modello-di-esecuzione-di-stan">
<h2>Modello di esecuzione di Stan<a class="headerlink" href="#modello-di-esecuzione-di-stan" title="Link to this heading">#</a></h2>
<p>I programmi Stan sono composti da diversi blocchi. Ecco una panoramica di ciascun blocco, di quando viene eseguito e di cosa fa. Nessuno di questi blocchi è obbligatorio, ma se presenti, devono seguire quest’ordine.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p><strong>Blocco</strong></p></th>
<th class="head text-left"><p><strong>Quando viene eseguito</strong></p></th>
<th class="head text-left"><p><strong>Cosa fa</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">functions</span></code></p></td>
<td class="text-left"><p>secondo necessità</p></td>
<td class="text-left"><p>Definizione delle funzioni create dall’utente</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">data</span></code></p></td>
<td class="text-left"><p>una volta</p></td>
<td class="text-left"><p>Lettura dei dati per costruire il modello</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">transformed</span> <span class="pre">data</span></code></p></td>
<td class="text-left"><p>una volta</p></td>
<td class="text-left"><p>Definizione dei dati trasformati</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">parameters</span></code></p></td>
<td class="text-left"><p>una volta / densità logaritmica</p></td>
<td class="text-left"><p>Definizione dei parametri con i relativi vincoli</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">transformed</span> <span class="pre">parameters</span></code></p></td>
<td class="text-left"><p>una volta / densità logaritmica</p></td>
<td class="text-left"><p>Definizione dei parametri trasformati</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">model</span></code></p></td>
<td class="text-left"><p>una volta / densità logaritmica</p></td>
<td class="text-left"><p>Valutazione della densità logaritmica del modello</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">generated</span> <span class="pre">quantities</span></code></p></td>
<td class="text-left"><p>una volta / per estrazione</p></td>
<td class="text-left"><p>Definizione delle quantità generate</p></td>
</tr>
</tbody>
</table>
</div>
<section id="dati-e-dati-trasformati">
<h3>Dati e dati trasformati<a class="headerlink" href="#dati-e-dati-trasformati" title="Link to this heading">#</a></h3>
<p>Il blocco <em>data</em> contiene solo le dichiarazioni delle variabili. Queste variabili vengono lette una volta durante il caricamento dei dati.</p>
<p>Il blocco <em>transformed data</em> contiene sia dichiarazioni che definizioni delle variabili. Questo blocco serve per calcolare nuove variabili a partire dai dati originali, come predittori standardizzati o costanti per i priori. Può anche includere la generazione pseudocasuale di numeri. Viene eseguito una volta, dopo la lettura dei dati, per definire le nuove variabili trasformate.</p>
<p>In ogni blocco, tutte le variabili devono avere il loro tipo e dimensione dichiarati (che possono dipendere dai dati). Le variabili locali all’interno dei blocchi, invece, sono dichiarate senza specificare la dimensione.</p>
<p>I vincoli sulle variabili nel blocco <em>data</em> vengono controllati mentre i dati vengono letti, mentre quelli nel blocco <em>transformed data</em> vengono verificati alla fine dell’esecuzione del blocco. Se ci sono violazioni dei vincoli nei dati o nei dati trasformati, si genera un’eccezione che interrompe l’esecuzione del programma.</p>
<p>Le variabili definite nel blocco <em>transformed data</em> possono essere assegnate una volta, ma non possono essere riassegnate dopo l’esecuzione del blocco.</p>
</section>
<section id="parametri-e-parametri-trasformati">
<h3>Parametri e Parametri Trasformati<a class="headerlink" href="#parametri-e-parametri-trasformati" title="Link to this heading">#</a></h3>
<p>Il blocco <em>parameters</em> serve a dichiarare le variabili su cui è basato il modello. In pratica, si tratta di elencare i parametri che il modello utilizzerà, specificandone le dimensioni. Quando il blocco viene eseguito, vengono forniti i valori concreti di questi parametri.</p>
<p>I vincoli sui parametri sono utilizzati per trasformare le variabili vincolate in variabili non vincolate. Ad esempio, se una variabile ha un vincolo <code class="docutils literal notranslate"><span class="pre">lower=0</span></code> (cioè deve essere maggiore o uguale a zero), questa variabile viene trasformata usando il logaritmo per renderla non vincolata. È essenziale dichiarare tutti i vincoli necessari sui parametri affinché il modello funzioni correttamente su tutto lo spazio dei parametri.</p>
<p>Il blocco <em>transformed parameters</em> permette di definire nuove variabili che sono funzioni dei parametri originali e dei dati. Gli utenti possono creare le loro trasformazioni dei parametri in questo blocco. I vincoli su queste nuove variabili vengono verificati alla fine dell’esecuzione del blocco. Se questi vincoli non sono rispettati, viene generata un’eccezione che di solito porta al rifiuto della proposta corrente.</p>
<p>Le variabili dichiarate nel blocco <em>parameters</em> sono simili agli argomenti di una funzione: la funzione di densità logaritmica del programma Stan prende questi parametri come input. Quindi, i valori dei parametri vengono sempre forniti dall’esterno del programma Stan.</p>
<p>Dopo l’esecuzione del blocco <em>transformed parameters</em>, le variabili dichiarate in esso non possono essere modificate ulteriormente.</p>
<p>La differenza principale tra le variabili dichiarate come locali nel blocco <em>model</em> e quelle nel blocco <em>transformed parameters</em> è che le variabili trasformate vengono stampate e sono disponibili anche nel blocco <em>generated quantities</em>.</p>
</section>
<section id="modello">
<h3>Modello<a class="headerlink" href="#modello" title="Link to this heading">#</a></h3>
<p>Lo scopo del blocco <em>model</em> è definire la funzione che calcola la densità logaritmica del modello. Una volta caricati i dati, il compito principale di un programma Stan è fornire questa funzione di densità logaritmica non normalizzata sui parametri non vincolati. Algoritmi esterni, come ottimizzatori, campionatori o metodi di inferenza variazionale, forniranno i valori dei parametri non vincolati per la valutazione.</p>
<p>Il valore della densità logaritmica non normalizzata calcolato dal modello viene conservato in una variabile chiamata <code class="docutils literal notranslate"><span class="pre">target</span></code>. Le densità posteriori (che ci interessano) sono calcolate moltiplicando i fattori delle funzioni di densità o massa di probabilità. In termini logaritmici, questo equivale ad aggiungere i termini delle funzioni di densità o massa non normalizzate alla <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
<p>L’accumulatore <code class="docutils literal notranslate"><span class="pre">target</span></code> parte da zero e viene incrementato durante l’esecuzione del programma Stan. Come accennato prima, la prima cosa che questa funzione di densità logaritmica non normalizzata fa è trasformare i parametri vincolati in non vincolati e aggiungere un aggiustamento logaritmico per il cambio di variabili alla <code class="docutils literal notranslate"><span class="pre">target</span></code>. Questo processo è automatico e fornisce i valori dei parametri trasformati al codice che verrà eseguito successivamente nel blocco <em>model</em>.</p>
<p>La densità logaritmica accumulata in <code class="docutils literal notranslate"><span class="pre">target</span></code> può essere incrementata direttamente, come mostrato nell’esempio seguente:</p>
<div class="highlight-stan notranslate"><div class="highlight"><pre><span></span><span class="k">target +=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">x</span><span class="o">^</span><span class="mf">2</span><span class="p">;</span>
</pre></div>
</div>
<p>Anche se non è possibile usare direttamente <code class="docutils literal notranslate"><span class="pre">target</span></code> come variabile, il suo valore attuale può essere recuperato tramite la funzione <code class="docutils literal notranslate"><span class="pre">target()</span></code>, utile per il debugging.</p>
<p>Le istruzioni di campionamento sono una scorciatoia per incrementare <code class="docutils literal notranslate"><span class="pre">target</span></code>. Ad esempio, l’istruzione</p>
<div class="highlight-stan notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">~</span><span class="w"> </span><span class="nb">normal</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">1</span><span class="p">);</span>
</pre></div>
</div>
<p>è equivalente a</p>
<div class="highlight-stan notranslate"><div class="highlight"><pre><span></span><span class="k">target +=</span> <span class="nb">normal_lupdf</span><span class="p">(</span><span class="n">x</span> <span class="p">|</span> <span class="mf">0</span><span class="p">,</span> <span class="mf">1</span><span class="p">);</span>
</pre></div>
</div>
<p>Qui, <code class="docutils literal notranslate"><span class="pre">_lupdf</span></code> indica che si tratta di una funzione di densità di probabilità logaritmica non normalizzata.</p>
<p>La barra verticale <code class="docutils literal notranslate"><span class="pre">|</span></code> è utilizzata per separare le variabili osservate dai parametri. La notazione <code class="docutils literal notranslate"><span class="pre">lpdf</span></code> denota una funzione di densità di probabilità logaritmica, mentre <code class="docutils literal notranslate"><span class="pre">lpmf</span></code> indica una funzione di massa di probabilità logaritmica. Le varianti <code class="docutils literal notranslate"><span class="pre">lupdf</span></code> e <code class="docutils literal notranslate"><span class="pre">lupmf</span></code> sono le loro controparti non normalizzate, che possono omettere le costanti di normalizzazione che non dipendono dai parametri. A meno che non siano necessarie, ad esempio in un componente di un modello di mescolanza, è più efficiente usare le forme <code class="docutils literal notranslate"><span class="pre">lupdf</span></code> e <code class="docutils literal notranslate"><span class="pre">lupmf</span></code> incrementando direttamente <code class="docutils literal notranslate"><span class="pre">target</span></code> o tramite istruzioni di campionamento.</p>
</section>
<section id="quantita-generate">
<h3>Quantità generate<a class="headerlink" href="#quantita-generate" title="Link to this heading">#</a></h3>
<p>Il blocco <em>generated quantities</em> viene eseguito una volta per ogni campione generato, anziché ogni volta che viene calcolata la densità logaritmica. Con algoritmi come il campionamento Monte Carlo Hamiltoniano, ogni campione può richiedere diverse valutazioni della densità logaritmica.</p>
<p>Un vantaggio delle quantità generate è che vengono calcolate utilizzando numeri in virgola mobile a doppia precisione, il che le rende molto efficienti. Questo blocco può anche utilizzare numeri pseudocasuali. I vincoli sui dati generati vengono verificati alla fine del blocco, ma eventuali errori non causano il rigetto del campione, solo possibili avvertimenti o valori non definiti (NaN).</p>
<p>Le quantità generate non influenzano il calcolo della densità logaritmica, ma sono comunque una parte importante del modello statistico. Sono utilizzate principalmente per fare previsioni su nuovi dati, basandosi sui parametri stimati dal modello. Questo processo è noto come inferenza predittiva posteriore. In altre parole, ci permette di fare previsioni su nuovi dati utilizzando i valori dei parametri generati dal modello.</p>
<p>Esempi di utilizzo delle quantità generate includono la previsione di nuovi valori o il calcolo di statistiche derivate dai parametri stimati. Le quantità generate offrono un modo per esplorare ulteriormente il comportamento del modello e fare inferenze utili dai dati simulati.</p>
</section>
</section>
<section id="informazioni-sull-ambiente-di-sviluppo">
<h2>Informazioni sull’Ambiente di Sviluppo<a class="headerlink" href="#informazioni-sull-ambiente-di-sviluppo" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> watermark
<span class="o">%</span><span class="k">watermark</span> -n -u -v -iv -w -m -p cmdstanpy
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Last updated: Sun Jun 16 2024

Python implementation: CPython
Python version       : 3.12.3
IPython version      : 8.25.0

cmdstanpy: 1.2.3

Compiler    : Clang 16.0.6 
OS          : Darwin
Release     : 23.4.0
Machine     : arm64
Processor   : arm
CPU cores   : 8
Architecture: 64bit

cmdstanpy : 1.2.3
pandas    : 2.2.2
matplotlib: 3.8.4
logging   : 0.5.1.2
numpy     : 1.26.4
arviz     : 0.18.0

Watermark: 2.4.3
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter_4"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="10_metropolis.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">precedente</p>
        <p class="prev-next-title">Monte Carlo a Catena di Markov</p>
      </div>
    </a>
    <a class="right-next"
       href="E_stan_beta_binomial.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">successivo</p>
        <p class="prev-next-title">✏️ Esercizio</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contenuti
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Introduzione a Stan</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparazione-del-notebook">Preparazione del Notebook</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Introduzione a Stan</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#metodi-monte-carlo-a-catena-di-markov-mcmc">Metodi Monte Carlo a Catena di Markov (MCMC)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stan-e-la-programmazione-probabilistica">Stan e la Programmazione Probabilistica</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#struttura-di-un-programma-stan">Struttura di un Programma Stan</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#esecuzione-di-un-programma-stan">Esecuzione di un Programma Stan</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulazione-avanti-e-problema-inverso">Simulazione Avanti e Problema Inverso</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#simulazione-avanti">Simulazione Avanti</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#esempio-di-simulazione-avanti">Esempio di Simulazione Avanti</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#il-problema-inverso">Il Problema Inverso</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#un-primo-programma-in-stan">Un Primo Programma in Stan</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generazione-di-dati-casuali">Generazione di Dati Casuali</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#organizzazione-di-un-programma-stan">Organizzazione di un Programma Stan</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tipi-di-variabili-in-stan">Tipi di Variabili in Stan</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vincoli-sui-tipi">Vincoli sui Tipi</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#esecuzione-del-programma-stan">Esecuzione del Programma Stan</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#costruzione-del-modello">Costruzione del Modello</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interfaccia-python">Interfaccia Python</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estrazione-dei-risultati">Estrazione dei Risultati</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#integrazione-monte-carlo">Integrazione Monte Carlo</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#esempio-stima-di-pi">Esempio: Stima di <span class="math notranslate nohighlight">\(\pi\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#codice-stan">Codice Stan</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#media-campionaria-dell-indicatore">Media Campionaria dell’Indicatore</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compilazione-e-campionamento">Compilazione e Campionamento</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metodi-monte-carlo-a-catena-di-markov">Metodi Monte Carlo a Catena di Markov</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#catene-di-markov">Catene di Markov</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#esempio-di-catena-di-markov">Esempio di Catena di Markov</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#il-problema-inverso-delle-nascite-di-laplace">Il Problema Inverso delle Nascite di Laplace</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#storia-e-applicazione">Storia e Applicazione</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modello-di-laplace">Modello di Laplace</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#distribuzione-a-priori">Distribuzione a Priori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#distribuzione-a-posteriori">Distribuzione a Posteriori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementazione-in-stan">Implementazione in Stan</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#campionare-dalla-distribuzione-a-posteriori">Campionare dalla Distribuzione a Posteriori</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compilazione-del-codice-stan">Compilazione del Codice Stan</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stime-puntuali-bayesiane">Stime Puntuali Bayesiane</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stimatore-della-media-posteriori">Stimatore della Media Posteriori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stimatore-della-mediana-posteriori-quantili-e-intervalli">Stimatore della Mediana Posteriori, Quantili e Intervalli</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#quantili-e-intervalli-di-credibilita">Quantili e Intervalli di Credibilità</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#quantili">Quantili</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#intervalli-posteriori">Intervalli Posteriori</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#errore-di-stima-e-bias">Errore di Stima e Bias</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stimatore-della-moda-posteriori">Stimatore della Moda Posteriori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#caratteristiche-della-moda-posteriori">Caratteristiche della Moda Posteriori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#funzioni-di-perdita-e-proprieta-degli-stimatori">Funzioni di Perdita e Proprietà degli Stimatori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#proprieta-della-mediana-posteriori">Proprietà della Mediana Posteriori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#concentrazione-sulle-medie-a-posteriori">Concentrazione sulle Medie a Posteriori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#errore-markov-chain-monte-carlo-e-dimensione-del-campione-effettivo">Errore (Markov Chain) Monte Carlo e Dimensione del Campione Effettivo</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#errore-standard-di-monte-carlo-mcmc">Errore Standard di Monte Carlo (MCMC)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#dimensione-del-campione-effettivo">Dimensione del Campione Effettivo</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stima-delle-probabilita-di-evento">Stima delle Probabilità di Evento</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilita-di-evento-tramite-indicatori">Probabilità di Evento tramite Indicatori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#eventi-come-indicatori-in-stan">Eventi come Indicatori in Stan</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#la-risposta-alla-domanda-di-laplace">La Risposta alla Domanda di Laplace</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#statistiche-di-riepilogo-mcmc-da-stan">Statistiche di riepilogo MCMC da Stan</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#riscaldamento-e-monitoraggio-della-convergenza">Riscaldamento e monitoraggio della convergenza</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#riscaldamento">Riscaldamento</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#riduzione-potenziale-della-scala-e-widehat-r">Riduzione potenziale della scala e <span class="math notranslate nohighlight">\(\widehat{R}\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quante-catene-per-quanto-tempo">Quante catene per quanto tempo?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#esecuzione-delle-catene-contemporaneamente">Esecuzione delle catene contemporaneamente</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#matrici-vettori-o-array-in-stan">Matrici, Vettori o Array in Stan</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modello-di-esecuzione-di-stan">Modello di esecuzione di Stan</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dati-e-dati-trasformati">Dati e dati trasformati</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parametri-e-parametri-trasformati">Parametri e Parametri Trasformati</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modello">Modello</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#quantita-generate">Quantità generate</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#informazioni-sull-ambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
Di Corrado Caudek
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>