
<!DOCTYPE html>


<html lang="it" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Monte Carlo a Catena di Markov &#8212; ds4p</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css?v=ca93fcec" />
    <link rel="stylesheet" type="text/css" href="../_static/exercise.css?v=20b57f81" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=3ee479438cf8b5e0d341"></script>

    <script src="../_static/documentation_options.js?v=8d586cc4"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="../_static/translations.js?v=0173e136"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-TP2WLBPMS6"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-TP2WLBPMS6');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-TP2WLBPMS6');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter_4/10_metropolis';</script>
    <link rel="canonical" href="https://ccaudek.github.io/ds4p/chapter_4/10_metropolis.html" />
    <link rel="icon" href="../_static/increasing.png"/>
    <link rel="index" title="Indice" href="../genindex.html" />
    <link rel="search" title="Cerca" href="../search.html" />
    <link rel="next" title="Introduzione a Stan" href="15_stan_beta_binomial.html" />
    <link rel="prev" title="L’influenza della distribuzione a priori" href="06_balance-prior-post.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="it"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="ds4p - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="ds4p - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Cerca" aria-label="Cerca" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Cerca</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Benvenuti
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_1/introduction_chapter_1.html">Python</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/00_prelims.html">Preliminari</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/01_python_1.html">Python (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/02_python_2.html">Python (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_python.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/03_numpy.html">NumPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_numpy.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/04_pandas.html">Pandas (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/05_pandas_aggregate.html">Pandas (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/06_pandas_functions.html">Pandas (3)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_pandas.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/07_matplotlib.html">Matplotlib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/08_seaborn.html">Seaborn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_matplotlib.html">✏️ Esercizi</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_2/introduction_chapter_2.html">Statistica descrittiva</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/00_scientific_method.html">La scienza dei dati e il metodo scientifico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/01_key_notions.html">Concetti chiave</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_key_notions.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/02_measurement.html">La misurazione in psicologia</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_scales.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/03_freq_distr.html">Dati e frequenze</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_sums.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/04_loc_scale.html">Indici di posizione e di scala</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/05_correlation.html">Le relazioni tra variabili</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/06_causality.html">Lo studio delle cause dei fenomeni</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_eda.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_mehr_song_spelke.html">✏️ Esercizi</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_3/introduction_chapter_3.html">Probabilità</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/01_intro_prob.html">Introduzione al calcolo delle probabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/02_conditional_prob.html">Probabilità condizionata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_cond_prob_1.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_cond_prob_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_discrete_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/03_bayes_theorem.html">Il teorema di Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_bayes_theorem.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_bayes_theorem_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/04a_random_var.html">Introduzione alle variabili casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/04b_expval_var.html">Proprietà delle variabili casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_exp_val_variance.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/04c_sampling_distr.html">Stime, stimatori e parametri</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_rv_discrete.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/05_joint_prob.html">Probabilità congiunta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_joint_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_covariance.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/06_density_func.html">La funzione di densità di probabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/07_discr_rv_distr.html">Distribuzioni di v.c. discrete</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_binomial.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/08_cont_rv_distr.html">Distribuzioni di v.c. continue</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_gaussian.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_beta_distr.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/09_likelihood.html">La verosimiglianza</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_likelihood.html">✏️ Esercizi</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="introduction_part_4.html">Inferenza bayesiana</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_intro_bayes.html">Modellazione bayesiana</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_subj_prop.html">Pensare ad una proporzione in termini soggettivi</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_grid_gauss.html">Verosimiglianza Gaussiana: Metodo Basato su Griglia</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_conjugate_families_1.html">Distribuzioni coniugate</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_conjugate_families_1.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="04_conjugate_families_2.html">Distribuzioni coniugate (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_summary_posterior.html">Sintesi a posteriori</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_conjugate.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="06_balance-prior-post.html">L’influenza della distribuzione a priori</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Monte Carlo a Catena di Markov</a></li>
<li class="toctree-l2"><a class="reference internal" href="15_stan_beta_binomial.html">Introduzione a Stan</a></li>

<li class="toctree-l2"><a class="reference internal" href="E_stan_beta_binomial.html">✏️ Esercizio</a></li>
<li class="toctree-l2"><a class="reference internal" href="16_stan_summary_posterior.html">Metodi di sintesi della distribuzione a posteriori</a></li>
<li class="toctree-l2"><a class="reference internal" href="17_stan_diagnostics.html">Diagnostica delle catene markoviane</a></li>
<li class="toctree-l2"><a class="reference internal" href="18_stan_prediction.html">La predizione bayesiana</a></li>

<li class="toctree-l2"><a class="reference internal" href="19_stan_odds_ratio.html">Analisi bayesiana dell’odds-ratio</a></li>
<li class="toctree-l2"><a class="reference internal" href="22_stan_normal_normal.html">Inferenza bayesiana su una media</a></li>
<li class="toctree-l2"><a class="reference internal" href="23_stan_two_groups.html">Confronto tra due gruppi</a></li>
<li class="toctree-l2"><a class="reference internal" href="24_stan_hier_beta_binom.html">Modello gerarchico beta-binomiale con Stan</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_5/introduction_part_5.html">Analisi della regressione</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_03_reglin_bayesian.html">Analisi bayesiana del modello di regressione lineare bivariato</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_1.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_04_synt_sugar.html">Zucchero sintattico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_05_two_means.html">Confronto tra le medie di due gruppi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_3.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_4.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_06_hier_regr.html">Il modello lineare gerarchico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_07_robust_regr.html">Regressione robusta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_08_specification_error.html">Errore di specificazione</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_09_causal_inference.html">Inferenza causale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_causal_inference.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_22_stan_logistic_regr.html">Regressione logistica con Stan</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_24_stan_mixed_models.html">Modelli misti con Stan</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_25_stan_rct.html">Incorporare dati storici di controllo in una RCT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_26_stan_mediation.html">Modello di mediazione con Stan</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_30_entropy.html">Entropia</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_31_kl.html">La divergenza di Kullback-Leibler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_kl.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_32_stan_loo.html">Validazione Incrociata Leave-One-Out</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_35_missing.html">Dati mancanti</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_40_rescorla_wagner.html">Apprendimento per rinforzo</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_6/introduction_part_6.html">Inferenza frequentista</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/01_intro_frequentist.html">Introduzione all’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_estimation.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/02_conf_interv.html">Intervallo di confidenza</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_conf_interv.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/03_test_ipotesi.html">Significatività statistica</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_t_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_interpretation_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_significato_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/04_two_ind_samples.html">Test t di Student per campioni indipendenti</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_test_media_pop.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_medie_pop_ampie.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_medie_pop_piccoli.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_campioni_appaiati.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_confronto_proporzioni.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/05_crisis.html">La crisi della generalizzabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/06_limiti_stat_frequentista.html">Limiti dell’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/07_effect_size.html">La grandezza dell’effetto</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/09_s_m_errors.html">Crisi della replicabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/10_integrity.html">Integrità della ricerca</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../references/bibliography.html">Bibliografia</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_7/introduction_appendix.html">Appendici</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a00_installation.html">Ambiente di lavoro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a01_markdown.html">Jupyter Notebook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a02_shell.html">La Shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a03_colab_tutorial.html">Colab: un breve tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a04_virtual_env.html">Ambienti virtuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a10_math_symbols.html">Simbologia di base</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a11_numbers.html">Numeri binari, interi, razionali, irrazionali e reali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a12_sum_notation.html">Simbolo di somma (sommatorie)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a13_sets.html">Insiemi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a13a_probability.html">Sigma algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a14_combinatorics.html">Calcolo combinatorio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a15_calculus.html">Per liberarvi dai terrori preliminari</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a20_kde_plot.html">Kernel Density Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a30_prob_tutorial.html">Esercizi di probabilità discreta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a40_rng.html">Generazione di numeri casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a44_montecarlo.html">Simulazione Monte Carlo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a45_mcmc.html">Catene di Markov</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a46_stan.html">Linguaggio Stan</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a50_lin_fun.html">La funzione lineare</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a50_reglin_ml.html">Modello di Regressione Bivariato e ML</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a51_reglin_1.html">Regressione lineare bivariata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a60_ttest_exercises.html">Esercizi sull’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a70_predict_counts.html">La predizione delle frequenze</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/ccaudek/ds4p/blob/main/docs/chapter_4/10_metropolis.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Scarica questa pagina">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapter_4/10_metropolis.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Scarica il file sorgente"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Stampa in PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Modalità schermo intero"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Cerca" aria-label="Cerca" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Monte Carlo a Catena di Markov</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contenuti </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparazione-del-notebook">Preparazione del Notebook</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#il-denominatore-bayesiano">Il denominatore bayesiano</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#il-metodo-di-monte-carlo">Il Metodo di Monte Carlo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#le-catene-di-markov">Le Catene di Markov</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estrazione-di-campioni-dalla-distribuzione-a-posteriori">Estrazione di campioni dalla distribuzione a posteriori</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulazione-con-distribuzione-target-nota">Simulazione con distribuzione target nota</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#algoritmo-di-metropolis">Algoritmo di Metropolis</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#passaggi-fondamentali-dell-algoritmo-di-metropolis">Passaggi Fondamentali dell’Algoritmo di Metropolis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#versione-di-mcelreath">Versione di McElreath</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#algoritmo-di-metropolis-con-distribuzione-target-nota">Algoritmo di Metropolis con Distribuzione Target Nota</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sintassi-della-funzione">Sintassi della funzione</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#parametri">Parametri</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#valore-di-ritorno">Valore di ritorno</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dettagli-dell-algoritmo">Dettagli dell’algoritmo</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#algoritmo-di-metropolis-con-distribuzione-target-incognita">Algoritmo di Metropolis con distribuzione target incognita</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aspetti-computazionali">Aspetti computazionali</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#warm-up-burn-in">Warm-up/Burn-in</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sintesi-della-distribuzione-a-posteriori">Sintesi della distribuzione a posteriori</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#diagnostiche-della-soluzione-mcmc">Diagnostiche della soluzione MCMC</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#catene-multiple">Catene multiple</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stazionarieta">Stazionarietà</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#autocorrelazione">Autocorrelazione</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#tasso-di-accettazione">Tasso di accettazione</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#test-di-convergenza">Test di convergenza</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#approcci-grafici-tracce-delle-serie-temporali-trace-plots">Approcci Grafici: Tracce delle Serie Temporali (Trace Plots)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#test-statistici-per-la-convergenza">Test Statistici per la Convergenza</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#test-di-geweke">Test di Geweke</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#geweke-z-score">Geweke Z-score</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#effective-sample-size-ess">Effective sample size (ESS)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#caso-normale-normale">Caso Normale-Normale</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#calcolo-dei-parametri-del-posterior-analitico">Calcolo dei Parametri del Posterior Analitico</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#codice-per-il-grafico">Codice per il Grafico</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#commenti-e-considerazioni-finali">Commenti e considerazioni finali</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#informazioni-sull-ambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="monte-carlo-a-catena-di-markov">
<span id="metropolis-notebook"></span><h1>Monte Carlo a Catena di Markov<a class="headerlink" href="#monte-carlo-a-catena-di-markov" title="Link to this heading">#</a></h1>
<p>In precedenza, abbiamo esplorato diversi esempi di inferenza bayesiana relativi alla distribuzione a posteriori di un singolo parametro, come nel caso del modello bernoulliano. Abbiamo anche discusso l’utilizzo di approcci come l’approssimazione tramite griglia e i metodi dei priori coniugati per ottenere o approssimare la distribuzione a posteriori. In questo capitolo, ci concentreremo sul metodo di simulazione e spiegheremo perché sono necessari approcci speciali noti come metodi di Monte Carlo a Catena di Markov (MCMC).</p>
<section id="preparazione-del-notebook">
<h2>Preparazione del Notebook<a class="headerlink" href="#preparazione-del-notebook" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> ../_config/config.py # Import the configuration settings
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">from</span> <span class="nn">statsmodels.graphics</span> <span class="kn">import</span> <span class="n">tsaplots</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="il-denominatore-bayesiano">
<h2>Il denominatore bayesiano<a class="headerlink" href="#il-denominatore-bayesiano" title="Link to this heading">#</a></h2>
<p>Nell’approccio bayesiano, il nostro obiettivo primario si concentra sulla determinazione della distribuzione a posteriori <span class="math notranslate nohighlight">\(p(\theta \mid y)\)</span> di un parametro <span class="math notranslate nohighlight">\(\theta\)</span> (nel caso più semplice), utilizzando come base sia i dati osservati <span class="math notranslate nohighlight">\(y\)</span> che la distribuzione a priori <span class="math notranslate nohighlight">\(p(\theta)\)</span>. Questo processo si avvale del teorema di Bayes per calcolare tale distribuzione:</p>
<div class="math notranslate nohighlight">
\[
p(\theta \mid y) = \frac{p(y \mid \theta) p(\theta)}{\int p(y \mid \theta) p(\theta) d\theta}.
\]</div>
<p>In questa formula, il denominatore <span class="math notranslate nohighlight">\(\int p(y \mid \theta) p(\theta) d\theta\)</span> rappresenta l’integrazione (o la somma, nel caso di variabili discrete) su tutti i possibili valori di <span class="math notranslate nohighlight">\(\theta\)</span>, fornendo così la probabilità marginale di <span class="math notranslate nohighlight">\(y\)</span>. Questo assicura che <span class="math notranslate nohighlight">\(p(\theta \mid y)\)</span> sia una distribuzione di probabilità valida che si somma (o integra) a 1.</p>
<p>Tuttavia, ci imbattiamo spesso in una sfida significativa: il calcolo dell’evidenza <span class="math notranslate nohighlight">\(p(y) = \int p(y \mid \theta) p(\theta) d\theta\)</span> può rivelarsi estremamente complesso, specialmente per modelli più articolati, rendendo difficile ottenere con precisione la distribuzione a posteriori.</p>
<p>Una soluzione possibile si trova nelle distribuzioni a priori coniugate, che offrono un metodo analitico per determinare la distribuzione a posteriori. Questo però limita la selezione delle distribuzioni a priori e di verosimiglianza. Per superare questa limitazione, soprattutto in modelli dove i metodi di campionamento a griglia non sono applicabili, si utilizzano i Metodi di Catena di Markov a Monte Carlo (MCMC). Questi metodi rappresentano una potente alternativa, consentendo di derivare la distribuzione a posteriori basandosi su presupposti teorici e senza restrizioni nella scelta delle distribuzioni.</p>
<p>L’approccio Monte Carlo si basa sulla generazione di sequenze di numeri casuali per creare un campione ampio di osservazioni proveniente dalla distribuzione a posteriori. Da questi campioni, possiamo poi stimare empiricamente le proprietà di interesse. Questo approccio richiede l’uso di metodi computazionalmente intensivi, e con la crescente potenza di calcolo dei computer moderni, tali metodi stanno diventando sempre più accessibili e popolari nell’analisi dei dati.</p>
</section>
<section id="il-metodo-di-monte-carlo">
<h2>Il Metodo di Monte Carlo<a class="headerlink" href="#il-metodo-di-monte-carlo" title="Link to this heading">#</a></h2>
<p>Nei capitoli precedenti abbiamo già esplorato l’efficacia della simulazione nel campo della teoria delle probabilità. Un esempio classico è il problema di Monty Hall, che mostra come la simulazione ripetuta possa fornire stime affidabili per la media e la varianza di variabili casuali. Inoltre, applicando la legge dei grandi numeri, queste stime diventano più accurate all’aumentare del numero di simulazioni. Ciò evidenzia la potenza dei metodi Monte Carlo, che evitano la necessità di calcolare integrali complessi.</p>
<p>Il Metodo di Monte Carlo, sviluppato durante il Progetto Manhattan negli anni “40, utilizza numeri casuali per risolvere problemi matematici complessi. Originariamente ideato da Stanislaw Ulam e successivamente implementato da John von Neumann, il metodo prende il nome dallo zio giocatore d’azzardo di Ulam, come suggerito da Nicholas Metropolis. Da allora, questo metodo è diventato una tecnica fondamentale in diverse discipline, contribuendo significativamente alla risoluzione di problemi complessi.</p>
<p>La metodologia di Monte Carlo genera un’ampia serie di punti casuali per stimare quantità di interesse, come l’integrazione numerica. Un esempio classico è l’approssimazione dell’integrale di un cerchio in 2D, dove il rapporto tra il numero di punti che cadono all’interno del cerchio e tutti i campioni fornisce un’approssimazione dell’area (per un esempio numerico, si veda <a class="reference internal" href="../chapter_7/a44_montecarlo.html#appendix-montecarlo"><span class="std std-ref">Simulazione Monte Carlo</span></a>).</p>
<p>Per illustrare ulteriormente questo concetto, consideriamo ora una distribuzione continua <span class="math notranslate nohighlight">\(p(\theta \mid y)\)</span> con una media <span class="math notranslate nohighlight">\(\mu\)</span>. Se siamo in grado di generare una sequenza di campioni casuali <span class="math notranslate nohighlight">\(\theta^{(1)}, \theta^{(2)}, \dots, \theta^{(T)}\)</span> indipendenti e identicamente distribuiti secondo <span class="math notranslate nohighlight">\(p(\theta \mid y)\)</span>, possiamo stimare il valore atteso teorico di <span class="math notranslate nohighlight">\(\theta\)</span> utilizzando la media campionaria <span class="math notranslate nohighlight">\(\frac{1}{T} \sum_{i=1}^T \theta^{(t)}\)</span>. Questa approssimazione diventa sempre più accurata man mano che aumenta il numero di campioni <span class="math notranslate nohighlight">\(T\)</span>, grazie alla Legge Forte dei Grandi Numeri.</p>
<p>Un altro vantaggio del Metodo di Monte Carlo è la sua capacità di approssimare la probabilità che una variabile casuale <span class="math notranslate nohighlight">\(\theta\)</span> cada all’interno di un intervallo specifico <span class="math notranslate nohighlight">\((l, u)\)</span>. Questo può essere ottenuto calcolando la media campionaria della funzione indicatrice <span class="math notranslate nohighlight">\(I(l &lt; \theta &lt; u)\)</span> per ogni realizzazione <span class="math notranslate nohighlight">\(\theta^{(t)}\)</span>, cioè <span class="math notranslate nohighlight">\(Pr(l &lt; \theta &lt; u) \approx \frac{\text{numero di realizzazioni } \theta^{(t)} \in (l, u)}{T}\)</span>.</p>
<p>Nonostante la loro efficacia, un limite dei metodi Monte Carlo tradizionali risiede nella generazione efficiente di un elevato numero di campioni <span class="math notranslate nohighlight">\(X_1, X_2, \ldots, X_n\)</span>. In risposta a questa sfida, i metodi di Monte Carlo basati su catene di Markov (MCMC) offrono una soluzione potente per simulare da distribuzioni complesse attraverso catene di Markov. L’evoluzione di questi algoritmi ha trasformato radicalmente la statistica e il calcolo scientifico, permettendo la simulazione da una vasta gamma di distribuzioni, anche in spazi di alta dimensionalità.</p>
</section>
<section id="le-catene-di-markov">
<h2>Le Catene di Markov<a class="headerlink" href="#le-catene-di-markov" title="Link to this heading">#</a></h2>
<p>Le catene di Markov, ideate da Andrey Markov nel 1906, rappresentano un tentativo di estendere la legge dei grandi numeri a contesti in cui le variabili casuali non sono indipendenti. Tradizionalmente, la statistica si concentra su sequenze di variabili casuali indipendenti e identicamente distribuite (i.i.d.), simboleggiate come <span class="math notranslate nohighlight">\(X_0, X_1, \ldots, X_n, \ldots\)</span>. In tali sequenze, ogni variabile è indipendente dalle altre e segue la stessa distribuzione, con <span class="math notranslate nohighlight">\(n\)</span> che rappresenta un indice temporale discreto. Tuttavia, questa assunzione di indipendenza non è sempre realistica nei modelli di fenomeni complessi, portando alla necessità di esplorare forme alternative di dipendenza tra variabili.</p>
<p>Per superare le limitazioni dell’indipendenza, le catene di Markov introducono una cosiddetta «dipendenza a un passo», incarnata nella «proprietà di Markov». Questa proprietà stabilisce che la previsione di un evento futuro <span class="math notranslate nohighlight">\(X_{n+1}\)</span> dipende unicamente dall’evento immediatamente precedente <span class="math notranslate nohighlight">\(X_n\)</span>, indipendentemente dagli eventi passati <span class="math notranslate nohighlight">\(X_0, X_1, X_2, \ldots, X_{n-1}\)</span>. La proprietà di Markov è espressa matematicamente come:</p>
<div class="math notranslate nohighlight">
\[
P(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, \ldots, X_0 = i_0) = P(X_{n+1} = j | X_n = i).
\]</div>
<p>Questa proprietà afferma che la previsione di un evento futuro dipende solo dall’evento immediatamente precedente, semplificando i calcoli relativi alle probabilità condizionali.</p>
<p>Le catene di Markov rappresentano un framework fondamentale per la modellazione delle dipendenze tra variabili casuali, una nozione cruciale in numerosi campi della statistica e della scienza dei dati, inclusa la metodologia MCMC (Markov Chain Monte Carlo). In particolare, nell’ambito dell’analisi bayesiana, l’uso di MCMC si rivela di estrema importanza, soprattutto quando non è possibile calcolare in modo analitico la distribuzione a posteriori.</p>
<p>L’algoritmo di Metropolis rappresenta una delle implementazioni più semplici del metodo MCMC. Questo algoritmo sfrutta la natura dipendente delle catene di Markov per navigare in modo efficace attraverso lo spazio della distribuzione a posteriori. Questo aspetto rende il MCMC uno strumento di grande potenza per affrontare problemi complessi in cui i metodi analitici tradizionali non possono essere applicati (per ulteriori dettagli, si veda <a class="reference internal" href="../chapter_7/a45_mcmc.html#appendix-markov"><span class="std std-ref">Catene di Markov</span></a>). In breve, il MCMC consente di generare un vasto insieme di valori per il parametro <span class="math notranslate nohighlight">\(\theta\)</span>. Idealmente, questi valori riflettono la distribuzione a posteriori <span class="math notranslate nohighlight">\(p(\theta \mid y)\)</span> quando questa non può essere ottenuta direttamente. Questa caratteristica rende il MCMC uno strumento essenziale per risolvere problemi complessi in cui i metodi analitici convenzionali non sono applicabili.</p>
</section>
<section id="estrazione-di-campioni-dalla-distribuzione-a-posteriori">
<h2>Estrazione di campioni dalla distribuzione a posteriori<a class="headerlink" href="#estrazione-di-campioni-dalla-distribuzione-a-posteriori" title="Link to this heading">#</a></h2>
<p>Nella discussione seguente ci porremo l’obiettivo di comprendere come utilizzare l’algoritmo di Metropolis per approssimare la distribuzione a posteriori <span class="math notranslate nohighlight">\(p(\theta \mid y)\)</span>. A questo fine, il capitolo è strutturato in varie sezioni che facilitano la comprensione progressiva del tema.</p>
<ul class="simple">
<li><p>Inizieremo discutendo di come la distribuzione a posteriori possa essere approssimata mediante tecniche di simulazione convenzionali. Questa prima parte presuppone che la distribuzione target, o «a posteriori,» sia già conosciuta o disponibile per l’analisi.</p></li>
<li><p>In seguito, passeremo a illustrare come l’algoritmo di Metropolis possa essere utilizzato per raggiungere lo stesso scopo—l’approssimazione della distribuzione a posteriori—mantenendo la presupposizione che la distribuzione target sia già nota.</p></li>
<li><p>Concluderemo il capitolo esplorando le modalità con cui l’algoritmo di Metropolis può essere adattato per affrontare situazioni in cui la distribuzione a posteriori non è direttamente nota. In questi casi, spesso abbiamo a disposizione informazioni riguardanti la distribuzione a priori e la funzione di verosimiglianza, che possono essere utilizzate per ottenere un’approssimazione efficace della distribuzione a posteriori.</p></li>
</ul>
<p>A titolo esemplificativo, utilizzeremo il dataset <code class="docutils literal notranslate"><span class="pre">moma_sample.csv</span></code>, il quale costituisce un campione casuale di 100 artisti provenienti dal Museo di Arte Moderna di New York (MoMA) e contiene diverse informazioni relative a ciascun artista.</p>
<p>Il nostro interesse è focalizzato sulla determinazione della probabilità che un artista presente nel MoMA appartenga alla generazione X o a una generazione successiva (nati dopo il 1965). Questa probabilità sarà indicata come <span class="math notranslate nohighlight">\(\pi\)</span>. Iniziamo importando i dati.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">moma_sample</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/moma_sample.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Esaminiamo le prime cinque righe del DataFrame.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">moma_sample</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>artist</th>
      <th>country</th>
      <th>birth</th>
      <th>death</th>
      <th>alive</th>
      <th>genx</th>
      <th>gender</th>
      <th>count</th>
      <th>year_acquired_min</th>
      <th>year_acquired_max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Ad Gerritsen</td>
      <td>dutch</td>
      <td>1940</td>
      <td>2015.0</td>
      <td>False</td>
      <td>False</td>
      <td>male</td>
      <td>1</td>
      <td>1981</td>
      <td>1981</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Kirstine Roepstorff</td>
      <td>danish</td>
      <td>1972</td>
      <td>NaN</td>
      <td>True</td>
      <td>True</td>
      <td>female</td>
      <td>3</td>
      <td>2005</td>
      <td>2005</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Lisa Baumgardner</td>
      <td>american</td>
      <td>1958</td>
      <td>2015.0</td>
      <td>False</td>
      <td>False</td>
      <td>female</td>
      <td>2</td>
      <td>2016</td>
      <td>2016</td>
    </tr>
    <tr>
      <th>3</th>
      <td>David Bates</td>
      <td>american</td>
      <td>1952</td>
      <td>NaN</td>
      <td>True</td>
      <td>False</td>
      <td>male</td>
      <td>1</td>
      <td>2001</td>
      <td>2001</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Simon Levy</td>
      <td>american</td>
      <td>1946</td>
      <td>NaN</td>
      <td>True</td>
      <td>False</td>
      <td>male</td>
      <td>1</td>
      <td>2012</td>
      <td>2012</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Dai dati osserviamo che solo 14 artisti su 100 appartengono alla generazione X o a una generazione successiva.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">result</span> <span class="o">=</span> <span class="n">moma_sample</span><span class="p">[</span><span class="s2">&quot;genx&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>genx
False    86
True     14
Name: count, dtype: int64
</pre></div>
</div>
</div>
</div>
<p>Il valore campionato <span class="math notranslate nohighlight">\(y = 14\)</span> riflette le caratteristiche del campione che è stato osservato. Tuttavia, poiché il MOMA contiene opere di migliaia di artisti, sorge una domanda riguardante il vero valore di <span class="math notranslate nohighlight">\(\theta\)</span> (la probabilità di appartenere alla generazione X o a una generazione successiva) all’interno di questa popolazione.</p>
<p>Possiamo interpretare i dati <span class="math notranslate nohighlight">\(y = 14\)</span> come l’esito di una variabile casuale Binomiale con parametri <span class="math notranslate nohighlight">\(N = 100\)</span> e <span class="math notranslate nohighlight">\(\theta\)</span> sconosciuto.</p>
<p>Supponiamo che le nostre credenze pregresse riguardo a <span class="math notranslate nohighlight">\(\theta\)</span> possano essere modellate attraverso una distribuzione Beta(4, 6).</p>
<p>Sfruttando le proprietà delle distribuzioni coniugate, possiamo calcolare la distribuzione a posteriori esatta:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Y</span> <span class="o">~</span> <span class="n">Binomiale</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">π</span><span class="p">)</span>
<span class="n">θ</span> <span class="o">=</span> <span class="n">Beta</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">θ</span> <span class="o">|</span> <span class="p">(</span><span class="n">Y</span> <span class="o">=</span> <span class="mi">14</span><span class="p">)</span> <span class="o">~</span> <span class="n">Beta</span><span class="p">(</span><span class="mi">4</span> <span class="o">+</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">6</span> <span class="o">+</span> <span class="mi">100</span> <span class="o">-</span> <span class="mi">14</span><span class="p">)</span> <span class="err">→</span> <span class="n">Beta</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">92</span><span class="p">)</span>
</pre></div>
</div>
<p>Nella figura successiva è rappresentata la distribuzione a posteriori del parametro <span class="math notranslate nohighlight">\(\theta\)</span>, insieme alla distribuzione a priori scelta.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="n">prior_density</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">posterior_density</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">92</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prior_density</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Prior: Beta(4, 6)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">posterior_density</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Posterior: Beta(18, 92)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Parameter Value&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Density&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Prior and Posterior Densities&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/2ffd301e88b2d1c1f39f92c3fe242ba7f133c26618838e8cea07097a5c42dac0.png"><img alt="../_images/2ffd301e88b2d1c1f39f92c3fe242ba7f133c26618838e8cea07097a5c42dac0.png" src="../_images/2ffd301e88b2d1c1f39f92c3fe242ba7f133c26618838e8cea07097a5c42dac0.png" style="width: 731px; height: 491px;" /></a>
</div>
</div>
<p>Se vogliamo conoscere il valore della media a posteriori di <span class="math notranslate nohighlight">\(\theta\)</span>, il risultato esatto è</p>
<div class="math notranslate nohighlight">
\[
\bar{\theta}_{post} = \frac{\alpha}{\alpha + \beta} = \frac{18}{18 + 92} \approx 0.1636.
\]</div>
<section id="simulazione-con-distribuzione-target-nota">
<h3>Simulazione con distribuzione target nota<a class="headerlink" href="#simulazione-con-distribuzione-target-nota" title="Link to this heading">#</a></h3>
<p>Usiamo ora una simulazione numerica per stimare la media a posteriori di <span class="math notranslate nohighlight">\(\theta\)</span>. Conoscendo la forma della distribuzione a posteriori <span class="math notranslate nohighlight">\(Beta(18, 92)\)</span>, possiamo generare un campione di osservazioni casuali da questa distribuzione. Successivamente, calcoliamo la media delle osservazioni ottenute per ottenere un’approssimazione della media a posteriori.</p>
<p>Se vogliamo ottenere un risultato approssimato con poche osservazioni (ad esempio, 10), possiamo procedere con la seguente simulazione:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">92</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.15055982 0.11082285 0.12981996 0.14002846 0.17033033 0.1016842
 0.16416764 0.10067355 0.21453883 0.14023775]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.14228633744567315
</pre></div>
</div>
</div>
</div>
<p>Tuttavia, con solo 10 campioni l’approssimazione potrebbe non essere molto accurata. Più aumentiamo il numero di campioni (cioè il numero di osservazioni casuali generate), più precisa sarà l’approssimazione. Aumentando il numero di campioni, ad esempio a 10000, otteniamo un risultato più preciso:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">92</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.1633850963306632
</pre></div>
</div>
</div>
</div>
<p>Quando il numero di campioni a posteriori diventa molto grande, la distribuzione campionaria <em>converge</em> alla densità della popolazione. Questo concetto si applica non solo alla media, ma anche ad altre statistiche descrittive, come la moda e la varianza.</p>
<p>È importante sottolineare che l’applicazione della simulazione di Monte Carlo è efficace per calcolare distribuzioni a posteriori solo quando conosciamo la distribuzione stessa e possiamo utilizzare funzioni Python per estrarre campioni casuali da tale distribuzione. Ciò è stato possibile nel caso della distribuzione a posteriori <span class="math notranslate nohighlight">\(Beta(18, 92)\)</span>.</p>
<p>Tuttavia, questa situazione ideale non si verifica sempre nella pratica, poiché le distribuzioni a priori coniugate alla verosimiglianza sono spesso rare. Per esempio, nel caso di una verosimiglianza binomiale e una distribuzione a priori gaussiana, l’espressione</p>
<div class="math notranslate nohighlight">
\[
p(\theta \mid y) = \frac{\mathrm{e}^{-(\theta - 1 / 2)^2} \theta^y (1 - \theta)^{n - y}} {\int_0^1 \mathrm{e}^{-(t - 1 / 2)^2} t^y (1 - t)^{n - y} dt}
\]</div>
<p>rende impossibile calcolare analiticamente la distribuzione a posteriori di <span class="math notranslate nohighlight">\(\theta\)</span>, precludendo quindi l’utilizzo diretto di Python per generare campioni casuali.</p>
<p>In queste circostanze, però, è possibile ottenere campioni casuali dalla distribuzione a posteriori mediante l’uso di metodi Monte Carlo basati su Catena di Markov (MCMC). Gli algoritmi MCMC, come ad esempio l’algoritmo Metropolis, costituiscono una classe di metodi che consentono di estrarre campioni casuali dalla distribuzione a posteriori <em>senza richiedere la conoscenza della sua rappresentazione analitica</em>. Le tecniche MCMC sono ampiamente adottate per risolvere problemi di inferenza bayesiana e rappresentano il principale strumento computazionale per ottenere stime approssimate di distribuzioni a posteriori in situazioni complesse e non analiticamente trattabili.</p>
</section>
</section>
<section id="algoritmo-di-metropolis">
<h2>Algoritmo di Metropolis<a class="headerlink" href="#algoritmo-di-metropolis" title="Link to this heading">#</a></h2>
<p>L’algoritmo di Metropolis è un metodo avanzato per il campionamento da distribuzioni probabilistiche complesse. Appartiene alla famiglia dei metodi Monte Carlo Markov Chain (MCMC) e combina strategie di campionamento Monte Carlo con catene di Markov per navigare nello spazio dei parametri in modo intelligente. Questo consente di ottenere campioni rappresentativi della distribuzione di interesse indipendentemente dal punto di partenza, riducendo il rischio di bias nei risultati.</p>
<section id="passaggi-fondamentali-dell-algoritmo-di-metropolis">
<h3>Passaggi Fondamentali dell’Algoritmo di Metropolis<a class="headerlink" href="#passaggi-fondamentali-dell-algoritmo-di-metropolis" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Inizio</strong>: Si parte da un valore iniziale casuale per le variabili di interesse.</p></li>
<li><p><strong>Generazione di Nuovi Punti</strong>: A ogni passo, si propone un nuovo valore («salto») basandosi su una distribuzione proposta, comunemente una distribuzione normale centrata sul punto corrente.</p></li>
<li><p><strong>Valutazione</strong>: Si calcola la probabilità associata al nuovo punto utilizzando la funzione di densità di probabilità (pdf) della distribuzione che si intende campionare.</p></li>
<li><p><strong>Decisione di Accettazione</strong>: Se il nuovo punto ha una probabilità maggiore rispetto al precedente (minore «energia»), lo si accetta. Questo favorisce la tendenza a spostarsi verso aree di maggiore probabilità.</p></li>
<li><p><strong>Accettazione Probabilistica</strong>: Se invece il nuovo punto presenta una probabilità minore, l’accettazione avviene comunque con una certa probabilità, determinata dal rapporto tra le probabilità del nuovo e del vecchio punto. Questo consente di evitare locali ottimalità e di esplorare più ampiamente lo spazio dei parametri.</p></li>
<li><p><strong>Raccolta dei Punti</strong>: I punti accettati vengono raccolti e costituiscono il campione dalla distribuzione desiderata.</p></li>
</ol>
<p>La procedura continua con l’iterazione dei passi dal 2 al 5, permettendo alla catena di campioni di convergere alla distribuzione target. Inizialmente, i campioni potrebbero non essere rappresentativi, ma dopo un sufficiente numero di iterazioni (il cosiddetto «burn-in»), la distribuzione dei punti accettati dovrebbe avvicinarsi a quella che si intende esplorare.</p>
<p>L’efficienza di questo algoritmo deriva dalla sua abilità nel mantenere un equilibrio tra l’esplorazione di nuove possibilità e l’utilizzo di quelle già note. Questo viene realizzato attraverso l’adozione di un meccanismo che accetta i punti suggeriti in modo probabilistico, facilitando così la raccolta di un campione che riflette accuratamente la distribuzione di probabilità complessa sotto indagine.</p>
<p>Per una visualizzazione del comportamento dell’algoritmo di Metropolis nell’esplorare lo spazio dei parametri, si può consultare <a class="reference external" href="https://elevanth.org/blog/2017/11/28/build-a-better-markov-chain/">questo post</a>. La distinzione tra i diversi metodi MCMC si basa principalmente sul tipo di distribuzione proposta e sul criterio di accettazione dei punti nel campionamento.</p>
</section>
<section id="versione-di-mcelreath">
<h3>Versione di McElreath<a class="headerlink" href="#versione-di-mcelreath" title="Link to this heading">#</a></h3>
<p><span id="id1">McElreath [<a class="reference internal" href="../references/bibliography.html#id14" title="Richard McElreath. Statistical rethinking: A Bayesian course with examples in R and Stan. CRC Press, Boca Raton, Florida, 2nd edition edition, 2020.">McE20</a>]</span> spiega l’algoritmo di Metropolis nel modo seguente. Re Markov era un autocrate benevolo di un regno insulare, un arcipelago circolare composto da 10 isole. Ogni isola era affiancata da altre due, e l’intero arcipelago formava un anello. Le isole erano di dimensioni diverse e quindi avevano popolazioni di diversa grandezza. La seconda isola aveva una popolazione circa il doppio di quella della prima, la terza circa il triplo della prima, e così via, fino all’isola più grande, che aveva una popolazione 10 volte maggiore della più piccola.</p>
<p>Il Buon Re aveva anche una serie di obblighi verso il suo popolo. Tra questi, Re Markov si impegnava a visitare ogni tanto ciascuna isola del suo regno. Poiché la gente amava il loro re, ogni isola preferiva che lui la visitasse più spesso. Così tutti concordarono che il re dovesse visitare ogni isola in proporzione alla sua dimensione demografica, visitando per esempio l’isola più grande 10 volte più spesso della più piccola.</p>
<p>Tuttavia, il Buon Re Markov non era amante delle agende o della contabilità, e quindi desiderava un modo per assolvere ai suoi obblighi senza pianificare i suoi viaggi con mesi di anticipo. Inoltre, poiché l’arcipelago era un anello, il Re insisteva nel muoversi solo tra isole adiacenti, per minimizzare il tempo trascorso sull’acqua.</p>
<p>Il consigliere del re, un certo Signor Metropolis, ideò una soluzione ingegnosa a queste esigenze. Chiameremo questa soluzione l’algoritmo di Metropolis.</p>
<ol class="arabic simple">
<li><p>Lancia una moneta per scegliere se andare all’isola a sinistra o a destra.</p></li>
<li><p>Determina la popolazione dell’isola proposta.</p></li>
<li><p>Determina la popolazione dell’isola corrente.</p></li>
<li><p>Spostati verso l’isola proposta con la probabilità calcolata.</p></li>
</ol>
<p>Ripeti i passaggi dal 1 al 4.</p>
<p>A lungo termine, questo processo porterà a visitare ciascuna isola in proporzione alla sua popolazione. Se utilizziamo la popolazione dell’isola come metafora della densità di probabilità, possiamo impiegare lo stesso algoritmo per campionare da qualsiasi distribuzione di probabilità usando un generatore di numeri casuali.</p>
<p>Per l’inferenza bayesiana, applichiamo l’algoritmo di Metropolis assumendo:</p>
<ul class="simple">
<li><p>Le «isole» come i valori dei parametri.</p></li>
<li><p>La «dimensione della popolazione» come le probabilità a posteriori.</p></li>
</ul>
<p>In questa metafora, l’algoritmo di Metropolis ci aiuta a esplorare lo spazio dei parametri, muovendoci verso valori di parametri con maggior probabilità posteriore (simili a isole con maggior popolazione) e campionando da queste distribuzioni in maniera proporzionale alla loro probabilità.</p>
<p>L’algoritmo di Metropolis, nella versione di <span id="id2">McElreath [<a class="reference internal" href="../references/bibliography.html#id14" title="Richard McElreath. Statistical rethinking: A Bayesian course with examples in R and Stan. CRC Press, Boca Raton, Florida, 2nd edition edition, 2020.">McE20</a>]</span> è stato implementato da Dustin Stansbury come indicato di seguito.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">simulate_markov_visits</span><span class="p">(</span><span class="n">island_sizes</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">100_000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;aka Metropolis algorithm&quot;&quot;&quot;</span>

    <span class="c1"># Metropolis algorithm</span>
    <span class="n">island_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">island_sizes</span><span class="p">))</span>
    <span class="n">visits</span> <span class="o">=</span> <span class="p">{</span><span class="n">ii</span><span class="p">:</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="n">island_idx</span><span class="p">}</span>
    <span class="n">current_island_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">island_idx</span><span class="p">)</span>
    <span class="n">markov_chain</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># store history</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span>
        <span class="c1"># 1. Flip a coin to propose a direction, left or right</span>
        <span class="n">coin_flip</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span>
        <span class="n">direction</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="k">if</span> <span class="n">coin_flip</span> <span class="k">else</span> <span class="mi">1</span>
        <span class="n">proposal_island_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">island_idx</span><span class="p">,</span> <span class="n">direction</span><span class="p">)[</span><span class="n">current_island_idx</span><span class="p">]</span>

        <span class="c1"># 2. Proposal island size</span>
        <span class="n">proposal_size</span> <span class="o">=</span> <span class="n">island_sizes</span><span class="p">[</span><span class="n">proposal_island_idx</span><span class="p">]</span>

        <span class="c1"># 3. Current island size</span>
        <span class="n">current_size</span> <span class="o">=</span> <span class="n">island_sizes</span><span class="p">[</span><span class="n">current_island_idx</span><span class="p">]</span>

        <span class="c1"># 4. Go to proposal island if ratio of sizes is greater than another coin flip</span>
        <span class="n">p_star</span> <span class="o">=</span> <span class="n">proposal_size</span> <span class="o">/</span> <span class="n">current_size</span>
        <span class="n">move</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">p_star</span>
        <span class="n">current_island_idx</span> <span class="o">=</span> <span class="n">proposal_island_idx</span> <span class="k">if</span> <span class="n">move</span> <span class="k">else</span> <span class="n">current_island_idx</span>

        <span class="c1"># 5. tally visits and repeat</span>
        <span class="n">visits</span><span class="p">[</span><span class="n">current_island_idx</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">markov_chain</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_island_idx</span><span class="p">)</span>

    <span class="c1"># Visualization</span>
    <span class="n">island_idx</span> <span class="o">=</span> <span class="n">visits</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
    <span class="n">island_visit_density</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span> <span class="o">/</span> <span class="n">n_steps</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">visits</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
    <span class="n">island_size_density</span> <span class="o">=</span> <span class="n">island_sizes</span> <span class="o">/</span> <span class="n">island_sizes</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="n">_</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">sca</span><span class="p">(</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">island_sizes</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Island Index&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Island Population&quot;</span><span class="p">);</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">island_sizes</span><span class="p">)));</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">sca</span><span class="p">(</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">island_idx</span><span class="p">,</span> <span class="n">island_size_density</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Population&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">island_idx</span><span class="p">,</span> <span class="n">island_visit_density</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">.4</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Visits&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Island Index&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Density&quot;</span><span class="p">);</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">island_sizes</span><span class="p">)));</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">markov_chain</span>
</pre></div>
</div>
</div>
</div>
<p>Verifichiamo l’algoritmo con una distribuzione approssimativamente gaussiana.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_steps</span> <span class="o">=</span> <span class="mi">100_000</span>
<span class="n">island_sizes</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">island_sizes</span> <span class="o">/=</span> <span class="n">island_sizes</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">/</span> <span class="mi">1000</span>

<span class="n">gaussian_markov_chain</span> <span class="o">=</span> <span class="n">simulate_markov_visits</span><span class="p">(</span><span class="n">island_sizes</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/02450ca8f6823e8eaafe0b367ac62029aa166ccc258c924da07fc6c6fbc9def9.png"><img alt="../_images/02450ca8f6823e8eaafe0b367ac62029aa166ccc258c924da07fc6c6fbc9def9.png" src="../_images/02450ca8f6823e8eaafe0b367ac62029aa166ccc258c924da07fc6c6fbc9def9.png" style="width: 1211px; height: 411px;" /></a>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_markov_chain</span><span class="p">(</span><span class="n">markov_chain</span><span class="p">,</span> <span class="o">**</span><span class="n">hist_kwargs</span><span class="p">):</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">sca</span><span class="p">(</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">markov_chain</span><span class="p">[:</span><span class="mi">500</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;visit number&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;island index&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Metropolis Algorithm Markov Chain</span><span class="se">\n</span><span class="s2">First 500 Steps&quot;</span><span class="p">);</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">sca</span><span class="p">(</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">markov_chain</span><span class="p">,</span> <span class="n">orientation</span><span class="o">=</span><span class="s1">&#39;horizontal&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">hist_kwargs</span><span class="p">);</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Resulting Posterior</span><span class="se">\n</span><span class="s2">(horizontal)&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_markov_chain</span><span class="p">(</span><span class="n">gaussian_markov_chain</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/e395f39f046d5627e15e7d123830de9ae86945019d46045cc8a686504c3c33e3.png"><img alt="../_images/e395f39f046d5627e15e7d123830de9ae86945019d46045cc8a686504c3c33e3.png" src="../_images/e395f39f046d5627e15e7d123830de9ae86945019d46045cc8a686504c3c33e3.png" style="width: 1011px; height: 411px;" /></a>
</div>
</div>
<p>Verifichiamo l’algoritmo con una distribuzione di Poisson.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">island_sizes</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
<span class="n">island_sizes</span> <span class="o">/=</span> <span class="n">island_sizes</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">/</span> <span class="mi">10</span>

<span class="n">poisson_markov_chain</span> <span class="o">=</span> <span class="n">simulate_markov_visits</span><span class="p">(</span><span class="n">island_sizes</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/51ab14388b2947da8a203dd5df75a2c01ae844cda4ef561a6f2cb18d6f138312.png"><img alt="../_images/51ab14388b2947da8a203dd5df75a2c01ae844cda4ef561a6f2cb18d6f138312.png" src="../_images/51ab14388b2947da8a203dd5df75a2c01ae844cda4ef561a6f2cb18d6f138312.png" style="width: 1211px; height: 411px;" /></a>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_markov_chain</span><span class="p">(</span><span class="n">poisson_markov_chain</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/fd3e2ddee08208d954390a016706c504bb86306d1e35f2a400bd28413aba4f04.png"><img alt="../_images/fd3e2ddee08208d954390a016706c504bb86306d1e35f2a400bd28413aba4f04.png" src="../_images/fd3e2ddee08208d954390a016706c504bb86306d1e35f2a400bd28413aba4f04.png" style="width: 1011px; height: 411px;" /></a>
</div>
</div>
</section>
<section id="algoritmo-di-metropolis-con-distribuzione-target-nota">
<h3>Algoritmo di Metropolis con Distribuzione Target Nota<a class="headerlink" href="#algoritmo-di-metropolis-con-distribuzione-target-nota" title="Link to this heading">#</a></h3>
<p>Torniamo al caso precedentemente esaminato in cui la distribuzione a posteriori è una Beta(18, 92). Ora, useremo una versione più generale dell’algoritmo di Metropolis rispetto a quello precedentemente discusso. Questa nuova versione ci consentirà di generare campioni da questa distribuzione nota in modo più flessibile.</p>
<p>Per iniziare, definiamo la distribuzione da cui verranno proposti i nuovi campioni. Nel nostro primo esempio, scegliamo una distribuzione proposta molto semplice: una piccola variazione, estratta da una distribuzione uniforme, verrà aggiunta al valore del campione precedente.</p>
<p>Ora procediamo a descrivere questa nuova implementazione dell’algoritmo di Metropolis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Proposal distribution</span>
<span class="k">def</span> <span class="nf">uniprop</span><span class="p">(</span><span class="n">xprev</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">xprev</span> <span class="o">+</span> <span class="n">stats</span><span class="o">.</span><span class="n">uniform</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">loc</span><span class="o">=-</span><span class="n">delta</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2</span> <span class="o">*</span> <span class="n">delta</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Metropolis algorithm </span>
<span class="k">def</span> <span class="nf">metropolis_v1</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">qdraw</span><span class="p">,</span> <span class="n">nsamp</span><span class="p">,</span> <span class="n">xinit</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implements the Metropolis algorithm for MCMC sampling.</span>

<span class="sd">    The function generates `nsamp` samples from a target distribution `p` using </span>
<span class="sd">    the Metropolis algorithm. The algorithm starts with an initial state `xinit` </span>
<span class="sd">    and iteratively applies a proposal mechanism governed by `qdraw` to explore </span>
<span class="sd">    the target distribution.</span>

<span class="sd">    Args:</span>
<span class="sd">        p (callable): A function representing the target distribution to sample from.</span>
<span class="sd">                     Should accept a float or array-like and return the density </span>
<span class="sd">                     (unnormalized is okay) at that point.</span>
<span class="sd">                     </span>
<span class="sd">        qdraw (callable): A function implementing the proposal mechanism. </span>
<span class="sd">                          Takes the current state (float or array-like) as input </span>
<span class="sd">                          and returns a proposed next state.</span>
<span class="sd">                          </span>
<span class="sd">        nsamp (int): The number of samples to draw from the target distribution.</span>
<span class="sd">        </span>
<span class="sd">        xinit (float or array-like): The initial state for the MCMC chain.</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: An array of shape (nsamp,) containing samples drawn from the </span>
<span class="sd">        target distribution `p`.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">        &gt;&gt;&gt; target = stats.norm().pdf  # Standard Normal as target</span>
<span class="sd">        &gt;&gt;&gt; qdraw = lambda x: x + np.random.normal(0, 1)  # Random-walk Metropolis</span>
<span class="sd">        &gt;&gt;&gt; samples = metropolis_v1(target, qdraw, 10000, 0.0)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">nsamp</span><span class="p">)</span>
    <span class="n">x_prev</span> <span class="o">=</span> <span class="n">xinit</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nsamp</span><span class="p">):</span>
        <span class="n">x_star</span> <span class="o">=</span> <span class="n">qdraw</span><span class="p">(</span><span class="n">x_prev</span><span class="p">)</span>
        <span class="n">p_star</span> <span class="o">=</span> <span class="n">p</span><span class="p">(</span><span class="n">x_star</span><span class="p">)</span>
        <span class="n">p_prev</span> <span class="o">=</span> <span class="n">p</span><span class="p">(</span><span class="n">x_prev</span><span class="p">)</span>
        <span class="n">pdfratio</span> <span class="o">=</span> <span class="n">p_star</span> <span class="o">/</span> <span class="n">p_prev</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span> <span class="o">&lt;</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">pdfratio</span><span class="p">):</span>
            <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_star</span>
            <span class="n">x_prev</span> <span class="o">=</span> <span class="n">x_star</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_prev</span>
    <span class="k">return</span> <span class="n">samples</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="sintassi-della-funzione">
<h3>Sintassi della funzione<a class="headerlink" href="#sintassi-della-funzione" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">metropolis_v1</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">qdraw</span><span class="p">,</span> <span class="n">nsamp</span><span class="p">,</span> <span class="n">xinit</span><span class="p">):</span>
</pre></div>
</div>
<section id="parametri">
<h4>Parametri<a class="headerlink" href="#parametri" title="Link to this heading">#</a></h4>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">p</span></code>: Questa è la distribuzione target da cui si desidera campionare. È fornita come una funzione invocabile che prende un valore <code class="docutils literal notranslate"><span class="pre">x</span></code> e restituisce la densità di probabilità (o massa) in quel punto. La distribuzione target potrebbe anche non essere normalizzata.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">qdraw</span></code>: Questa è la distribuzione proposta da cui viene generato un possibile stato successivo (<code class="docutils literal notranslate"><span class="pre">x_star</span></code>), dato lo stato corrente (<code class="docutils literal notranslate"><span class="pre">x_prev</span></code>). Anche questa è una funzione invocabile, che dovrebbe restituire una nuova proposta basata sullo stato corrente.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">nsamp</span></code>: Questo è il numero di campioni che si desidera generare dalla distribuzione target. Determina quante iterazioni verranno eseguite dall’algoritmo.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">xinit</span></code>: Questo è lo stato iniziale della catena di Markov. L’algoritmo partirà da questo punto.</p></li>
</ol>
</section>
<section id="valore-di-ritorno">
<h4>Valore di ritorno<a class="headerlink" href="#valore-di-ritorno" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>La funzione restituisce un array (<code class="docutils literal notranslate"><span class="pre">samples</span></code>) di dimensione <code class="docutils literal notranslate"><span class="pre">nsamp</span></code>, contenente i campioni estratti dalla distribuzione target.</p></li>
</ul>
</section>
</section>
<section id="dettagli-dell-algoritmo">
<h3>Dettagli dell’algoritmo<a class="headerlink" href="#dettagli-dell-algoritmo" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Inizializzazione</strong>:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">nsamp</span><span class="p">)</span>
<span class="n">x_prev</span> <span class="o">=</span> <span class="n">xinit</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">samples</span></code>: Un array NumPy vuoto che sarà popolato con i campioni generati dall’algoritmo.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">x_prev</span></code>: Lo stato corrente della catena di Markov. Inizializzato a <code class="docutils literal notranslate"><span class="pre">xinit</span></code>. Iniziamo dunque con un punto arbitrario nello spazio dei parametri. Questo primo valore della catena di Markov può essere scelto casualmente tra i valori possibili del parametro.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p><strong>Il ciclo</strong>:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nsamp</span><span class="p">):</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Si itera <code class="docutils literal notranslate"><span class="pre">nsamp</span></code> volte per generare <code class="docutils literal notranslate"><span class="pre">nsamp</span></code> campioni.</p></li>
</ul>
<ol class="arabic simple" start="3">
<li><p><strong>Fase di proposta</strong>:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x_star</span> <span class="o">=</span> <span class="n">qdraw</span><span class="p">(</span><span class="n">x_prev</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Un nuovo stato (<code class="docutils literal notranslate"><span class="pre">x_star</span></code>) viene proposto sulla base dello stato corrente (<code class="docutils literal notranslate"><span class="pre">x_prev</span></code>) utilizzando la funzione di distribuzione proposta <code class="docutils literal notranslate"><span class="pre">qdraw</span></code>.</p></li>
</ul>
<ol class="arabic simple" start="4">
<li><p><strong>Calcolo della densità</strong>:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">p_star</span> <span class="o">=</span> <span class="n">p</span><span class="p">(</span><span class="n">x_star</span><span class="p">)</span>
<span class="n">p_prev</span> <span class="o">=</span> <span class="n">p</span><span class="p">(</span><span class="n">x_prev</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Calcola le densità dei punti proposti (<code class="docutils literal notranslate"><span class="pre">x_star</span></code>) e correnti (<code class="docutils literal notranslate"><span class="pre">x_prev</span></code>) utilizzando la funzione di distribuzione target <code class="docutils literal notranslate"><span class="pre">p</span></code>.</p></li>
</ul>
<ol class="arabic simple" start="5">
<li><p><strong>Rapporto tra densità</strong>:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pdfratio</span> <span class="o">=</span> <span class="n">p_star</span> <span class="o">/</span> <span class="n">p_prev</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Viene calcolato il rapporto tra le densità (<code class="docutils literal notranslate"><span class="pre">p_star</span> <span class="pre">/</span> <span class="pre">p_prev</span></code>). Questo rapporto decide se accettare o meno lo stato proposto.</p></li>
</ul>
<ol class="arabic simple" start="6">
<li><p><strong>Fase di accettazione</strong>:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span> <span class="o">&lt;</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">pdfratio</span><span class="p">):</span>
    <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_star</span>
    <span class="n">x_prev</span> <span class="o">=</span> <span class="n">x_star</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_prev</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Viene estratto un numero casuale dalla distribuzione uniforme tra 0 e 1.</p></li>
<li><p>Se questo numero è minore del minimo tra 1 e <code class="docutils literal notranslate"><span class="pre">pdfratio</span></code>, lo stato proposto viene accettato e <code class="docutils literal notranslate"><span class="pre">x_prev</span></code> viene aggiornato a <code class="docutils literal notranslate"><span class="pre">x_star</span></code>.</p></li>
<li><p>Altrimenti, lo stato proposto viene respinto e lo stato corrente (<code class="docutils literal notranslate"><span class="pre">x_prev</span></code>) viene mantenuto per il ciclo successivo.</p></li>
</ul>
<p>In sintesi, la decisione di accettare o rifiutare il parametro proposto <code class="docutils literal notranslate"><span class="pre">x_star</span></code> si basa sul valore di <code class="docutils literal notranslate"><span class="pre">pdfratio</span></code>. Se <code class="docutils literal notranslate"><span class="pre">pdfratio</span></code> è maggiore di 1, ciò indica che il parametro proposto è più probabile del parametro corrente <code class="docutils literal notranslate"><span class="pre">x_prev</span></code>; di conseguenza, <code class="docutils literal notranslate"><span class="pre">x_star</span></code> viene sempre accettato. Se, invece, <code class="docutils literal notranslate"><span class="pre">pdfratio</span></code> è minore di 1, il parametro proposto viene accettato con una probabilità che è proporzionale a <code class="docutils literal notranslate"><span class="pre">pdfratio</span></code> stesso. Per esempio, un <code class="docutils literal notranslate"><span class="pre">pdfratio</span></code> di 0.10 implica una probabilità del 10% di accettare <code class="docutils literal notranslate"><span class="pre">x_star</span></code>.</p>
<p>Questa strategia di accettazione ci consente di generare campioni che sono statisticamente rappresentativi della distribuzione target. Questo perché la probabilità di accettare un candidato è direttamente proporzionale alla sua densità della distribuzione che stiamo cercando di campionare.</p>
<p>Nella pratica, questo processo decisionale viene implementato confrontando <code class="docutils literal notranslate"><span class="pre">pdfratio</span></code> con un numero casuale <span class="math notranslate nohighlight">\(u\)</span>, estratto da una distribuzione uniforme <span class="math notranslate nohighlight">\(Unif(0, 1)\)</span>. Se <code class="docutils literal notranslate"><span class="pre">pdfratio</span></code> <span class="math notranslate nohighlight">\(&gt; u\)</span>, il parametro proposto <code class="docutils literal notranslate"><span class="pre">x_star</span></code> viene accettato, e la catena di Markov si sposta verso questo nuovo valore. In caso contrario, il valore corrente <code class="docutils literal notranslate"><span class="pre">x_prev</span></code> viene mantenuto come prossimo elemento nella catena.</p>
<p>Applichiamo ora l’algoritmo di Metropolis usando una Beta(18, 92) quale distribuzione target e una distribuzione uniforme quale distribuzione proposta.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialization</span>
<span class="n">init_state</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">100_000</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Using Beta(18, 92) as the target distribution</span>
<span class="n">samps</span> <span class="o">=</span> <span class="n">metropolis_v1</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">92</span><span class="p">),</span> <span class="n">uniprop</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">init_state</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>La ragione per cui è necessario scrivere <code class="docutils literal notranslate"><span class="pre">lambda</span> <span class="pre">x:</span> <span class="pre">stats.beta.pdf(x,</span> <span class="pre">18,</span> <span class="pre">92)</span></code> anziché <code class="docutils literal notranslate"><span class="pre">stats.beta.pdf(x,</span> <span class="pre">18,</span> <span class="pre">92)</span></code> è che la funzione <code class="docutils literal notranslate"><span class="pre">metropolis_v1</span></code> si aspetta una funzione che può essere chiamata all’interno del codice di <code class="docutils literal notranslate"><span class="pre">metropolis_v1</span></code>. Scrivere direttamente <code class="docutils literal notranslate"><span class="pre">stats.beta.pdf(x,</span> <span class="pre">18,</span> <span class="pre">92)</span></code> come argomento causerà un errore di sintassi perché <code class="docutils literal notranslate"><span class="pre">x</span></code> non è definito in quel contesto. La funzione <code class="docutils literal notranslate"><span class="pre">metropolis_v1</span></code> deve poter invocare <code class="docutils literal notranslate"><span class="pre">p</span></code> con differenti valori di <code class="docutils literal notranslate"><span class="pre">x</span></code> durante l’esecuzione. Quindi, ha bisogno di una «funzione» e non di un singolo valore. La funzione lambda <code class="docutils literal notranslate"><span class="pre">lambda</span> <span class="pre">x:</span> <span class="pre">stats.beta.pdf(x,</span> <span class="pre">18,</span> <span class="pre">92)</span></code> è invocabile: dato un <code class="docutils literal notranslate"><span class="pre">x</span></code>, restituirà il valore della PDF della distribuzione Beta in quel punto. Utilizzando la funzione lambda, fissiamo i parametri <code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">=</span> <span class="pre">18</span></code> e <code class="docutils literal notranslate"><span class="pre">beta</span> <span class="pre">=</span> <span class="pre">92</span></code> nella distribuzione Beta, rendendola una funzione di una sola variabile <code class="docutils literal notranslate"><span class="pre">x</span></code>, che è ciò che la funzione <code class="docutils literal notranslate"><span class="pre">metropolis_v1</span></code> richiede.</p>
<p>In sostanza, la funzione lambda serve come un «incapsulamento» o «avvolgimento» per la funzione <code class="docutils literal notranslate"><span class="pre">stats.beta.pdf</span></code>, restringendola a specifici parametri e rendendola invocabile con una sola variabile, che è esattamente ciò che l’algoritmo di Metropolis necessita.</p>
</div>
<p>Esaminiamo i primi 20 valori ottenuti.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">samps</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">20</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.5        0.5        0.5        0.46609323 0.46609323 0.46609323
 0.4325139  0.40252421 0.35581839 0.35581839 0.35581839 0.36884884
 0.33176351 0.29100705 0.24560277 0.25871319 0.25871319 0.25871319
 0.25871319 0.25871319]
</pre></div>
</div>
</div>
</div>
<p>Generiamo ora un istogramma di tutti i 100000 campioni prodotti dall’algoritmo di Metropolis, a cui sovrapponiamo la densità Beta(18, 92).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samps</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;MCMC distribution&quot;</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">92</span><span class="p">),</span> <span class="s2">&quot;C0&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;True distribution&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/cd3d7fed5259a4322c6ee58eef5c272b14a4c3265ad96e0c64671b409dcf5dd3.png"><img alt="../_images/cd3d7fed5259a4322c6ee58eef5c272b14a4c3265ad96e0c64671b409dcf5dd3.png" src="../_images/cd3d7fed5259a4322c6ee58eef5c272b14a4c3265ad96e0c64671b409dcf5dd3.png" style="width: 731px; height: 491px;" /></a>
</div>
</div>
<p>Si noti che la procedura di Metropolis genera un insieme di campioni che approssima la distribuzione target desiderata. In altre parole, i campioni ottenuti seguono la distribuzione che stiamo cercando di esplorare, fornendo quindi un modo efficace per ottenere un campionamento casuale da questa distribuzione.</p>
<p>Ora esaminiamo una diversa funzione di proposta: una distribuzione gaussiana centrata attorno allo stato precedente, con una deviazione standard <span class="math notranslate nohighlight">\(\sigma\)</span>. In questo caso, ogni nuovo punto candidato <span class="math notranslate nohighlight">\(x^*\)</span> sarà estratto da una gaussiana con media uguale allo stato corrente <span class="math notranslate nohighlight">\(x_{\text{prev}}\)</span> e deviazione standard <span class="math notranslate nohighlight">\(\sigma\)</span>. Questo introduce un grado di esplorazione randomica attorno al punto attuale, permettendo all’algoritmo di navigare efficacemente nello spazio dei parametri. In pratica, questo significa che, se <span class="math notranslate nohighlight">\(\sigma\)</span> è piccola, il valore candidato <span class="math notranslate nohighlight">\(x^*\)</span> sarà simile al valore corrente <span class="math notranslate nohighlight">\(x_{\text{prev}}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Proposal distribution</span>
<span class="k">def</span> <span class="nf">gaussprop</span><span class="p">(</span><span class="n">xprev</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">xprev</span> <span class="o">+</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Applichiamo nuovamente l’algorimo di Metropolis con questa nuova distribuzione proposta.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">samps</span> <span class="o">=</span> <span class="n">metropolis_v1</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">92</span><span class="p">),</span> <span class="n">gaussprop</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">init_state</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">samps</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">20</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.20090969 0.13346877 0.13346877 0.13346877 0.13346877 0.13346877
 0.13346877 0.15164492 0.15164492 0.19828971 0.19828971 0.16806675
 0.16806675 0.16806675 0.16806675 0.16806675 0.16806675 0.22020973
 0.14820446 0.13045723]
</pre></div>
</div>
</div>
</div>
<p>Otteniamo anche in questo caso un campione casuale dalla distribuzione target.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samps</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;MCMC distribution&quot;</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">92</span><span class="p">),</span> <span class="s2">&quot;C0&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;True distribution&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/1a2d2e49edaf041aa1474c158345c0517c18bd18daa53922202bea5d8b9680bc.png"><img alt="../_images/1a2d2e49edaf041aa1474c158345c0517c18bd18daa53922202bea5d8b9680bc.png" src="../_images/1a2d2e49edaf041aa1474c158345c0517c18bd18daa53922202bea5d8b9680bc.png" style="width: 731px; height: 491px;" /></a>
</div>
</div>
</section>
<section id="algoritmo-di-metropolis-con-distribuzione-target-incognita">
<h3>Algoritmo di Metropolis con distribuzione target incognita<a class="headerlink" href="#algoritmo-di-metropolis-con-distribuzione-target-incognita" title="Link to this heading">#</a></h3>
<p>Ora andiamo oltre: invece di presupporre che la distribuzione target sia già nota, cosa che si verifica quando utilizziamo distribuzioni coniugate, nel contesto bayesiano la distribuzione target che vogliamo campionare è il prodotto non normalizzato della verosimiglianza e della distribuzione a priori.</p>
<p>Iniziamo quindi col definire la distribuzione a priori. In questo esempio, la distribuzione a priori è una distribuzione Beta(4, 6).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prior</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="mi">6</span>
    <span class="k">return</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Definiamo la verosimiglianza. Il problema presente richiede una verosimiglianza binomiale.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">likelihood</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="mi">14</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="k">return</span> <span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>La distribuzione a posteriori non normalizzata è il prodotto della distribuzione a priori e della verosimiglianza. Si noti che, per il motivo spiegato prima, non è necessario normalizzare la distribuzione a posteriori.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">posterior</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">likelihood</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">*</span> <span class="n">prior</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Per la distribuzione proposta, faremo ricorso alla stessa funzione che abbiamo precedentemente definito. Tuttavia, apporteremo alcune modifiche all’algoritmo di Metropolis per adeguarlo a questo nuovo contesto.</p>
<p>Nell’implementazione di un algoritmo di Metropolis in ambito bayesiano, vi sono diversi aspetti da considerare attentamente. Ecco alcuni punti cruciali:</p>
<ol class="arabic simple">
<li><p><strong>Simmetria della Distribuzione Proposta</strong>: È fondamentale che la distribuzione proposta sia simmetrica. Questa è una condizione necessaria per il funzionamento dell’algoritmo di Metropolis, ma non per quello di Metropolis-Hastings.</p></li>
<li><p><strong>Valore Iniziale</strong>: Il valore iniziale scelto dovrebbe essere plausibile in base alla distribuzione a priori, in modo da facilitare la convergenza dell’algoritmo.</p></li>
<li><p><strong>Probabilità Zero</strong>: Nel caso in cui la verosimiglianza o il prior assumano un valore di zero, il rapporto tra le densità di probabilità (<code class="docutils literal notranslate"><span class="pre">pdfratio</span></code>) all’interno dell’algoritmo di Metropolis risulterà indefinito. Pertanto, è importante garantire che il valore <code class="docutils literal notranslate"><span class="pre">x_star</span></code>, generato dalla distribuzione proposta, cada sempre entro i limiti del supporto sia del prior che della verosimiglianza.</p></li>
</ol>
<p>Di seguito è presentato il codice, rivisto in base a queste considerazioni.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Definizione della funzione dell&#39;algoritmo di Metropolis.</span>
<span class="c1"># nsamp: Numero di campioni da generare.</span>
<span class="c1"># xinit: Valore iniziale da cui iniziare il sampling.</span>
<span class="k">def</span> <span class="nf">metropolis_v2</span><span class="p">(</span><span class="n">nsamp</span><span class="p">,</span> <span class="n">xinit</span><span class="p">):</span>
    <span class="c1"># Inizializza un array vuoto per conservare i campioni generati.</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">nsamp</span><span class="p">)</span>

    <span class="c1"># Imposta il primo valore (valore iniziale) da cui partire per la generazione dei campioni.</span>
    <span class="n">x_prev</span> <span class="o">=</span> <span class="n">xinit</span>

    <span class="c1"># Inizia un ciclo che si ripeterà per il numero di volte specificato da nsamp (numero di campioni da generare).</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nsamp</span><span class="p">):</span>
        <span class="c1"># Genera un nuovo punto (x_star) usando una distribuzione normale (gaussiana).</span>
        <span class="c1"># Questo nuovo punto è generato in modo da essere &quot;vicino&quot; al punto precedente (x_prev),</span>
        <span class="c1"># con una deviazione standard di 0.1. Questo significa che la maggior parte dei punti</span>
        <span class="c1"># sarà entro 0.1 unità da x_prev, ma alcuni potrebbero essere più lontani.</span>
        <span class="n">x_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">x_prev</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

        <span class="c1"># Verifica che il nuovo punto (x_star) sia un valore plausibile nel contesto del problema.</span>
        <span class="c1"># Qui, l&#39;assunzione è che x_star debba essere tra 0 e 1. Se non lo è, il punto è rifiutato.</span>
        <span class="k">if</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">x_star</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Calcola il valore della funzione di densità di probabilità posterior per il nuovo punto e il punto precedente.</span>
            <span class="c1"># La funzione posterior è definita altrove e rappresenta il prodotto del prior e della likelihood.</span>
            <span class="n">p_star</span> <span class="o">=</span> <span class="n">posterior</span><span class="p">(</span><span class="n">x_star</span><span class="p">)</span>
            <span class="n">p_prev</span> <span class="o">=</span> <span class="n">posterior</span><span class="p">(</span><span class="n">x_prev</span><span class="p">)</span>

            <span class="c1"># Calcola il rapporto tra le densità posterior del nuovo punto e del punto precedente.</span>
            <span class="c1"># Questo rapporto determina la probabilità di accettare il nuovo punto.</span>
            <span class="c1"># Se p_prev è 0, per evitare la divisione per zero, il rapporto è impostato a 1.</span>
            <span class="n">pdfratio</span> <span class="o">=</span> <span class="n">p_star</span> <span class="o">/</span> <span class="n">p_prev</span> <span class="k">if</span> <span class="n">p_prev</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span>

            <span class="c1"># Genera un numero casuale tra 0 e 1.</span>
            <span class="n">random_chance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span>

            <span class="c1"># Calcola il rapporto tra la densità posteriore del nuovo punto e quella del punto precedente.</span>
            <span class="c1"># Se il nuovo punto è migliore o uguale, questo rapporto sarà &gt;= 1.</span>
            <span class="c1"># Se il nuovo punto è peggiore, il rapporto sarà un numero fra 0 e 1.</span>
            <span class="n">acceptance_probability</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">pdfratio</span><span class="p">)</span>

            <span class="c1"># Se il numero casuale è minore dell&#39;acceptance_probability, accettiamo il nuovo punto.</span>
            <span class="c1"># Ciò significa che un punto migliore o uguale viene sempre accettato (perché random_chance sarà sempre &lt; 1),</span>
            <span class="c1"># mentre un punto peggiore ha una possibilità basata sul quanto è peggiore.</span>
            <span class="k">if</span> <span class="n">random_chance</span> <span class="o">&lt;</span> <span class="n">acceptance_probability</span><span class="p">:</span>
                <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_star</span>  <span class="c1"># Accetta il nuovo punto.</span>
                <span class="n">x_prev</span> <span class="o">=</span> <span class="n">x_star</span>  <span class="c1"># Aggiorna il punto precedente con il nuovo punto accettato.</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_prev</span>  <span class="c1"># Mantiene il punto precedente se il nuovo punto non è accettato.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_prev</span>  <span class="c1"># Se x_star non è nel supporto, conserva il punto precedente.</span>

    <span class="c1"># Dopo aver generato il numero desiderato di campioni, ritorna l&#39;array dei campioni.</span>
    <span class="k">return</span> <span class="n">samples</span>
</pre></div>
</div>
</div>
</div>
<p>L’idea fondamentale dietro la fase dell’algoritmo di Metropolis successiva al calcolo di <code class="docutils literal notranslate"><span class="pre">p_star</span></code> e <code class="docutils literal notranslate"><span class="pre">p_prev</span></code> è decidere se «muoversi» verso un nuovo punto basandosi su quanto è probabile (o «buono») quel punto rispetto al punto attuale, in termini della densità posteriore. Qui, la «probabilità» di un punto è data dalla sua densità posteriore, che è un modo per misurare quanto bene un certo valore del parametro si adatta ai dati osservati, dato un modello.</p>
<p>Ecco come funziona:</p>
<ol class="arabic simple">
<li><p><strong>Generazione di un numero casuale</strong>.</p></li>
<li><p><strong>Confronto tra i punti</strong>: Si confronta il «valore» del nuovo punto (<code class="docutils literal notranslate"><span class="pre">x_star</span></code>) con quello del punto precedente (<code class="docutils literal notranslate"><span class="pre">x_prev</span></code>). Questo «valore» è dato dalla densità posteriore: più alto è, meglio è.</p></li>
<li><p><strong>Decisione</strong>:</p>
<ul class="simple">
<li><p>Se il nuovo punto è <strong>migliore</strong> del precedente (ovvero, ha una densità posteriore <strong>maggiore o uguale</strong>), lo accettiamo sempre.</p></li>
<li><p>Se il nuovo punto è <strong>peggiore</strong> del precedente (ha una densità posteriore <strong>minore</strong>), non lo rifiutiamo subito. Invece, gli diamo una chance di essere scelto, ma questa chance è più piccola quanto più il nuovo punto è «peggiore».</p></li>
</ul>
</li>
</ol>
<p>In termini di codice, questa logica si traduce così:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Genera un numero casuale tra 0 e 1.</span>
<span class="n">random_chance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span>

<span class="c1"># Calcola il rapporto tra la densità posteriore del nuovo punto e quella del punto precedente.</span>
<span class="c1"># Se il nuovo punto è migliore o uguale, questo rapporto sarà &gt;= 1.</span>
<span class="c1"># Se il nuovo punto è peggiore, il rapporto sarà un numero fra 0 e 1.</span>
<span class="n">acceptance_probability</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">pdfratio</span><span class="p">)</span>

<span class="c1"># Se il numero casuale è minore dell&#39;acceptance_probability, accettiamo il nuovo punto.</span>
<span class="c1"># Ciò significa che un punto migliore o uguale viene sempre accettato (perché random_chance sarà sempre &lt; 1),</span>
<span class="c1"># mentre un punto peggiore ha una possibilità basata sul quanto è peggiore.</span>
<span class="k">if</span> <span class="n">random_chance</span> <span class="o">&lt;</span> <span class="n">acceptance_probability</span><span class="p">:</span>
    <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_star</span>  <span class="c1"># Accetta il nuovo punto.</span>
    <span class="n">x_prev</span> <span class="o">=</span> <span class="n">x_star</span>      <span class="c1"># Aggiorna il punto precedente con il nuovo punto accettato.</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_prev</span>  <span class="c1"># Mantiene il punto precedente se il nuovo punto non è accettato.</span>
</pre></div>
</div>
<p>In sintesi, questo meccanismo consente all’algoritmo di esplorare lo spazio dei parametri in modo efficiente, accettando sempre miglioramenti e, occasionalmente, facendo passi in direzioni non ottimali per evitare di rimanere intrappolati in «minimi locali», ovvero in soluzioni che sembrano buone rispetto a quelle vicine ma non sono le migliori globalmente.</p>
<p>Si osservi un punto importante: nel calcolo di <code class="docutils literal notranslate"><span class="pre">pdfratio</span></code>, il rapporto tra la densità a posteriori del parametro proposto <code class="docutils literal notranslate"><span class="pre">x_star</span></code> e quella del parametro corrente <code class="docutils literal notranslate"><span class="pre">x_prev</span></code>, la costante di normalizzazione si annulla grazie alla regola di Bayes. Questo lascia nel rapporto solamente le componenti relative alla verosimiglianza e alla distribuzione a priori, che sono entrambe facilmente calcolabili. Matematicamente, questo si esprime come:</p>
<div class="math notranslate nohighlight" id="equation-eq-ratio-metropolis">
<span class="eqno">(50)<a class="headerlink" href="#equation-eq-ratio-metropolis" title="Link to this equation">#</a></span>\[
\begin{equation}
\text{pdfratio} = \frac{p(\theta^* \mid y)}{p(\theta^{\text{prev}} \mid y)} = \frac{\frac{p(y \mid \theta^*) p(\theta^*)}{p(y)}}{\frac{p(y \mid \theta^{\text{prev}}) p(\theta^{\text{prev}})}{p(y)}}
= \frac{p(y \mid \theta^*) p(\theta^*)}{p(y \mid \theta^{\text{prev}}) p(\theta^{\text{prev}})}
\end{equation}
\]</div>
<p>Eseguiamo dunque il campionamento usando l’algoritmo che abbiamo definito.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_samples</span> <span class="o">=</span> <span class="mi">100_000</span>
<span class="n">samps</span> <span class="o">=</span> <span class="n">metropolis_v2</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In somma, l’algoritmo Metropolis accetta come input il numero <code class="docutils literal notranslate"><span class="pre">nsamp</span></code> di passi da simulare e il punto di partenza. Come output, l’algoritmo restituisce una catena di valori del parametro, specificamente la sequenza <span class="math notranslate nohighlight">\( \theta^{(1)}, \theta^{(2)}, \ldots, \theta^{\text{nsamp}} \)</span>. Uno degli aspetti cruciali per la riuscita dell’algoritmo è il raggiungimento della stazionarietà da parte della catena. In genere, i primi 1000-5000 valori vengono scartati in quanto rappresentano il periodo di «burn-in» della catena. Dopo un determinato numero di passi <span class="math notranslate nohighlight">\( k \)</span>, la catena converge e i valori diventano campioni effettivi dalla distribuzione a posteriori <span class="math notranslate nohighlight">\( p(\theta \mid y) \)</span>.</p>
<p>Il modello descritto è stato inizialmente proposto da Metropolis et al. nel 1953 <span id="id3"></span>. Hastings nel 1970 introdusse un’estensione nota come algoritmo Metropolis-Hastings <span id="id4"></span>. Altre varianti includono il campionatore di Gibbs, introdotto da Geman e Geman nel 1984 <span id="id5">[]</span>, l’Hamiltonian Monte Carlo <span id="id6"></span>, e il No-U-Turn Sampler (NUTS) utilizzato in pacchetti come PyMC e Stan <span id="id7"></span>. Per un’analisi più dettagliata e intuitiva dell’algoritmo Metropolis, si rimanda a <span id="id8"></span>.</p>
<p>Un elemento chiave da considerare nell’uso dell’algoritmo Metropolis è il tasso di accettazione, che è il rapporto tra il numero di valori del parametro proposti e il numero di quei valori che vengono effettivamente accettati. Un limite di questo algoritmo è la sua inefficienza relativa: rispetto alle sue varianti più moderne, l’algoritmo Metropolis tende ad essere meno efficiente.</p>
</section>
</section>
<section id="aspetti-computazionali">
<h2>Aspetti computazionali<a class="headerlink" href="#aspetti-computazionali" title="Link to this heading">#</a></h2>
<section id="warm-up-burn-in">
<h3>Warm-up/Burn-in<a class="headerlink" href="#warm-up-burn-in" title="Link to this heading">#</a></h3>
<p>Una catena di Markov ha bisogno di alcune iterazioni per raggiungere la distribuzione stazionaria. Queste iterazioni sono comunemente chiamate iterazioni di warm-up o burn-in (a seconda dell’algoritmo e del software utilizzato) e vengono di solito scartate. In molti programmi software, la prima metà delle iterazioni viene considerata come iterazioni di warm-up, quindi, nel caso presente, anche se abbiamo ottenuto 100000 iterazioni, ne utilizzeremo solo 50000.</p>
</section>
<section id="sintesi-della-distribuzione-a-posteriori">
<h3>Sintesi della distribuzione a posteriori<a class="headerlink" href="#sintesi-della-distribuzione-a-posteriori" title="Link to this heading">#</a></h3>
<p>L’array <code class="docutils literal notranslate"><span class="pre">samps</span></code> contiene 100000 valori di una catena di Markov. Escludiamo i primi 50000 valori considerati come burn-in e consideriamo i restanti 50000 valori come un campione casuale estratto dalla distribuzione a posteriori <span class="math notranslate nohighlight">\(p(\theta \mid y)\)</span>.</p>
<p>Mediante i valori della catena così ottenuta è facile trovare una stima a posteriori del parametro <span class="math notranslate nohighlight">\(\theta\)</span>. Per esempio, possiamo trovare la stima della media a posteriori.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">burnin</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">*</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">burnin</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>50000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samps</span><span class="p">[</span><span class="n">burnin</span><span class="p">:])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.16333189691090788
</pre></div>
</div>
</div>
</div>
<p>Oppure possiamo stimare la deviazione standard della distribuzione a posteriori.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">samps</span><span class="p">[</span><span class="n">burnin</span><span class="p">:])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.03529394100872187
</pre></div>
</div>
</div>
</div>
<p>Visualizziamo un <em>trace plot</em> dei valori della catena di Markov dopo il periodo di burn-in.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samps</span><span class="p">[</span><span class="n">burnin</span><span class="p">:])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;sample&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;theta&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/4e22b0195357b710f6ef9a5949f66fbfc7e2703827f81ef3390d4b815bebc3bb.png"><img alt="../_images/4e22b0195357b710f6ef9a5949f66fbfc7e2703827f81ef3390d4b815bebc3bb.png" src="../_images/4e22b0195357b710f6ef9a5949f66fbfc7e2703827f81ef3390d4b815bebc3bb.png" style="width: 731px; height: 491px;" /></a>
</div>
</div>
<p>Il trace plot indica che la catena inizia con un valore casuale per poi spostarsi rapidamente nell’area intorno a 0.16, che è l’area con alta densità a posteriori. Successivamente, oscilla intorno a quel valore per le iterazioni successive.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samps</span><span class="p">[:</span><span class="mi">500</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;sample&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;theta&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/da610ba6c51f45cbdf3fef64ee708df802788ac4e24fc53feca362222e3f1175.png"><img alt="../_images/da610ba6c51f45cbdf3fef64ee708df802788ac4e24fc53feca362222e3f1175.png" src="../_images/da610ba6c51f45cbdf3fef64ee708df802788ac4e24fc53feca362222e3f1175.png" style="width: 731px; height: 491px;" /></a>
</div>
</div>
<p>L’istogramma mostrato di seguito, sul quale è stata sovrapposta la distribuzione a posteriori derivata analiticamente – specificamente una <span class="math notranslate nohighlight">\(\text{Beta}(25, 17)\)</span> – dimostra che la catena converge effettivamente alla distribuzione a posteriori desiderata.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samps</span><span class="p">[</span><span class="n">burnin</span><span class="p">:],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;MCMC distribution&quot;</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># plot the true function</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">92</span><span class="p">),</span> <span class="s2">&quot;C0&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;True distribution&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/d8827350b89bc5362c5b532ddf2ad60c559ebe596baee23db64a73b4b2203fc6.png"><img alt="../_images/d8827350b89bc5362c5b532ddf2ad60c559ebe596baee23db64a73b4b2203fc6.png" src="../_images/d8827350b89bc5362c5b532ddf2ad60c559ebe596baee23db64a73b4b2203fc6.png" style="width: 731px; height: 491px;" /></a>
</div>
</div>
<p>È possibile usare la funzione <code class="docutils literal notranslate"><span class="pre">summary</span></code> del pacchetto AriviZ per calolare l’intervallo di credibilità, ovvero l’intervallo che contiene la proporzione indicata dei valori estratti a caso dalla distribuzione a posteriori.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">samps</span><span class="p">[</span><span class="n">burnin</span><span class="p">:],</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;stats&quot;</span><span class="p">,</span> <span class="n">hdi_prob</span><span class="o">=</span><span class="mf">0.94</span><span class="p">,</span> <span class="n">round_to</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>x</th>
      <td>0.16</td>
      <td>0.04</td>
      <td>0.1</td>
      <td>0.23</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Un KDE plot corrispondente all’istogramma precedente si può generare usando <code class="docutils literal notranslate"><span class="pre">az.plot_posterior()</span></code>. La curva  rappresenta l’intera distribuzione a posteriori e viene calcolata utilizzando la stima della densità del kernel (KDE) che serve a «lisciare» l’istogramma.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_posterior</span><span class="p">(</span><span class="n">samps</span><span class="p">[</span><span class="n">burnin</span><span class="p">:])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/9d06eb2cc9b1864a360b940d1be28f395060a7e2ba602e2440dcbae5fd910530.png"><img alt="../_images/9d06eb2cc9b1864a360b940d1be28f395060a7e2ba602e2440dcbae5fd910530.png" src="../_images/9d06eb2cc9b1864a360b940d1be28f395060a7e2ba602e2440dcbae5fd910530.png" style="width: 731px; height: 491px;" /></a>
</div>
</div>
<p>L’HDI è una scelta comune nelle statistiche bayesiane e valori arrotondati come 50% o 95% sono molto popolari. Ma ArviZ utilizza il 94% come valore predefinito. La ragione di questa scelta è che il 94% è vicino al valore ampiamente utilizzato del 95%, ma è anche diverso da questo, così da servire da «amichevole promemoria» che non c’è niente di speciale nella soglia del 5%. Idealmente sarebbe opportuno scegliere un valore che si adatti alle specifiche esigenze dell’analisi statistica che si sta svolgendo, o almeno riconoscere che si sta usando un valore arbitrario.</p>
</section>
</section>
<section id="diagnostiche-della-soluzione-mcmc">
<h2>Diagnostiche della soluzione MCMC<a class="headerlink" href="#diagnostiche-della-soluzione-mcmc" title="Link to this heading">#</a></h2>
<section id="catene-multiple">
<h3>Catene multiple<a class="headerlink" href="#catene-multiple" title="Link to this heading">#</a></h3>
<p>Poiché ciascuno stato in una catena di Markov dipende dagli stati precedenti, il valore o i valori iniziali possono influenzare i valori campionati. Una soluzione per verificare la sensibilità rispetto ai valori iniziali è utilizzare più catene, ognuna con diversi valori iniziali. Se più catene campionano la stessa distribuzione target, queste dovrebbero mescolarsi bene, ovvero intersecarsi l’una con l’altra in un trace plot.</p>
</section>
<section id="stazionarieta">
<h3>Stazionarietà<a class="headerlink" href="#stazionarieta" title="Link to this heading">#</a></h3>
<p>Un punto importante da verificare è se il campionatore ha raggiunto la sua distribuzione stazionaria. La convergenza di una catena di Markov alla distribuzione stazionaria viene detta «mixing».</p>
</section>
<section id="autocorrelazione">
<h3>Autocorrelazione<a class="headerlink" href="#autocorrelazione" title="Link to this heading">#</a></h3>
<p>Ogni passo nell’algoritmo MCMC è chiamato <em>iterazione</em>. I valori campionati sono dipendenti, il che significa che il valore all’iterazione <span class="math notranslate nohighlight">\(m\)</span> dipende dal valore all’iterazione <span class="math notranslate nohighlight">\(m-1\)</span>. Questa è una differenza importante rispetto alle funzioni che generano campioni casuali indipendenti, come <code class="docutils literal notranslate"><span class="pre">beta(25,</span> <span class="pre">17).rvs()</span></code>. I valori campionati formano una <em>catena di Markov</em>, il che significa che ciascun valore campionato è correlato con il valore precedente (ad esempio, se <span class="math notranslate nohighlight">\(\theta(m)\)</span> è grande, <span class="math notranslate nohighlight">\(\theta(m+1)\)</span> sarà anch’esso grande).</p>
<p>Informazioni sul «mixing» della catena di Markov sono fornite dall’autocorrelazione. L’autocorrelazione misura la correlazione tra i valori successivi di una catena di Markov. Il valore <span class="math notranslate nohighlight">\(m\)</span>-esimo della serie ordinata viene confrontato con un altro valore ritardato di una quantità <span class="math notranslate nohighlight">\(k\)</span> (dove <span class="math notranslate nohighlight">\(k\)</span> è l’entità del ritardo) per verificare quanto si correli al variare di <span class="math notranslate nohighlight">\(k\)</span>. L’autocorrelazione di ordine 1 (<em>lag 1</em>) misura la correlazione tra valori successivi della catena di Markow (cioè, la correlazione tra <span class="math notranslate nohighlight">\(\theta^{(m)}\)</span> e <span class="math notranslate nohighlight">\(\theta^{(m-1)}\)</span>); l’autocorrelazione di ordine 2 (<em>lag 2</em>) misura la correlazione tra valori della catena di Markow separati da due «passi» (cioè, la correlazione tra <span class="math notranslate nohighlight">\(\theta^{(m)}\)</span> e <span class="math notranslate nohighlight">\(\theta^{(m-2)}\)</span>); e così via.</p>
<p>L’autocorrelazione di ordine <span class="math notranslate nohighlight">\(k\)</span> è data da <span class="math notranslate nohighlight">\(\rho_k\)</span> e può essere stimata come:</p>
<div class="math notranslate nohighlight" id="equation-eq-autocor">
<span class="eqno">(51)<a class="headerlink" href="#equation-eq-autocor" title="Link to this equation">#</a></span>\[\begin{split}
\begin{align}
\rho_k &amp;= \frac{Cov(\theta_m, \theta_{m+k})}{Var(\theta_m)}\notag\\
&amp;= \frac{\sum_{m=1}^{n-k}(\theta_m - \bar{\theta})(\theta_{m-k} - \bar{\theta})}{\sum_{m=1}^{n-k}(\theta_m - \bar{\theta})^2} \qquad\text{con }\quad \bar{\theta} = \frac{1}{n}\sum_{m=1}^{n}\theta_m.
\end{align}
\end{split}\]</div>
<p>Per fare un esempio pratico, simuliamo dei dati autocorrelati.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">22</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">29</span><span class="p">,</span> <span class="mi">34</span><span class="p">,</span> <span class="mi">37</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">44</span><span class="p">,</span> <span class="mi">51</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">47</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">51</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;IntegerArray&gt;
[22, 24, 25, 25, 28, 29, 34, 37, 40, 44, 51, 48, 47, 50, 51]
Length: 15, dtype: Int64
</pre></div>
</div>
</div>
</div>
<p>L’autocorrelazione di ordine 1 è semplicemente la correlazione tra ciascun elemento e quello successivo nella sequenza.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sm</span><span class="o">.</span><span class="n">tsa</span><span class="o">.</span><span class="n">acf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 1.        ,  0.83174224,  0.65632458,  0.49105012,  0.27863962,
        0.03102625, -0.16527446, -0.30369928, -0.40095465, -0.45823389,
       -0.45047733, -0.36933174])
</pre></div>
</div>
</div>
</div>
<p>Nell’esempio, il vettore <code class="docutils literal notranslate"><span class="pre">x</span></code> è una sequenza temporale di 15 elementi. Il vettore <span class="math notranslate nohighlight">\(x'\)</span> include gli elementi con gli indici da 0 a 13 nella sequenza originaria, mentre il vettore <span class="math notranslate nohighlight">\(x''\)</span> include gli elementi 1:14. Gli elementi delle coppie ordinate dei due vettori avranno dunque gli indici <span class="math notranslate nohighlight">\((0, 1)\)</span>, <span class="math notranslate nohighlight">\((1, 2), (2, 3), \dots (13, 14)\)</span> degli elementi della sequenza originaria. La correlazione di Pearson tra i vettori <span class="math notranslate nohighlight">\(x'\)</span> e <span class="math notranslate nohighlight">\(x''\)</span> corrisponde all’autocorrelazione di ordine 1 della serie temporale.</p>
<p>Nell’output precedente</p>
<ul class="simple">
<li><p>0.83174224 è l’autocorrelazione di ordine 1 (lag = 1),</p></li>
<li><p>0.65632458 è l’autocorrelazione di ordine 2 (lag = 2),</p></li>
<li><p>0.49105012 è l’autocorrelazione di ordine 3 (lag = 3),</p></li>
<li><p>ecc.</p></li>
</ul>
<p>È possibile specificare il numero di ritardi (<em>lag</em>) da utilizzare con l’argomento <code class="docutils literal notranslate"><span class="pre">nlags</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sm</span><span class="o">.</span><span class="n">tsa</span><span class="o">.</span><span class="n">acf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">nlags</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1.        , 0.83174224, 0.65632458, 0.49105012, 0.27863962])
</pre></div>
</div>
</div>
</div>
<p>In Python possiamo creare un grafico della funzione di autocorrelazione (correlogramma) per una serie temporale usando la funzione <code class="docutils literal notranslate"><span class="pre">tsaplots.plot_acf()</span></code> dalla libreria <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tsaplots</span><span class="o">.</span><span class="n">plot_acf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lags</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/15cec27c297c111ba85181c29c0893664833d386c3ffbe3b26b243aeb1a6b5d3.png"><img alt="../_images/15cec27c297c111ba85181c29c0893664833d386c3ffbe3b26b243aeb1a6b5d3.png" src="../_images/15cec27c297c111ba85181c29c0893664833d386c3ffbe3b26b243aeb1a6b5d3.png" style="width: 731px; height: 491px;" /></a>
</div>
</div>
<p>Per i dati dell’esempio in discussione otteniamo la situazione seguente.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tsaplots</span><span class="o">.</span><span class="n">plot_acf</span><span class="p">(</span><span class="n">samps</span><span class="p">[</span><span class="n">burnin</span><span class="p">:],</span> <span class="n">lags</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/b97f14f879836ad0d00c1d9745c14c0f2b23d1dc22824ea4607b21eca5cb7ccd.png"><img alt="../_images/b97f14f879836ad0d00c1d9745c14c0f2b23d1dc22824ea4607b21eca5cb7ccd.png" src="../_images/b97f14f879836ad0d00c1d9745c14c0f2b23d1dc22824ea4607b21eca5cb7ccd.png" style="width: 731px; height: 491px;" /></a>
</div>
</div>
<p>Il correlogramma è uno strumento grafico usato per la valutazione della tendenza di una catena di Markov nel tempo. Il correlogramma si costruisce a partire dall’autocorrelazione <span class="math notranslate nohighlight">\(\rho_k\)</span> di una catena di Markov in funzione del ritardo <span class="math notranslate nohighlight">\(k\)</span> con cui l’autocorrelazione è calcolata: nel grafico ogni barretta verticale riporta il valore dell’autocorrelazione (sull’asse delle ordinate) in funzione del ritardo (sull’asse delle ascisse).</p>
<p>In situazioni ottimali l’autocorrelazione diminuisce rapidamente ed è effettivamente pari a 0 per piccoli lag. Ciò indica che i valori della catena di Markov che si trovano a più di soli pochi passi di distanza gli uni dagli altri non risultano associati tra loro, il che fornisce una conferma del «mixing» della catena di Markov, ossia della convergenza alla distribuzione stazionaria. Nelle analisi bayesiane, una delle strategie che consentono di ridurre l’autocorrelazione è quella di assottigliare l’output immagazzinando solo ogni <span class="math notranslate nohighlight">\(m\)</span>-esimo punto dopo il periodo di burn-in. Una tale strategia va sotto il nome di <em>thinning</em>.</p>
<p>Nel seguente correlogramma, analizziamo la medesima catena di Markov. Tuttavia, in questa occasione applichiamo un «thinning» (sottocampionamento) con un fattore di 5.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">thin</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">sampsthin</span> <span class="o">=</span> <span class="n">samps</span><span class="p">[</span><span class="n">burnin</span><span class="p">::</span><span class="n">thin</span><span class="p">]</span>
<span class="n">tsaplots</span><span class="o">.</span><span class="n">plot_acf</span><span class="p">(</span><span class="n">sampsthin</span><span class="p">,</span> <span class="n">lags</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/bb29cfba032bb54a598088b3f481458d033e8928bf2f605dd8a3c3d9f580011f.png"><img alt="../_images/bb29cfba032bb54a598088b3f481458d033e8928bf2f605dd8a3c3d9f580011f.png" src="../_images/bb29cfba032bb54a598088b3f481458d033e8928bf2f605dd8a3c3d9f580011f.png" style="width: 731px; height: 491px;" /></a>
</div>
</div>
<p>Si può notare come l’autocorrelazione diminuisce molto più rapidamente.</p>
<section id="tasso-di-accettazione">
<h4>Tasso di accettazione<a class="headerlink" href="#tasso-di-accettazione" title="Link to this heading">#</a></h4>
<p>Quando si utilizza l’algoritmo Metropolis, è importante monitorare il tasso di accettazione e assicurarsi che sia nell’intervallo ottimale. Se si accetta quasi sempre il candidato proposto, probabilmente significa che, in ogni iterazione, la catena salta solo di un piccolo passo (in modo che il rapporto di accettazione sia vicino a 1 ogni volta). Di conseguenza, la catena impiegherà molte iterazioni per raggiungere altre regioni della distribuzione stazionaria e i campioni consecutivi saranno molto fortemente correlati. D’altra parte, se il tasso di accettazione è molto basso, la catena rimarrà bloccata nella stessa posizione per molte iterazioni prima di spostarsi verso uno stato diverso. Per l’algoritmo Metropolis base con un singolo parametro con una distribuzione proposta Gaussiana normale, un tasso di accettazione ottimale è compreso tra il 40% e il 50%.</p>
</section>
<section id="test-di-convergenza">
<h4>Test di convergenza<a class="headerlink" href="#test-di-convergenza" title="Link to this heading">#</a></h4>
<p>Per valutare la convergenza di una catena di Markov Monte Carlo (MCMC), esistono diversi metodi, tra cui approcci grafici e test statistici. Ecco una spiegazione più chiara e dettagliata:</p>
</section>
</section>
<section id="approcci-grafici-tracce-delle-serie-temporali-trace-plots">
<h3>Approcci Grafici: Tracce delle Serie Temporali (Trace Plots)<a class="headerlink" href="#approcci-grafici-tracce-delle-serie-temporali-trace-plots" title="Link to this heading">#</a></h3>
<p>Le tracce delle serie temporali, o trace plots, sono grafici che mostrano l’evoluzione dei valori campionati rispetto al numero di iterazioni. Questi grafici sono utili per valutare visivamente se la catena ha raggiunto la convergenza. Segni che indicano una potenziale convergenza includono:</p>
<ul class="simple">
<li><p><strong>Assenza di Tendenze</strong>: Non ci sono trend ascendenti o discendenti nel corso delle iterazioni.</p></li>
<li><p><strong>Costanza dell’Ampiezza</strong>: La variabilità dei valori campionati rimane costante nel tempo, senza significative fluttuazioni.</p></li>
<li><p><strong>Mancanza di Periodicità</strong>: Non si osservano cicli o ripetizioni regolari che potrebbero indicare la presenza di correlazioni residue.</p></li>
</ul>
</section>
<section id="test-statistici-per-la-convergenza">
<h3>Test Statistici per la Convergenza<a class="headerlink" href="#test-statistici-per-la-convergenza" title="Link to this heading">#</a></h3>
<p>Oltre agli approcci grafici, esistono test statistici specifici che possono aiutare a determinare se la catena ha raggiunto uno stato stazionario.</p>
<section id="test-di-geweke">
<h4>Test di Geweke<a class="headerlink" href="#test-di-geweke" title="Link to this heading">#</a></h4>
<p>Il test di Geweke è una procedura che confronta le medie di due segmenti della catena di campionamento, tipicamente il primo 10% e l’ultimo 50% dei campioni, dopo aver escluso un iniziale periodo di «burn-in» (una fase iniziale durante la quale la catena potrebbe non essere ancora convergente). La premessa di base è che, se la catena è in uno stato stazionario, le medie di questi due segmenti dovrebbero essere sostanzialmente uguali. Differenze significative tra queste medie possono indicare che la catena non ha ancora raggiunto la convergenza.</p>
</section>
<section id="geweke-z-score">
<h4>Geweke Z-score<a class="headerlink" href="#geweke-z-score" title="Link to this heading">#</a></h4>
<p>Una variante del test di Geweke è lo z-score di Geweke, che offre un modo quantitativo per valutare le differenze tra i segmenti della catena. Questo test calcola uno z-score che confronta le medie dei due segmenti tenendo conto della varianza. Un valore di z-score:</p>
<ul class="simple">
<li><p><strong>Al di sotto di 2 (in valore assoluto)</strong> suggerisce che non ci sono differenze significative tra i segmenti, indicando che la catena potrebbe essere in stato stazionario.</p></li>
<li><p><strong>Superiore a 2 (in valore assoluto)</strong> indica che esiste una differenza significativa tra i segmenti, suggerendo che la catena non ha raggiunto la convergenza e potrebbe essere necessario un periodo di burn-in più esteso.</p></li>
</ul>
<p>Entrambi i metodi forniscono strumenti utili per valutare la convergenza delle catene MCMC. È importante notare che nessun test può garantire con certezza la convergenza, ma l’utilizzo congiunto di approcci grafici e test statistici può offrire una buona indicazione dello stato della catena.</p>
</section>
</section>
<section id="effective-sample-size-ess">
<h3>Effective sample size (ESS)<a class="headerlink" href="#effective-sample-size-ess" title="Link to this heading">#</a></h3>
<p>Quando le iterazioni sono dipendenti, ogni iterazione contiene informazioni sovrapposte con le iterazioni precedenti. In altre parole, quando si ottengono 500 campioni dipendenti dalla distribuzione a posteriori, questi contengono solo informazioni equivalenti a &lt; 500 campioni indipendenti. L’ESS (Effective Sample Size) quantifica la quantità effettiva di informazioni, quindi una catena con ESS = n conterrà approssimativamente la stessa quantità di informazioni di n campioni indipendenti. In generale, vogliamo che l’ESS sia almeno 400 per un’utilizzazione generale nel riassumere la distribuzione a posteriori.</p>
</section>
</section>
<section id="caso-normale-normale">
<h2>Caso Normale-Normale<a class="headerlink" href="#caso-normale-normale" title="Link to this heading">#</a></h2>
<p>Consideriamo ora il caso Normale-Normale di cui è possibile trovare una soluzione analitica. Supponiamo, come prior, una <span class="math notranslate nohighlight">\(\mathcal{N}(30, 5\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prior</span><span class="p">(</span><span class="n">mu</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Per la verosimiglianza del parametro <span class="math notranslate nohighlight">\(\mu\)</span>, supponiamo <span class="math notranslate nohighlight">\(\sigma\)</span> nota e uguale alla deviazione standard del campione.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">likelihood</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="n">std_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>  <span class="c1"># Calcola la deviazione standard dei dati</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">std_data</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Definiamo il posterior non normalizzato:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">posterior</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">likelihood</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="n">prior</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Modifichiamo ora l’algoritmo di Metropolis descritto sopra per adattarlo al caso presente.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Algoritmo di Metropolis per il caso normale-normale</span>
<span class="k">def</span> <span class="nf">metropolis_for_normal</span><span class="p">(</span><span class="n">nsamp</span><span class="p">,</span> <span class="n">xinit</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">nsamp</span><span class="p">)</span>
    <span class="n">x_prev</span> <span class="o">=</span> <span class="n">xinit</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nsamp</span><span class="p">):</span>
        <span class="n">x_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">x_prev</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>  <span class="c1"># Genera un nuovo punto dalla proposta</span>

        <span class="c1"># Calcola il rapporto di accettazione e accetta il nuovo punto con una certa probabilità</span>
        <span class="k">if</span> <span class="n">posterior</span><span class="p">(</span><span class="n">x_star</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> <span class="o">/</span> <span class="n">posterior</span><span class="p">(</span><span class="n">x_prev</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">():</span>
            <span class="n">x_prev</span> <span class="o">=</span> <span class="n">x_star</span>

        <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_prev</span>

    <span class="k">return</span> <span class="n">samples</span>
</pre></div>
</div>
</div>
</div>
<p>Vediamo cosa fa la presente versione dell’algoritmo di Metropolis passo dopo passo:</p>
<ol class="arabic simple">
<li><p><strong>Ciclo sui Campioni</strong>: <code class="docutils literal notranslate"><span class="pre">for</span> <span class="pre">i</span> <span class="pre">in</span> <span class="pre">range(nsamp):</span></code> inizia un ciclo che si ripeterà <code class="docutils literal notranslate"><span class="pre">nsamp</span></code> volte, dove <code class="docutils literal notranslate"><span class="pre">nsamp</span></code> è il numero totale di campioni che vogliamo generare. Ogni iterazione di questo ciclo produrrà un campione dalla distribuzione di interesse.</p></li>
<li><p><strong>Generazione di un Nuovo Punto</strong>: <code class="docutils literal notranslate"><span class="pre">x_star</span> <span class="pre">=</span> <span class="pre">np.random.normal(x_prev,</span> <span class="pre">0.5)</span></code> genera un nuovo punto (<code class="docutils literal notranslate"><span class="pre">x_star</span></code>) come proposta per il prossimo passo del campionamento. Questo è fatto campionando da una distribuzione normale con media uguale all’ultimo punto accettato (<code class="docutils literal notranslate"><span class="pre">x_prev</span></code>) e una deviazione standard di <code class="docutils literal notranslate"><span class="pre">0.5</span></code>. Questa distribuzione è detta distribuzione di proposta e serve a esplorare lo spazio dei parametri.</p></li>
<li><p><strong>Calcolo del Rapporto di Accettazione</strong>:</p>
<ul class="simple">
<li><p>Il rapporto di accettazione è calcolato come <code class="docutils literal notranslate"><span class="pre">posterior(x_star,</span> <span class="pre">data)</span> <span class="pre">/</span> <span class="pre">posterior(x_prev,</span> <span class="pre">data)</span></code>, che è il rapporto tra la probabilità del posterior del nuovo punto proposto (<code class="docutils literal notranslate"><span class="pre">x_star</span></code>) e la probabilità del posterior dell’ultimo punto accettato (<code class="docutils literal notranslate"><span class="pre">x_prev</span></code>).</p></li>
<li><p>Questo rapporto indica quanto sia preferibile il nuovo punto rispetto al precedente, basandosi sulla funzione <code class="docutils literal notranslate"><span class="pre">posterior</span></code>, che calcola la probabilità a posteriori del modello dato il parametro e i dati osservati.</p></li>
</ul>
</li>
<li><p><strong>Decisione di Accettazione del Nuovo Punto</strong>:</p>
<ul class="simple">
<li><p>La decisione se accettare o meno il nuovo punto (<code class="docutils literal notranslate"><span class="pre">x_star</span></code>) si basa su un confronto del rapporto di accettazione con un numero casuale uniformemente distribuito tra 0 e 1 (<code class="docutils literal notranslate"><span class="pre">np.random.uniform()</span></code>).</p></li>
<li><p>Se il rapporto di accettazione è maggiore di questo numero casuale, il nuovo punto è accettato come il prossimo punto nella catena (<code class="docutils literal notranslate"><span class="pre">x_prev</span> <span class="pre">=</span> <span class="pre">x_star</span></code>). Ciò significa che il nuovo punto ha una probabilità a posteriori più alta rispetto al punto precedente, o è stato «fortunato» nel processo di selezione casuale, consentendo all’algoritmo di esplorare lo spazio dei parametri anche in zone di minore probabilità.</p></li>
<li><p>Se il nuovo punto non viene accettato, la catena rimane nel punto precedente (<code class="docutils literal notranslate"><span class="pre">x_prev</span></code>), e questo punto viene nuovamente aggiunto all’array dei campioni.</p></li>
</ul>
</li>
<li><p><strong>Salvataggio del Campione</strong>: <code class="docutils literal notranslate"><span class="pre">samples[i]</span> <span class="pre">=</span> <span class="pre">x_prev</span></code> salva il punto corrente (che può essere il nuovo punto accettato o il punto precedente se il nuovo punto è stato rifiutato) nell’array <code class="docutils literal notranslate"><span class="pre">samples</span></code>. Questo processo si ripete fino a quando non si raggiunge il numero desiderato di campioni.</p></li>
</ol>
<p>Come dati, usiamo il campione di 30 valori BDI-II ottenuti dai soggetti clinici esaminati da <span id="id9">[]</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="mf">26.0</span><span class="p">,</span> <span class="mf">35.0</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">44</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">43</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">43</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">39</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">26</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span>
    <span class="mi">41</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="mi">26</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">27</span><span class="p">,</span> <span class="mi">34</span><span class="p">,</span> <span class="mi">27</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Procediamo con l’esecuzione dell’algoritmo di Metropolis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">samples</span> <span class="o">=</span> <span class="n">metropolis_for_normal</span><span class="p">(</span><span class="mi">100_000</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
<span class="n">samples</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(100000,)
</pre></div>
</div>
</div>
</div>
<section id="calcolo-dei-parametri-del-posterior-analitico">
<h3>Calcolo dei Parametri del Posterior Analitico<a class="headerlink" href="#calcolo-dei-parametri-del-posterior-analitico" title="Link to this heading">#</a></h3>
<p>Nel caso normale-normale, possiamo derivare analiticamente la distribuzione posteriore quando sia il prior che la likelihood sono distribuzioni normali. La bellezza di questo approccio sta nella forma chiusa del posterior, che è anch’esso una distribuzione normale con parametri specifici facilmente calcolabili. Ecco come si fa:</p>
<ol class="arabic">
<li><p><strong>Media Posteriore (<span class="math notranslate nohighlight">\(\mu_{post}\)</span>)</strong>: La media del posterior è un peso tra la media del campione e la media del prior, dove i pesi sono determinati dalle varianze del prior e dei dati.</p>
<div class="math notranslate nohighlight">
\[ 
   \mu_{post} = \frac{\frac{\mu_{prior}}{\sigma_{prior}^2} + \frac{\sum y_i}{\sigma_{data}^2}}{\frac{1}{\sigma_{prior}^2} + \frac{n}{\sigma_{data}^2}} 
   \]</div>
</li>
<li><p><strong>Varianza Posteriore (<span class="math notranslate nohighlight">\(\sigma_{post}^2\)</span>)</strong>: La varianza del posterior è determinata dalle varianze del prior e dei dati.</p>
<div class="math notranslate nohighlight">
\[ 
   \sigma_{post}^2 = \left(\frac{1}{\sigma_{prior}^2} + \frac{n}{\sigma_{data}^2}\right)^{-1} 
   \]</div>
</li>
</ol>
<p>Dove:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mu_{prior}\)</span> è la media del prior (in questo caso, 30),</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma_{prior}^2\)</span> è la varianza del prior (<span class="math notranslate nohighlight">\(5^2\)</span> in questo caso),</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma_{data}^2\)</span> è la varianza dei dati (calcolata dai dati),</p></li>
<li><p><span class="math notranslate nohighlight">\(n\)</span> è il numero di osservazioni,</p></li>
<li><p><span class="math notranslate nohighlight">\(\sum y_i\)</span> è la somma delle osservazioni.</p></li>
</ul>
</section>
<section id="codice-per-il-grafico">
<h3>Codice per il Grafico<a class="headerlink" href="#codice-per-il-grafico" title="Link to this heading">#</a></h3>
<p>Per produrre il grafico con l’istogramma dei campioni dal posterior (usando l’algoritmo di Metropolis) e la curva della distribuzione posteriore analitica, usiamo i parametri calcolati:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Parametri del prior</span>
<span class="n">mu_prior</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">std_prior</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">var_prior</span> <span class="o">=</span> <span class="n">std_prior</span> <span class="o">**</span> <span class="mi">2</span>

<span class="c1"># Dati osservati</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">sum_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">var_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># ddof=1 for sample variance</span>

<span class="c1"># Calcolo dei parametri posterior</span>
<span class="n">mu_post</span> <span class="o">=</span> <span class="p">(</span><span class="n">mu_prior</span> <span class="o">/</span> <span class="n">var_prior</span> <span class="o">+</span> <span class="n">sum_y</span> <span class="o">/</span> <span class="n">var_data</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">var_prior</span> <span class="o">+</span> <span class="n">n</span> <span class="o">/</span> <span class="n">var_data</span><span class="p">)</span>
<span class="n">var_post</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">var_prior</span> <span class="o">+</span> <span class="n">n</span> <span class="o">/</span> <span class="n">var_data</span><span class="p">)</span>
<span class="n">std_post</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var_post</span><span class="p">)</span>

<span class="c1"># Generazione dei punti x per il grafico</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">mu_post</span> <span class="o">-</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">std_post</span><span class="p">,</span> <span class="n">mu_post</span> <span class="o">+</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">std_post</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># Istogramma dei campioni dal posterior</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="n">burnin</span><span class="p">:],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;MCMC Samples Distribution&quot;</span><span class="p">)</span>

<span class="c1"># Curva della distribuzione posteriore analitica</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu_post</span><span class="p">,</span> <span class="n">std_post</span><span class="p">),</span> <span class="s2">&quot;C1&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Analytical Posterior Distribution&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/1683d7349fdccdb4784807d20c03bdc7f00010c9217892d217f5ccce4824b999.png"><img alt="../_images/1683d7349fdccdb4784807d20c03bdc7f00010c9217892d217f5ccce4824b999.png" src="../_images/1683d7349fdccdb4784807d20c03bdc7f00010c9217892d217f5ccce4824b999.png" style="width: 731px; height: 491px;" /></a>
</div>
</div>
<p>Questo codice mostra come integrare l’analisi MCMC con l’approccio analitico per il caso normale-normale, offrendo sia una visualizzazione dei risultati del sampling che la conferma attraverso la soluzione analitica.</p>
</section>
</section>
<section id="commenti-e-considerazioni-finali">
<h2>Commenti e considerazioni finali<a class="headerlink" href="#commenti-e-considerazioni-finali" title="Link to this heading">#</a></h2>
<p>In generale, la distribuzione a posteriori dei parametri di un modello statistico non può essere determinata per via analitica. Tale problema viene invece affrontato facendo ricorso ad una classe di algoritmi per il campionamento da distribuzioni di probabilità che sono estremamente onerosi dal punto di vista computazionale e che possono essere utilizzati nelle applicazioni pratiche solo grazie alla potenza di calcolo dei moderni computer. Lo sviluppo di software che rendono sempre più semplice l’uso dei metodi MCMC, insieme all’incremento della potenza di calcolo dei computer, ha contribuito a rendere sempre più popolare il metodo dell’inferenza bayesiana che, in questo modo, può essere estesa a problemi di qualunque grado di complessità.</p>
</section>
<section id="informazioni-sull-ambiente-di-sviluppo">
<h2>Informazioni sull’Ambiente di Sviluppo<a class="headerlink" href="#informazioni-sull-ambiente-di-sviluppo" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> watermark
<span class="o">%</span><span class="k">watermark</span> -n -u -v -iv -w -m
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Last updated: Sun Jun 16 2024

Python implementation: CPython
Python version       : 3.12.3
IPython version      : 8.25.0

Compiler    : Clang 16.0.6 
OS          : Darwin
Release     : 23.4.0
Machine     : arm64
Processor   : arm
CPU cores   : 8
Architecture: 64bit

statsmodels: 0.14.2
pandas     : 2.2.2
arviz      : 0.18.0
scipy      : 1.13.1
matplotlib : 3.8.4
numpy      : 1.26.4

Watermark: 2.4.3
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter_4"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="06_balance-prior-post.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">precedente</p>
        <p class="prev-next-title">L’influenza della distribuzione a priori</p>
      </div>
    </a>
    <a class="right-next"
       href="15_stan_beta_binomial.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">successivo</p>
        <p class="prev-next-title">Introduzione a Stan</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contenuti
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparazione-del-notebook">Preparazione del Notebook</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#il-denominatore-bayesiano">Il denominatore bayesiano</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#il-metodo-di-monte-carlo">Il Metodo di Monte Carlo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#le-catene-di-markov">Le Catene di Markov</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estrazione-di-campioni-dalla-distribuzione-a-posteriori">Estrazione di campioni dalla distribuzione a posteriori</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulazione-con-distribuzione-target-nota">Simulazione con distribuzione target nota</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#algoritmo-di-metropolis">Algoritmo di Metropolis</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#passaggi-fondamentali-dell-algoritmo-di-metropolis">Passaggi Fondamentali dell’Algoritmo di Metropolis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#versione-di-mcelreath">Versione di McElreath</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#algoritmo-di-metropolis-con-distribuzione-target-nota">Algoritmo di Metropolis con Distribuzione Target Nota</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sintassi-della-funzione">Sintassi della funzione</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#parametri">Parametri</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#valore-di-ritorno">Valore di ritorno</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dettagli-dell-algoritmo">Dettagli dell’algoritmo</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#algoritmo-di-metropolis-con-distribuzione-target-incognita">Algoritmo di Metropolis con distribuzione target incognita</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aspetti-computazionali">Aspetti computazionali</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#warm-up-burn-in">Warm-up/Burn-in</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sintesi-della-distribuzione-a-posteriori">Sintesi della distribuzione a posteriori</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#diagnostiche-della-soluzione-mcmc">Diagnostiche della soluzione MCMC</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#catene-multiple">Catene multiple</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stazionarieta">Stazionarietà</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#autocorrelazione">Autocorrelazione</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#tasso-di-accettazione">Tasso di accettazione</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#test-di-convergenza">Test di convergenza</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#approcci-grafici-tracce-delle-serie-temporali-trace-plots">Approcci Grafici: Tracce delle Serie Temporali (Trace Plots)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#test-statistici-per-la-convergenza">Test Statistici per la Convergenza</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#test-di-geweke">Test di Geweke</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#geweke-z-score">Geweke Z-score</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#effective-sample-size-ess">Effective sample size (ESS)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#caso-normale-normale">Caso Normale-Normale</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#calcolo-dei-parametri-del-posterior-analitico">Calcolo dei Parametri del Posterior Analitico</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#codice-per-il-grafico">Codice per il Grafico</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#commenti-e-considerazioni-finali">Commenti e considerazioni finali</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#informazioni-sull-ambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
Di Corrado Caudek
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>