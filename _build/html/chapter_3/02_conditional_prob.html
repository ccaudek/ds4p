
<!DOCTYPE html>


<html lang="it" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Probabilità condizionata &#8212; ds4p</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css?v=ca93fcec" />
    <link rel="stylesheet" type="text/css" href="../_static/exercise.css?v=20b57f81" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=3ee479438cf8b5e0d341"></script>

    <script src="../_static/documentation_options.js?v=8d586cc4"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="../_static/translations.js?v=0173e136"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-TP2WLBPMS6"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-TP2WLBPMS6');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-TP2WLBPMS6');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter_3/02_conditional_prob';</script>
    <link rel="canonical" href="https://ccaudek.github.io/ds4p/chapter_3/02_conditional_prob.html" />
    <link rel="icon" href="../_static/increasing.png"/>
    <link rel="index" title="Indice" href="../genindex.html" />
    <link rel="search" title="Cerca" href="../search.html" />
    <link rel="next" title="✏️ Esercizi" href="E_cond_prob_1.html" />
    <link rel="prev" title="✏️ Esercizi" href="E_prob.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="it"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="ds4p - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="ds4p - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Cerca" aria-label="Cerca" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Cerca</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Benvenuti
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_1/introduction_chapter_1.html">Python</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/00_prelims.html">Preliminari</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/01_python_1.html">Python (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/02_python_2.html">Python (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_python.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/03_numpy.html">NumPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_numpy.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/04_pandas.html">Pandas (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/05_pandas_aggregate.html">Pandas (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/06_pandas_functions.html">Pandas (3)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_pandas.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/07_matplotlib.html">Matplotlib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/08_seaborn.html">Seaborn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_matplotlib.html">✏️ Esercizi</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_2/introduction_chapter_2.html">Statistica descrittiva</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/00_scientific_method.html">La scienza dei dati e il metodo scientifico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/01_key_notions.html">Concetti chiave</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_key_notions.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/02_measurement.html">La misurazione in psicologia</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_scales.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/03_freq_distr.html">Dati e frequenze</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_sums.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/04_loc_scale.html">Indici di posizione e di scala</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/05_correlation.html">Le relazioni tra variabili</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/06_causality.html">Lo studio delle cause dei fenomeni</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_eda.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_mehr_song_spelke.html">✏️ Esercizi</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="introduction_chapter_3.html">Probabilità</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_intro_prob.html">Introduzione al calcolo delle probabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Probabilità condizionata</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_cond_prob_1.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_cond_prob_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_discrete_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_bayes_theorem.html">Il teorema di Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_bayes_theorem.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_bayes_theorem_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="04a_random_var.html">Introduzione alle variabili casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="04b_expval_var.html">Proprietà delle variabili casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_exp_val_variance.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="04c_sampling_distr.html">Stime, stimatori e parametri</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_rv_discrete.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_joint_prob.html">Probabilità congiunta</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_joint_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_covariance.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="06_density_func.html">La funzione di densità di probabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="07_discr_rv_distr.html">Distribuzioni di v.c. discrete</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_binomial.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="08_cont_rv_distr.html">Distribuzioni di v.c. continue</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_gaussian.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_beta_distr.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="09_likelihood.html">La verosimiglianza</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_likelihood.html">✏️ Esercizi</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_4/introduction_part_4.html">Inferenza bayesiana</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/01_intro_bayes.html">Modellazione bayesiana</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/02_subj_prop.html">Pensare ad una proporzione in termini soggettivi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/02_grid_gauss.html">Verosimiglianza Gaussiana: Metodo Basato su Griglia</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/03_conjugate_families_1.html">Distribuzioni coniugate</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/E_conjugate_families_1.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/04_conjugate_families_2.html">Distribuzioni coniugate (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/05_summary_posterior.html">Sintesi a posteriori</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/E_conjugate.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/06_balance-prior-post.html">L’influenza della distribuzione a priori</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/10_metropolis.html">Monte Carlo a Catena di Markov</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/15_stan_beta_binomial.html">Introduzione a Stan</a></li>

<li class="toctree-l2"><a class="reference internal" href="../chapter_4/E_stan_beta_binomial.html">✏️ Esercizio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/16_stan_summary_posterior.html">Metodi di sintesi della distribuzione a posteriori</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/17_stan_diagnostics.html">Diagnostica delle catene markoviane</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/18_stan_prediction.html">La predizione bayesiana</a></li>

<li class="toctree-l2"><a class="reference internal" href="../chapter_4/19_stan_odds_ratio.html">Analisi bayesiana dell’odds-ratio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/22_stan_normal_normal.html">Inferenza bayesiana su una media</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/23_stan_two_groups.html">Confronto tra due gruppi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/24_stan_hier_beta_binom.html">Modello gerarchico beta-binomiale con Stan</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_5/introduction_part_5.html">Analisi della regressione</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_03_reglin_bayesian.html">Analisi bayesiana del modello di regressione lineare bivariato</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_1.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_04_synt_sugar.html">Zucchero sintattico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_05_two_means.html">Confronto tra le medie di due gruppi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_3.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_4.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_06_hier_regr.html">Il modello lineare gerarchico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_07_robust_regr.html">Regressione robusta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_08_specification_error.html">Errore di specificazione</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_09_causal_inference.html">Inferenza causale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_causal_inference.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_22_stan_logistic_regr.html">Regressione logistica con Stan</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_24_stan_mixed_models.html">Modelli misti con Stan</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_25_stan_rct.html">Incorporare dati storici di controllo in una RCT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_26_stan_mediation.html">Modello di mediazione con Stan</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_30_entropy.html">Entropia</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_31_kl.html">La divergenza di Kullback-Leibler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_kl.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_32_stan_loo.html">Validazione Incrociata Leave-One-Out</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_35_missing.html">Dati mancanti</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_6/introduction_part_6.html">Inferenza frequentista</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/01_intro_frequentist.html">Introduzione all’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_estimation.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/02_conf_interv.html">Intervallo di confidenza</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_conf_interv.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/03_test_ipotesi.html">Significatività statistica</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_t_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_interpretation_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_significato_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/04_two_ind_samples.html">Test t di Student per campioni indipendenti</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_test_media_pop.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_medie_pop_ampie.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_medie_pop_piccoli.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_campioni_appaiati.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_confronto_proporzioni.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/05_crisis.html">La crisi della generalizzabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/06_limiti_stat_frequentista.html">Limiti dell’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/07_effect_size.html">La grandezza dell’effetto</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/09_s_m_errors.html">Crisi della replicabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/10_integrity.html">Integrità della ricerca</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../references/bibliography.html">Bibliografia</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_7/introduction_appendix.html">Appendici</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a00_installation.html">Ambiente di lavoro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a01_markdown.html">Jupyter Notebook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a02_shell.html">La Shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a03_colab_tutorial.html">Colab: un breve tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a04_virtual_env.html">Ambienti virtuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a10_math_symbols.html">Simbologia di base</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a11_numbers.html">Numeri binari, interi, razionali, irrazionali e reali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a12_sum_notation.html">Simbolo di somma (sommatorie)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a13_sets.html">Insiemi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a13a_probability.html">Sigma algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a14_combinatorics.html">Calcolo combinatorio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a15_calculus.html">Per liberarvi dai terrori preliminari</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a20_kde_plot.html">Kernel Density Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a30_prob_tutorial.html">Esercizi di probabilità discreta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a40_rng.html">Generazione di numeri casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a44_montecarlo.html">Simulazione Monte Carlo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a45_mcmc.html">Catene di Markov</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a46_stan.html">Linguaggio Stan</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a50_lin_fun.html">La funzione lineare</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a50_reglin_ml.html">Modello di Regressione Bivariato e ML</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a51_reglin_1.html">Regressione lineare bivariata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a60_ttest_exercises.html">Esercizi sull’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a70_predict_counts.html">La predizione delle frequenze</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/ccaudek/ds4p/blob/main/docs/chapter_3/02_conditional_prob.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Scarica questa pagina">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapter_3/02_conditional_prob.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Scarica il file sorgente"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Stampa in PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Modalità schermo intero"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Cerca" aria-label="Cerca" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Probabilità condizionata</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contenuti </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparazione-del-notebook">Preparazione del Notebook</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#indipendenza-stocastica">Indipendenza Stocastica</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#indipendenza-di-due-eventi">Indipendenza di Due Eventi</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#indipendenza-di-un-insieme-di-eventi">Indipendenza di un Insieme di Eventi</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#eventi-disgiunti-e-indipendenza">Eventi Disgiunti e Indipendenza</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilita-condizionata-su-altri-eventi">Probabilità condizionata su altri eventi</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#il-paradosso-di-simpson">Il paradosso di Simpson</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#teorema-della-probabilita-composta">Teorema della probabilità composta</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#il-teorema-della-probabilita-totale">Il teorema della probabilità totale</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#indipendenza-e-probabilita-condizionata">Indipendenza e probabilità condizionata</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#indipendenza-di-tre-eventi">Indipendenza di Tre Eventi</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#commenti-e-considerazioni-finali">Commenti e considerazioni finali</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#informazioni-sull-ambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="probabilita-condizionata">
<span id="cond-prob-notebook"></span><h1>Probabilità condizionata<a class="headerlink" href="#probabilita-condizionata" title="Link to this heading">#</a></h1>
<p>Un principio fondamentale nel campo della probabilità è il concetto di condizionamento. Il condizionamento si verifica quando, all’interno di un esperimento aleatorio, le probabilità vengono calcolate focalizzandosi esclusivamente su un sottoinsieme specifico dei risultati possibili. In pratica, questo significa che la probabilità viene determinata tenendo conto solo di quei risultati che rientrano in un certo criterio o condizione predefinita.</p>
<section id="preparazione-del-notebook">
<h2>Preparazione del Notebook<a class="headerlink" href="#preparazione-del-notebook" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">random</span> 
</pre></div>
</div>
</div>
</div>
</section>
<section id="indipendenza-stocastica">
<h2>Indipendenza Stocastica<a class="headerlink" href="#indipendenza-stocastica" title="Link to this heading">#</a></h2>
<p>Nel contesto della probabilità condizionata, il concetto di indipendenza gioca un ruolo fondamentale. Questa caratteristica permette di semplificare notevolmente il calcolo delle probabilità in molti problemi, evidenziando come la conoscenza di un evento non fornisca alcuna informazione aggiuntiva sull’altro.</p>
<section id="indipendenza-di-due-eventi">
<h3>Indipendenza di Due Eventi<a class="headerlink" href="#indipendenza-di-due-eventi" title="Link to this heading">#</a></h3>
<p>Due eventi <span class="math notranslate nohighlight">\( A \)</span> e <span class="math notranslate nohighlight">\( B \)</span> sono detti <strong>indipendenti</strong> se il verificarsi di uno non influenza la probabilità di verificarsi dell’altro. Formalmente, questa condizione è espressa come:</p>
<div class="math notranslate nohighlight">
\[ \mathbb{P}(A \cap B) = \mathbb{P}(A) \mathbb{P}(B), \]</div>
<p>dove <span class="math notranslate nohighlight">\( \mathbb{P}(A \cap B) \)</span> rappresenta la probabilità che entrambi gli eventi <span class="math notranslate nohighlight">\( A \)</span> e <span class="math notranslate nohighlight">\( B \)</span> si verifichino simultaneamente.</p>
<p>Se questa condizione è soddisfatta, scriviamo <span class="math notranslate nohighlight">\( A \text{ ⫫ } B \)</span>, il che significa «A è indipendente da B».</p>
</section>
<section id="indipendenza-di-un-insieme-di-eventi">
<h3>Indipendenza di un Insieme di Eventi<a class="headerlink" href="#indipendenza-di-un-insieme-di-eventi" title="Link to this heading">#</a></h3>
<p>L’indipendenza stocastica è un concetto fondamentale nell’applicazione della probabilità in campo statistico. Un insieme di eventi <span class="math notranslate nohighlight">\( \{ A_i : i \in I \} \)</span> è detto <strong>indipendente</strong> se per ogni sottoinsieme finito <span class="math notranslate nohighlight">\( J \)</span> di <span class="math notranslate nohighlight">\( I \)</span>, la probabilità dell’intersezione degli eventi nel sottoinsieme <span class="math notranslate nohighlight">\( J \)</span> è uguale al prodotto delle loro singole probabilità. Formalmente:</p>
<div class="math notranslate nohighlight">
\[ \mathbb{P} \left( \cap_{i \in J} A_i \right) = \prod_{i \in J} \mathbb{P}(A_i). \]</div>
<p>Questo significa che ogni combinazione finita di eventi nell’insieme è indipendente.</p>
<p>L’indipendenza può essere <strong>assunta</strong> o <strong>derivata</strong> a seconda del contesto. In alcuni modelli o situazioni, assumiamo che certi eventi siano indipendenti perché questa assunzione semplifica i calcoli o riflette una conoscenza previa. In altri casi, l’indipendenza può essere derivata dai dati o da altre proprietà del modello.</p>
</section>
<section id="eventi-disgiunti-e-indipendenza">
<h3>Eventi Disgiunti e Indipendenza<a class="headerlink" href="#eventi-disgiunti-e-indipendenza" title="Link to this heading">#</a></h3>
<p>Eventi disgiunti (o mutuamente esclusivi) sono quelli che non possono verificarsi simultaneamente, cioè <span class="math notranslate nohighlight">\( \mathbb{P}(A \cap B) = 0 \)</span>. Se due eventi disgiunti hanno una probabilità positiva di verificarsi, allora non possono essere indipendenti. Questo perché per eventi disgiunti con <span class="math notranslate nohighlight">\( \mathbb{P}(A) &gt; 0 \)</span> e <span class="math notranslate nohighlight">\( \mathbb{P}(B) &gt; 0 \)</span>, l’equazione di indipendenza <span class="math notranslate nohighlight">\( \mathbb{P}(A \cap B) = \mathbb{P}(A) \mathbb{P}(B) \)</span> non può essere soddisfatta, dato che <span class="math notranslate nohighlight">\( \mathbb{P}(A \cap B) = 0 \)</span> e <span class="math notranslate nohighlight">\( \mathbb{P}(A) \mathbb{P}(B) &gt; 0 \)</span>.</p>
</section>
</section>
<section id="probabilita-condizionata-su-altri-eventi">
<span id="sec-prob-cond"></span><h2>Probabilità condizionata su altri eventi<a class="headerlink" href="#probabilita-condizionata-su-altri-eventi" title="Link to this heading">#</a></h2>
<p>La probabilità di un evento è intrinsecamente condizionata dal nostro stato di informazione. In presenza di un determinato insieme di informazioni, attribuiamo a un evento una probabilità specifica di occorrenza. Tuttavia, qualora il nostro stato informativo subisca una modifica, anche la probabilità associata all’evento verrà corrispondentemente aggiornata.</p>
<p>In realtà, tutte le probabilità possono essere intese come probabilità condizionate, anche quando la variabile o l’evento condizionante non è esplicitamente specificato. Ciò implica che le probabilità sono sempre contestualizzate e dipendono dal set informativo disponibile in un dato scenario.</p>
<p>Questo quadro concettuale ci induce a considerare le probabilità come una “misura di plausibilità” che riflette la nostra conoscenza corrente del sistema o del fenomeno sotto indagine. A seguito dell’acquisizione di nuove informazioni o di cambiamenti nel contesto, la nostra misura di plausibilità, e quindi la probabilità attribuita agli eventi, può essere rivista.</p>
<div class="admonition-definizione admonition">
<p class="admonition-title">Definizione</p>
<p>Siano <span class="math notranslate nohighlight">\( A \)</span> e <span class="math notranslate nohighlight">\( B \)</span> due eventi definiti su uno spazio campionario <span class="math notranslate nohighlight">\( S \)</span>. Supponendo che l’evento <span class="math notranslate nohighlight">\( B \)</span> si verifichi, la <em>probabilità condizionata</em> di <span class="math notranslate nohighlight">\( A \)</span> dato <span class="math notranslate nohighlight">\( B \)</span> è data da</p>
<div class="math notranslate nohighlight" id="equation-eq-prob-cond-def">
<span class="eqno">(10)<a class="headerlink" href="#equation-eq-prob-cond-def" title="Link to this equation">#</a></span>\[ 
P(A \mid B) = \frac{P(A \cap B)}{P(B)}, \quad \text{per}\, P(B) &gt; 0,
\]</div>
<p>dove <span class="math notranslate nohighlight">\( P(A \cap B) \)</span> rappresenta la <em>probabilità congiunta</em> dei due eventi, ovvero la probabilità che entrambi si verifichino.</p>
</div>
<p>Nell’eq. <a class="reference internal" href="#equation-eq-prob-cond-def">(10)</a>, <span class="math notranslate nohighlight">\( P(A \cap B) \)</span> è la probabilità congiunta che entrambi gli eventi si verifichino, mentre <span class="math notranslate nohighlight">\( P(B) \)</span> è la probabilità marginale dell’evento <span class="math notranslate nohighlight">\( B \)</span>. Riorganizzando i termini, otteniamo la regola della moltiplicazione:</p>
<div class="math notranslate nohighlight">
\[ 
P(A \cap B) = P(A \mid B)P(B) = P(B \mid A)P(A). 
\]</div>
<p>Utilizzando questa regola, possiamo derivare una forma alternativa della legge della probabilità totale:</p>
<div class="math notranslate nohighlight">
\[ 
P(A) = P(A \mid B)P(B) + P(A \mid B^c)P(B^c).
\]</div>
<p>Dove <span class="math notranslate nohighlight">\( B^c \)</span> rappresenta il complemento dell’evento <span class="math notranslate nohighlight">\( B \)</span>.</p>
<p>È importante notare che <span class="math notranslate nohighlight">\(P(A \mid B)\)</span> non è definita se <span class="math notranslate nohighlight">\(P(B) = 0\)</span>.</p>
<p>La probabilità condizionata può essere interpretata come una ricalibrazione dello spazio campionario da <span class="math notranslate nohighlight">\(S\)</span> a <span class="math notranslate nohighlight">\(B\)</span>. Per spazi campionari discreti, la probabilità condizionata è espressa come</p>
<div class="math notranslate nohighlight">
\[
P(A \mid B) = \frac{| A \cap B |}{| B |}.
\]</div>
<div class="exercise admonition" id="ex-two-dice-sum">

<p class="admonition-title"><span class="caption-number">Exercise 80 </span></p>
<section id="exercise-content">
<p>Lanciamo due dadi equilibrati e vogliamo calcolare la probabilità che la somma dei punteggi ottenuti sia minore di 8.</p>
<p>Inizialmente, quando non abbiamo ulteriori informazioni, possiamo calcolare la probabilità in modo tradizionale. Ci sono 21 risultati possibili con somma minore di 8. Poiché ci sono 36 possibili combinazioni di lancio dei due dadi, la probabilità di ottenere una somma minore di 8 è 21/36, che equivale a circa 0.58.</p>
<p>Supponiamo ora di sapere che la somma del lancio di due dadi ha prodotto un risultato dispari. In questo caso, ci sono solo 18 possibili combinazioni di lancio dei due dadi (dato che abbiamo escluso i risultati pari). Tra essi, vi sono 12 risultati che soddisfano la condizione per cui la somma è minore di 8. Quindi, la probabilità di ottenere una somma minore di 8 cambia da circa 0.58 a 12/18, ovvero 0.67 quando consideriamo l’informazione aggiuntiva del risultato dispari.</p>
<p>Svolgiamo il problema in Python.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">r</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">sample</span> <span class="o">=</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">r</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">r</span><span class="p">]</span>
<span class="n">sample</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(1, 1),
 (1, 2),
 (1, 3),
 (1, 4),
 (1, 5),
 (1, 6),
 (2, 1),
 (2, 2),
 (2, 3),
 (2, 4),
 (2, 5),
 (2, 6),
 (3, 1),
 (3, 2),
 (3, 3),
 (3, 4),
 (3, 5),
 (3, 6),
 (4, 1),
 (4, 2),
 (4, 3),
 (4, 4),
 (4, 5),
 (4, 6),
 (5, 1),
 (5, 2),
 (5, 3),
 (5, 4),
 (5, 5),
 (5, 6),
 (6, 1),
 (6, 2),
 (6, 3),
 (6, 4),
 (6, 5),
 (6, 6)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">event</span> <span class="o">=</span> <span class="p">[</span><span class="n">roll</span> <span class="k">for</span> <span class="n">roll</span> <span class="ow">in</span> <span class="n">sample</span> <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">roll</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">8</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">event</span><span class="p">)</span><span class="si">}</span><span class="s2"> / </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>21 / 36
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_odd</span> <span class="o">=</span> <span class="p">[</span><span class="n">roll</span> <span class="k">for</span> <span class="n">roll</span> <span class="ow">in</span> <span class="n">sample</span> <span class="k">if</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">roll</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">sample_odd</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(1, 2),
 (1, 4),
 (1, 6),
 (2, 1),
 (2, 3),
 (2, 5),
 (3, 2),
 (3, 4),
 (3, 6),
 (4, 1),
 (4, 3),
 (4, 5),
 (5, 2),
 (5, 4),
 (5, 6),
 (6, 1),
 (6, 3),
 (6, 5)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">event</span> <span class="o">=</span> <span class="p">[</span><span class="n">roll</span> <span class="k">for</span> <span class="n">roll</span> <span class="ow">in</span> <span class="n">sample_odd</span> <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">roll</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">8</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">event</span><span class="p">)</span><span class="si">}</span><span class="s2"> / </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">sample_odd</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>12 / 18
</pre></div>
</div>
</div>
</div>
<p>Se applichiamo l’eq. <code class="xref eq docutils literal notranslate"><span class="pre">eq-probcond</span></code>, abbiamo: <span class="math notranslate nohighlight">\(P(A \cap B)\)</span> = 12/36, <span class="math notranslate nohighlight">\(P(B)\)</span> = 18/36 e</p>
<div class="math notranslate nohighlight">
\[
P(A \mid B) = \frac{12}{18}.
\]</div>
<p>Questo esempio illustra come la probabilità di un evento possa variare in base alle informazioni aggiuntive di cui disponiamo. Nel secondo caso, avendo l’informazione che la somma è dispari, la probabilità di ottenere una somma minore di 8 aumenta notevolmente rispetto al caso iniziale in cui non avevamo questa informazione.</p>
</section>
</div>
<div class="exercise admonition" id="ex-mammografia">

<p class="admonition-title"><span class="caption-number">Exercise 81 </span></p>
<section id="exercise-content">
<p>Consideriamo uno screening per la diagnosi precoce del tumore mammario utilizzando un test con determinate caratteristiche:</p>
<ul class="simple">
<li><p>Sensibilità del test: 90%. Questo significa che il test classifica correttamente come positivo il 90% delle donne colpite dal cancro al seno.</p></li>
<li><p>Specificità del test: 90%. Ciò indica che il test classifica correttamente come negativo il 90% delle donne che non hanno il cancro al seno.</p></li>
<li><p>Prevalenza del cancro al seno nella popolazione sottoposta allo screening: 1% (0.01). Questo è il 1% delle donne che ha effettivamente il cancro al seno, mentre il restante 99% (0.99) non ne è affetto.</p></li>
</ul>
<p>Ora cerchiamo di rispondere alle seguenti domande:</p>
<ul class="simple">
<li><p>Qual è la probabilità che una donna scelta a caso ottenga una mammografia positiva? Poiché il 1% delle donne ha il cancro al seno, la probabilità di ottenere una mammografia positiva (test positivo) è pari alla sensibilità del test, ovvero 0.90 (cioè 90%).</p></li>
<li><p>Se la mammografia è positiva, qual è la probabilità che vi sia effettivamente un tumore al seno?</p></li>
</ul>
<p>Per risolvere questo problema, consideriamo un campione di 1000 donne sottoposte al test di screening per il tumore al seno. Di queste 1000 donne:</p>
<ul class="simple">
<li><p>10 donne (1% del campione) hanno effettivamente il cancro al seno. Per queste 10 donne con il cancro, il test darà un risultato positivo (vera positività) in 9 casi (90%).</p></li>
<li><p>Per le restanti 990 donne (99% del campione) che non hanno il cancro al seno, il test darà un risultato positivo (falsa positività) in 99 casi (10%).</p></li>
</ul>
<p>Questa situazione può essere rappresentata graficamente nel seguente modo:</p>
<a class="reference internal image-reference" href="../_images/mammografia.png" id="mammografia"><img alt="../_images/mammografia.png" id="mammografia" src="../_images/mammografia.png" style="height: 165px;" /></a>
<p>Combinando i due risultati precedenti, vediamo che il test dà un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non lo hanno, per un totale di 108 risultati positivi su 1000. Pertanto, la probabilità di ottenere un risultato positivo al test è <span class="math notranslate nohighlight">\(\frac{108}{1000}\)</span> = 0.108.</p>
<p>Tuttavia, tra le 108 donne che hanno ottenuto un risultato positivo al test, solo 9 hanno effettivamente il cancro al seno. Quindi, la probabilità di avere il cancro al seno, dato un risultato positivo al test, è pari a <span class="math notranslate nohighlight">\(\frac{9}{108}\)</span> = 0.083, corrispondente all’8.3%.</p>
<p>In questo esempio, la probabilità dell’evento «ottenere un risultato positivo al test» è una probabilità non condizionata, poiché calcoliamo semplicemente la proporzione di risultati positivi nel campione totale. D’altra parte, la probabilità dell’evento «avere il cancro al seno, dato che il test ha prodotto un risultato positivo» è una probabilità condizionata, poiché calcoliamo la proporzione delle donne con il cancro al seno tra quelle che hanno ottenuto un risultato positivo al test.</p>
<p>Questo esempio illustra come la conoscenza di ulteriori informazioni (il risultato positivo al test) può influenzare la probabilità di un evento (avere il cancro al seno), mostrando chiaramente la differenza tra probabilità condizionate e non condizionate.</p>
</section>
</div>
<div class="exercise admonition" id="ex-monty-hall">

<p class="admonition-title"><span class="caption-number">Exercise 82 </span></p>
<section id="exercise-content">
<p>Il paradosso di Monty Hall rappresenta un curioso esempio di come l’introduzione di nuove informazioni possa influenzare l’esito di una situazione probabilistica. Questo famoso problema trae origine dal popolare programma televisivo americano «Let’s Make a Deal» e deve la sua notorietà al conduttore Monty Hall.</p>
<p>Nel gioco ci sono tre porte chiuse: dietro una si nasconde un’automobile, mentre dietro le altre due ci sono delle capre. Inizialmente, il concorrente sceglie una delle tre porte senza aprirla. Successivamente, Monty Hall apre una delle due porte rimaste, rivelando una capra. A questo punto, offre al concorrente la possibilità di cambiare la sua scelta iniziale e optare per l’altra porta ancora chiusa. Il paradosso si presenta quando si scopre che cambiando la scelta in questa fase, il concorrente aumenta le sue probabilità di vincere l’automobile, passando da 1/3 a 2/3.</p>
<p><img alt="Monty Hall" src="../_images/monty-hall.jpg" /></p>
<p>Per confermare questo risultato inaspettato, è possibile eseguire una simulazione in Python. In questa simulazione, consideriamo due scenari: uno in cui il concorrente mantiene la sua scelta iniziale e un altro in cui cambia la sua scelta dopo che Monty Hall ha svelato una capra. Ripetendo questa simulazione migliaia di volte, possiamo confrontare i risultati empirici e confermare come effettivamente il cambiamento di scelta aumenti le probabilità del concorrente di vincere l’automobile.</p>
<p>Di seguito è riportato lo script di una simulazione progettata per illustrare il paradosso di Monty Hall.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">porte</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;capra1&quot;</span><span class="p">,</span>
    <span class="s2">&quot;capra2&quot;</span><span class="p">,</span>
    <span class="s2">&quot;macchina&quot;</span><span class="p">,</span>
<span class="p">]</span>  <span class="c1"># definisco il gioco, scelgo una porta a caso per n volte</span>
<span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">contatore_cambio</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">porta_vincente</span> <span class="o">=</span> <span class="s2">&quot;macchina&quot;</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">scelta_casuale</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">porte</span><span class="p">)</span>
    <span class="n">porte_rimaste</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">porte</span> <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="n">scelta_casuale</span><span class="p">]</span>
    <span class="n">porta_rivelata</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">porte_rimaste</span> <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="n">porta_vincente</span><span class="p">])</span>
    <span class="n">porta_alternativa</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">porte</span> <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="n">scelta_casuale</span> <span class="ow">and</span> <span class="n">x</span> <span class="o">!=</span> <span class="n">porta_rivelata</span>
    <span class="p">]</span>
    <span class="k">if</span> <span class="s2">&quot;macchina&quot;</span> <span class="ow">in</span> <span class="n">porta_alternativa</span><span class="p">:</span>
        <span class="n">contatore_cambio</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">scelta_casuale</span> <span class="o">==</span> <span class="s2">&quot;macchina&quot;</span><span class="p">:</span>
        <span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="nb">print</span><span class="p">(</span><span class="n">counter</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span>  <span class="c1"># quante volte vinco non cambiando porta</span>
<span class="nb">print</span><span class="p">(</span><span class="n">contatore_cambio</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span>  <span class="c1"># quante volte vinco cambiando porta</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.3302
0.6698
</pre></div>
</div>
</div>
</div>
<p>Questo script Python è stato creato da un gruppo di studenti di Psicometria nell’AA 2023-2023. La simulazione mostra che, effettivamente, la probabilità di vincere la macchina aumenta quando il concorrente sceglie di cambiare porta.</p>
<p>Ecco una spiegazione del paradosso:</p>
<ol class="arabic simple">
<li><p><strong>Fase Iniziale:</strong> Nel gioco, il concorrente deve scegliere una delle tre porte (A, B, C), dietro una delle quali si trova una macchina. Inizialmente, la probabilità che la macchina si trovi dietro la porta scelta è <span class="math notranslate nohighlight">\(1/3\)</span>, dato che esistono tre possibilità ugualmente probabili e solo una contiene la macchina.</p></li>
<li><p><strong>Aggiunta di Informazioni:</strong> Dopo la scelta iniziale, Monty Hall, che conosce il contenuto dietro ogni porta, apre una delle due porte non scelte, rivelando sempre una capra. Questo passaggio è fondamentale: non cambia la probabilità <span class="math notranslate nohighlight">\(1/3\)</span> che la macchina sia dietro la porta originariamente scelta dal concorrente, ma la probabilità che la macchina si trovi dietro l’altra porta non scelta aumenta ora a <span class="math notranslate nohighlight">\(2/3\)</span>. Questo aumento di probabilità deriva dal fatto che Monty ha scelto deliberatamente una porta con una capra, basando la sua scelta sulla posizione della macchina.</p></li>
</ol>
<p>Consideriamo i tre possibili scenari dopo che il concorrente ha scelto la porta A:</p>
<ul class="simple">
<li><p><strong>La macchina è dietro la porta A:</strong> La probabilità di questo scenario è <span class="math notranslate nohighlight">\(1/3\)</span>. Monty può aprire sia la porta B che la porta C, poiché entrambe nascondono una capra. Se il concorrente cambia la sua scelta, perderà.</p></li>
<li><p><strong>La macchina è dietro la porta B:</strong> La probabilità di questo scenario è <span class="math notranslate nohighlight">\(1/3\)</span>. Monty aprirà la porta C, perché sa che la macchina è dietro la porta B e non può rivelarla. Se il concorrente cambia la sua scelta da A a B, vincerà.</p></li>
<li><p><strong>La macchina è dietro la porta C:</strong> La probabilità di questo scenario è <span class="math notranslate nohighlight">\(1/3\)</span>. Monty aprirà la porta B. Se il concorrente cambia la sua scelta da A a C, vincerà.</p></li>
</ul>
<p>In conclusione, cambiare la scelta originale porta alla vittoria in due dei tre scenari possibili. Pertanto, la probabilità complessiva di vincere cambiando la scelta è <span class="math notranslate nohighlight">\(2/3\)</span>.</p>
<p>Questo paradosso evidenzia come, in presenza di informazioni aggiuntive, le probabilità iniziali possano essere riviste significativamente. È un classico esempio di come l’intuizione umana spesso si scontri con i principi della teoria delle probabilità, sottolineando l’importanza della revisione bayesiana delle probabilità alla luce di nuove informazioni.</p>
</section>
</div>
<section id="il-paradosso-di-simpson">
<span id="sec-simpson-paradox"></span><h3>Il paradosso di Simpson<a class="headerlink" href="#il-paradosso-di-simpson" title="Link to this heading">#</a></h3>
<p>Nel campo della probabilità condizionata, uno dei fenomeni più interessanti e, nel contempo, più controintuitivi, è rappresentato dal paradosso di Simpson. Il paradosso di Simpson è un fenomeno statistico in cui una tendenza che appare in diversi gruppi separati di dati scompare o si inverte quando i dati vengono combinati. Questo paradosso mette in luce l’importanza di considerare le variabili confondenti e di analizzare i dati con attenzione per evitare conclusioni errate.</p>
<div class="exercise admonition" id="ex-simpson-paradox">

<p class="admonition-title"><span class="caption-number">Exercise 83 </span></p>
<section id="exercise-content">
<p>Due psicoterapeuti, Rossi e Bianchi, praticano due tipi di terapie: terapia per disturbi d’ansia e coaching per migliorare le prestazioni lavorative. Ogni terapia può avere un esito positivo o negativo.</p>
<p>I rispettivi bilanci dei due terapeuti sono riportati nelle seguenti tabelle.</p>
<p><strong>Rossi</strong></p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Tipo di terapia</p></th>
<th class="head"><p>Successo</p></th>
<th class="head"><p>Fallimento</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Disturbi d’ansia</p></td>
<td><p>70</p></td>
<td><p>20</p></td>
</tr>
<tr class="row-odd"><td><p>Coaching lavorativo</p></td>
<td><p>10</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p><strong>Totale</strong></p></td>
<td><p>80</p></td>
<td><p>20</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>Bianchi</strong></p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Tipo di terapia</p></th>
<th class="head"><p>Successo</p></th>
<th class="head"><p>Fallimento</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Disturbi d’ansia</p></td>
<td><p>2</p></td>
<td><p>8</p></td>
</tr>
<tr class="row-odd"><td><p>Coaching lavorativo</p></td>
<td><p>81</p></td>
<td><p>9</p></td>
</tr>
<tr class="row-even"><td><p><strong>Totale</strong></p></td>
<td><p>83</p></td>
<td><p>17</p></td>
</tr>
</tbody>
</table>
</div>
<p>Rossi ha un tasso di successo superiore a Bianchi nella terapia per i disturbi d’ansia: 70 su 90 rispetto a 2 su 10. Anche nel coaching lavorativo, Rossi ha un tasso di successo superiore: 10 su 10 rispetto a 81 su 90. Tuttavia, se aggregiamo i dati dei due tipi di terapia per confrontare i tassi di successo globali, Rossi è efficace in 80 su 100 terapie, mentre Bianchi in 83 su 100: il tasso di successo globale di Bianchi risulta superiore!</p>
<p>Questo fenomeno è un esempio del paradosso di Simpson, dove una tendenza osservata in diversi gruppi si inverte quando i gruppi sono combinati.</p>
<p>Per essere più precisi, possiamo calcolare i tassi di successo per ciascun terapeuta e per ciascun tipo di terapia, oltre al tasso di successo globale.</p>
<ol class="arabic simple">
<li><p><strong>Rossi</strong></p>
<ul class="simple">
<li><p>Tasso di successo in terapia per disturbi d’ansia: <span class="math notranslate nohighlight">\(\frac{70}{70+20} = \frac{70}{90} \approx 0.778\)</span></p></li>
<li><p>Tasso di successo in coaching lavorativo: <span class="math notranslate nohighlight">\(\frac{10}{10+0} = \frac{10}{10} = 1\)</span></p></li>
<li><p>Tasso di successo globale: <span class="math notranslate nohighlight">\(\frac{70+10}{70+20+10+0} = \frac{80}{100} = 0.8\)</span></p></li>
</ul>
</li>
<li><p><strong>Bianchi</strong></p>
<ul class="simple">
<li><p>Tasso di successo in terapia per disturbi d’ansia: <span class="math notranslate nohighlight">\(\frac{2}{2+8} = \frac{2}{10} = 0.2\)</span></p></li>
<li><p>Tasso di successo in coaching lavorativo: <span class="math notranslate nohighlight">\(\frac{81}{81+9} = \frac{81}{90} \approx 0.9\)</span></p></li>
<li><p>Tasso di successo globale: <span class="math notranslate nohighlight">\(\frac{2+81}{2+8+81+9} = \frac{83}{100} = 0.83\)</span></p></li>
</ul>
</li>
</ol>
<p>Quello che sta succedendo è che Rossi, presumibilmente a causa della sua reputazione come terapeuta più esperto, sta effettuando un numero maggiore di terapie per disturbi d’ansia, che sono intrinsecamente più complesse e con una probabilità di successo variabile rispetto al coaching lavorativo. Il suo tasso di successo globale è inferiore non a causa di una minore abilità in un particolare tipo di terapia, ma perché una frazione maggiore delle sue terapie riguarda casi più complessi.</p>
<p>L’aggregazione dei dati tra diversi tipi di terapia presenta un quadro fuorviante delle abilità dei terapeuti perché perdiamo l’informazione su quale terapeuta tende a effettuare quale tipo di terapia. Quando sospettiamo la presenza di variabili di confondimento, come ad esempio il tipo di terapia in questo contesto, è fondamentale analizzare i dati in modo disaggregato per comprendere con precisione la dinamica in atto.</p>
</section>
</div>
</section>
</section>
<section id="teorema-della-probabilita-composta">
<h2>Teorema della probabilità composta<a class="headerlink" href="#teorema-della-probabilita-composta" title="Link to this heading">#</a></h2>
<p>È possibile scrivere l’eq. <a class="reference internal" href="#equation-eq-prob-cond-def">(10)</a> nella forma:</p>
<div class="math notranslate nohighlight" id="equation-eq-probcondinv">
<span class="eqno">(11)<a class="headerlink" href="#equation-eq-probcondinv" title="Link to this equation">#</a></span>\[
P(A \cap B) = P(B)P(A \mid B) = P(A)P(B \mid A).
\]</div>
<p>Questo secondo modo di scrivere l’equazione <a class="reference internal" href="#equation-eq-prob-cond-def">(10)</a> è chiamato <em>teorema della probabilità composta</em> (o regola moltiplicativa, o regola della catena). La legge della probabilità composta ci dice che la probabilità che si verifichino contemporaneamente due eventi <span class="math notranslate nohighlight">\(A\)</span> e <span class="math notranslate nohighlight">\(B\)</span> è pari alla probabilità di uno dei due eventi moltiplicata per la probabilità dell’altro evento condizionata al verificarsi del primo.</p>
<p>L’eq. <a class="reference internal" href="#equation-eq-probcondinv">(11)</a> si estende al caso di <span class="math notranslate nohighlight">\(n\)</span> eventi <span class="math notranslate nohighlight">\(A_1, \dots, A_n\)</span> nella forma seguente:</p>
<div class="math notranslate nohighlight" id="equation-eq-probcomposte">
<span class="eqno">(12)<a class="headerlink" href="#equation-eq-probcomposte" title="Link to this equation">#</a></span>\[
P\left( \bigcap_{k=1}^n A_k \right) = \prod_{k=1}^n P\left(  A_k  \ \Biggl\lvert \ \bigcap_{j=1}^{k-1} A_j \right).
\]</div>
<p>Per esempio, nel caso di quattro eventi abbiamo</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
P(&amp;A_1 \cap A_2 \cap A_3 \cap A_4) =  \\
 &amp; P(A_1) \cdot P(A_2 \mid A_1) \cdot  P(A_3 \mid A_1 \cap A_2) \cdot P(A_4 \mid A_1 \cap A_2 \cap A_{3}).\notag
\end{split}
\end{split}\]</div>
<div class="exercise admonition" id="ex-urn-white-black">

<p class="admonition-title"><span class="caption-number">Exercise 84 </span></p>
<section id="exercise-content">
<p>Per fare un esempio, consideriamo il problema seguente. Da un’urna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell’urna. Indichiamo con <span class="math notranslate nohighlight">\(B_i\)</span> l’evento: «esce una pallina bianca alla <span class="math notranslate nohighlight">\(i\)</span>-esima estrazione» e con <span class="math notranslate nohighlight">\(N_i\)</span> l’estrazione di una pallina nera. L’evento: «escono due palline bianche nelle prime due estrazioni» è rappresentato dalla intersezione <span class="math notranslate nohighlight">\(\{B_1 \cap B_2\}\)</span> e, per l’eq. <a class="reference internal" href="#equation-eq-probcondinv">(11)</a>, la sua probabilità vale</p>
<div class="math notranslate nohighlight">
\[
P(B_1 \cap B_2) = P(B_1)P(B_2 \mid B_1).
\]</div>
<p><span class="math notranslate nohighlight">\(P(B_1)\)</span> vale 6/10, perché nella prima estrazione <span class="math notranslate nohighlight">\(\Omega\)</span> è costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilità condizionata <span class="math notranslate nohighlight">\(P(B_2 \mid B_1)\)</span> vale 5/9, perché nella seconda estrazione, se è verificato l’evento <span class="math notranslate nohighlight">\(B_1\)</span>, lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto:</p>
<div class="math notranslate nohighlight">
\[
P(B_1 \cap B_2) = \frac{6}{10} \cdot \frac{5}{9} = \frac{1}{3}.
\]</div>
<p>In modo analogo si ha che</p>
<div class="math notranslate nohighlight">
\[
P(N_1 \cap N_2) = P(N_1)P(N_2 \mid N_1) = \frac{4}{10} \cdot \frac{3}{9} = \frac{4}{30}.
\]</div>
<p>Se l’esperimento consiste nell’estrazione successiva di 3 palline, la probabilità che queste siano tutte bianche, per l’eq. <a class="reference internal" href="#equation-eq-probcomposte">(12)</a>, vale</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
P(B_1 \cap B_2 \cap B_3) &amp;=P(B_1)P(B_2 \mid B_1)P(B_3 \mid B_1 \cap B_2) \notag\\ 
&amp;=\frac{6}{10}\cdot\frac{5}{9} \cdot\frac{4}{8} \notag\\ 
&amp;= \frac{1}{6}.
\end{aligned}
\end{split}\]</div>
<p>La probabilità dell’estrazione di tre palline nere è invece:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
P(N_1 \cap N_2 \cap N_3) &amp;= P(N_1)P(N_2 \mid N_1)P(N_3 \mid N_1 \cap N_2)\notag\\ 
&amp;= \frac{4}{10} \cdot \frac{3}{9} \cdot \frac{2}{8} \notag\\ 
&amp;= \frac{1}{30}.\notag
\end{aligned}
\end{split}\]</div>
</section>
</div>
</section>
<section id="il-teorema-della-probabilita-totale">
<h2>Il teorema della probabilità totale<a class="headerlink" href="#il-teorema-della-probabilita-totale" title="Link to this heading">#</a></h2>
<p>Il <em>teorema della probabilità totale</em> (detto anche teorema delle partizioni) afferma che se abbiamo una partizione di uno spazio campionario <span class="math notranslate nohighlight">\(\Omega\)</span> in <span class="math notranslate nohighlight">\(n\)</span> eventi mutualmente esclusivi e tali che la loro unione formi <span class="math notranslate nohighlight">\(\Omega\)</span>, allora la probabilità di un qualsiasi evento in <span class="math notranslate nohighlight">\(\Omega\)</span> può essere calcolata sommando la probabilità dell’evento su ciascun sottoinsieme della partizione, pesata in base alla probabilità del sottoinsieme.</p>
<p>In altre parole, se <span class="math notranslate nohighlight">\(H_1, H_2, \dots, H_n\)</span> sono eventi mutualmente esclusivi e tali che <span class="math notranslate nohighlight">\(\bigcup_{i=1}^n H_i = \Omega\)</span>, allora per ogni evento <span class="math notranslate nohighlight">\(E \subseteq \Omega\)</span>, la probabilità di <span class="math notranslate nohighlight">\(E\)</span> è data dalla formula:</p>
<div class="math notranslate nohighlight" id="equation-eq-prob-tot">
<span class="eqno">(13)<a class="headerlink" href="#equation-eq-prob-tot" title="Link to this equation">#</a></span>\[
P(E) = \sum_{i=1}^n P(E \mid H_i)P(H_i),
\]</div>
<p>dove <span class="math notranslate nohighlight">\(P(E \mid H_i)\)</span> rappresenta la probabilità condizionata di <span class="math notranslate nohighlight">\(E\)</span> dato che si è verificato l’evento <span class="math notranslate nohighlight">\(H_i\)</span>, e <span class="math notranslate nohighlight">\(P(H_i)\)</span> è la probabilità dell’evento <span class="math notranslate nohighlight">\(H_i\)</span>.</p>
<p>Il teorema della probabilità totale riveste un ruolo fondamentale in quanto fornisce il denominatore  nel teorema di Bayes, svolgendo la funzione di costante di normalizzazione. Questa costante di normalizzazione è di vitale importanza per assicurare che la distribuzione a posteriori sia una distribuzione di probabilità valida. Per ulteriori dettagli e approfondimenti, è possibile fare riferimento al capitolo <a class="reference internal" href="../chapter_4/02_subj_prop.html#cap-subj-prop"><span class="std std-ref">Pensare ad una proporzione in termini soggettivi</span></a>.</p>
<p>Nell’ambito della probabilità discreta, questo teorema viene usato quando abbiamo una partizione dello spazio campionario e vogliamo calcolare la probabilità di un evento, sfruttando le probabilità dei singoli eventi della partizione. Il caso più semplice è quello di una partizione dello spazio campione in due sottoinsiemi: <span class="math notranslate nohighlight">\(P(E) = P(E \cap H_1) + P(E \cap H_2)\)</span>.</p>
<a class="reference internal image-reference" href="../_images/bayes_theorem.png" id="image-bayes-theorem"><img alt="../_images/bayes_theorem.png" class="align-center" id="image-bayes-theorem" src="../_images/bayes_theorem.png" style="height: 230px;" /></a>
<p>In tali circostanza abbiamo che</p>
<div class="math notranslate nohighlight">
\[
P(E) = P(E \mid H_1) P(H_1) + P(E \mid H_2) P(H_2).
\]</div>
<p>L’eq. <a class="reference internal" href="#equation-eq-prob-tot">(13)</a> è utile per calcolare <span class="math notranslate nohighlight">\(P(E)\)</span>, se <span class="math notranslate nohighlight">\(P(E \mid H_i)\)</span> e <span class="math notranslate nohighlight">\(P(H_i)\)</span> sono facili da trovare.</p>
<div class="exercise admonition" id="ex-prob-tot-1">

<p class="admonition-title"><span class="caption-number">Exercise 85 </span></p>
<section id="exercise-content">
<p>Abbiamo tre urne, ciascuna delle quali contiene 100 palline:</p>
<ul class="simple">
<li><p>Urna 1: 75 palline rosse e 25 palline blu,</p></li>
<li><p>Urna 2: 60 palline rosse e 40 palline blu,</p></li>
<li><p>Urna 3: 45 palline rosse e 55 palline blu.</p></li>
</ul>
<p>Una pallina viene estratta a caso da un’urna anch’essa scelta a caso. Qual è la probabilità che la pallina estratta sia di colore rosso?</p>
<p>Sia <span class="math notranslate nohighlight">\(R\)</span> l’evento «la pallina estratta è rossa» e sia <span class="math notranslate nohighlight">\(U_i\)</span> l’evento che corrisponde alla scelta dell”<span class="math notranslate nohighlight">\(i\)</span>-esima urna. Sappiamo che</p>
<div class="math notranslate nohighlight">
\[
P(R \mid U_1) = 0.75, \quad P(R \mid U_2) = 0.60, \quad P(R \mid U_3) = 0.45.
\]</div>
<p>Gli eventi <span class="math notranslate nohighlight">\(U_1\)</span>, <span class="math notranslate nohighlight">\(U_2\)</span> e <span class="math notranslate nohighlight">\(U_3\)</span> costituiscono una partizione dello spazio campione in quanto <span class="math notranslate nohighlight">\(U_1\)</span>, <span class="math notranslate nohighlight">\(U_2\)</span> e <span class="math notranslate nohighlight">\(U_3\)</span> sono eventi mutualmente esclusivi ed esaustivi, ovvero <span class="math notranslate nohighlight">\(P(U_1 \cup U_2 \cup U_3) = 1.0\)</span>. In base al teorema della probabilità totale, la probabilità di estrarre una pallina rossa è dunque</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
P(R) &amp;= P(R \mid U_1)P(U_1) + P(R \mid U_2)P(U_2) + P(R \mid U_3)P(U_3) \\
&amp;= 0.75 \cdot \frac{1}{3}+0.60 \cdot \frac{1}{3}+0.45 \cdot \frac{1}{3} \\
&amp;=0.60.
\end{split}
\end{split}\]</div>
</section>
</div>
<section id="indipendenza-e-probabilita-condizionata">
<h3>Indipendenza e probabilità condizionata<a class="headerlink" href="#indipendenza-e-probabilita-condizionata" title="Link to this heading">#</a></h3>
<p>L’indipendenza tra due eventi <span class="math notranslate nohighlight">\(A\)</span> e <span class="math notranslate nohighlight">\(B\)</span> può essere espressa in modo intuitivo utilizzando la probabilità condizionata. Se <span class="math notranslate nohighlight">\(A\)</span> e <span class="math notranslate nohighlight">\(B\)</span> sono indipendenti, il verificarsi di uno degli eventi non influisce sulla probabilità del verificarsi dell’altro. In altre parole, la probabilità che <span class="math notranslate nohighlight">\(A\)</span> accada non cambia se sappiamo che <span class="math notranslate nohighlight">\(B\)</span> è avvenuto, e viceversa.</p>
<p>Possiamo esprimere questa idea con le seguenti equazioni:</p>
<div class="math notranslate nohighlight">
\[
P(A \mid B) = \frac{P(A \cap B)}{P(B)} = P(A),
\]</div>
<div class="math notranslate nohighlight">
\[
P(B \mid A) = \frac{P(A \cap B)}{P(A)} = P(B).
\]</div>
<p>Quindi, due eventi <span class="math notranslate nohighlight">\(A\)</span> e <span class="math notranslate nohighlight">\(B\)</span> sono indipendenti se soddisfano le condizioni:</p>
<div class="math notranslate nohighlight">
\[
P(A \mid B) = P(A),
\]</div>
<div class="math notranslate nohighlight">
\[
P(B \mid A) = P(B).
\]</div>
<p>Questo significa che la probabilità di <span class="math notranslate nohighlight">\(A\)</span> rimane invariata indipendentemente dal fatto che <span class="math notranslate nohighlight">\(B\)</span> sia accaduto o meno, e lo stesso vale per <span class="math notranslate nohighlight">\(B\)</span>.</p>
<section id="indipendenza-di-tre-eventi">
<h4>Indipendenza di Tre Eventi<a class="headerlink" href="#indipendenza-di-tre-eventi" title="Link to this heading">#</a></h4>
<p>Tre eventi <span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(B\)</span> e <span class="math notranslate nohighlight">\(C\)</span> sono indipendenti se soddisfano le seguenti condizioni:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
P(A \cap B) &amp;= P(A) P(B), \\
P(A \cap C) &amp;= P(A) P(C), \\
P(B \cap C) &amp;= P(B) P(C), \\
P(A \cap B \cap C) &amp;= P(A) P(B) P(C).
\end{align}
\end{split}\]</div>
<p>Le prime tre condizioni verificano l’indipendenza a due a due, ovvero l’indipendenza di ciascuna coppia di eventi. Tuttavia, per essere completamente indipendenti, deve essere soddisfatta anche l’ultima condizione, che riguarda l’intersezione di tutti e tre gli eventi. Solo se tutte queste condizioni sono soddisfatte possiamo dire che <span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(B\)</span> e <span class="math notranslate nohighlight">\(C\)</span> sono completamente indipendenti.</p>
<p>In sintesi, l’indipendenza tra eventi implica che la conoscenza del verificarsi di uno non fornisce alcuna informazione sulla probabilità del verificarsi degli altri.</p>
<div class="exercise admonition" id="ex-queen-spades">

<p class="admonition-title"><span class="caption-number">Exercise 86 </span></p>
<section id="exercise-content">
<p>Consideriamo un esempio utilizzando un mazzo di 52 carte. Ogni seme contiene 13 carte e ci sono 4 regine in totale. Definiamo i seguenti eventi:</p>
<ul class="simple">
<li><p>Evento A: pescare una carta di picche,</p></li>
<li><p>Evento B: pescare una regina.</p></li>
</ul>
<p><strong>Probabilità con un mazzo completo</strong></p>
<p>In un mazzo completo, la probabilità di pescare una carta di picche (<span class="math notranslate nohighlight">\(P(A)\)</span>) è <span class="math notranslate nohighlight">\( \frac{13}{52} = \frac{1}{4} \)</span>, poiché ci sono 13 picche su 52 carte totali. La probabilità di pescare una regina (<span class="math notranslate nohighlight">\(P(B)\)</span>) è <span class="math notranslate nohighlight">\( \frac{4}{52} = \frac{1}{13} \)</span>, poiché ci sono 4 regine su 52 carte.</p>
<p>Ora consideriamo la probabilità congiunta di pescare la regina di picche (<span class="math notranslate nohighlight">\(P(AB)\)</span>). Poiché esiste solo una regina di picche nel mazzo, la probabilità di pescare questa specifica carta è <span class="math notranslate nohighlight">\( \frac{1}{52} \)</span>.</p>
<p>Secondo la definizione di indipendenza, se gli eventi <span class="math notranslate nohighlight">\(A\)</span> e <span class="math notranslate nohighlight">\(B\)</span> sono indipendenti, allora:</p>
<div class="math notranslate nohighlight">
\[ P(AB) = P(A)P(B) \]</div>
<p>Calcoliamo <span class="math notranslate nohighlight">\(P(A)P(B)\)</span>:</p>
<div class="math notranslate nohighlight">
\[ P(A)P(B) = \left( \frac{1}{4} \right) \left( \frac{1}{13} \right) = \frac{1}{52} \]</div>
<p>Poiché <span class="math notranslate nohighlight">\(P(AB) = \frac{1}{52}\)</span> è uguale a <span class="math notranslate nohighlight">\(P(A)P(B)\)</span>, possiamo affermare che gli eventi <span class="math notranslate nohighlight">\(A\)</span> e <span class="math notranslate nohighlight">\(B\)</span> sono indipendenti con un mazzo completo di 52 carte.</p>
<p><strong>Probabilità dopo la rimozione di una carta</strong></p>
<p>Consideriamo ora un mazzo con una carta in meno, ad esempio il due di quadri, riducendo il numero totale di carte a 51. Ricalcoliamo le probabilità con questo mazzo ridotto:</p>
<p>La probabilità di pescare la regina di picche (<span class="math notranslate nohighlight">\(P(AB)\)</span>) è ora <span class="math notranslate nohighlight">\( \frac{1}{51} \)</span>, poiché ci sono 51 carte nel mazzo.</p>
<p>Ricalcoliamo anche <span class="math notranslate nohighlight">\(P(A)\)</span> e <span class="math notranslate nohighlight">\(P(B)\)</span>:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(A)\)</span> diventa <span class="math notranslate nohighlight">\( \frac{13}{51} \)</span>, poiché ci sono ancora 13 picche, ma su 51 carte.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(B)\)</span> diventa <span class="math notranslate nohighlight">\( \frac{4}{51} \)</span>, poiché ci sono ancora 4 regine, ma su 51 carte.</p></li>
</ul>
<p>Ora calcoliamo il prodotto <span class="math notranslate nohighlight">\(P(A)P(B)\)</span> con queste nuove probabilità:</p>
<div class="math notranslate nohighlight">
\[ P(A)P(B) = \left( \frac{13}{51} \right) \left( \frac{4}{51} \right) = \frac{52}{2601} \]</div>
<p>Confrontiamo <span class="math notranslate nohighlight">\(P(AB)\)</span> e <span class="math notranslate nohighlight">\(P(A)P(B)\)</span>:</p>
<div class="math notranslate nohighlight">
\[ \frac{1}{51} \neq \frac{52}{2601} \]</div>
<p>Poiché <span class="math notranslate nohighlight">\( \frac{1}{51} \neq \frac{52}{2601} \)</span>, gli eventi <span class="math notranslate nohighlight">\(A\)</span> e <span class="math notranslate nohighlight">\(B\)</span> non sono più indipendenti dopo la rimozione del due di quadri.</p>
<p>Questo esempio mostra come l’indipendenza tra due eventi dipenda dal contesto. Con un mazzo completo, i due eventi sono indipendenti. Tuttavia, rimuovendo una carta dal mazzo, le probabilità cambiano e gli eventi non sono più indipendenti. Questo evidenzia l’importanza di considerare la composizione e le condizioni iniziali quando si analizzano probabilità e indipendenza. Modifiche nella composizione del mazzo possono alterare le probabilità, influenzando le relazioni di indipendenza tra eventi specifici.</p>
<p>In generale, l’indipendenza tra due eventi significa che la probabilità di uno non è influenzata dal verificarsi dell’altro. Questo concetto è cruciale per analisi probabilistiche e modelli statistici più complessi.</p>
</section>
</div>
<div class="exercise admonition" id="ex-two-dice-independence">

<p class="admonition-title"><span class="caption-number">Exercise 87 </span></p>
<section id="exercise-content">
<p>Nel lancio di due dadi non truccati, si considerino gli eventi: <span class="math notranslate nohighlight">\(A\)</span> = «esce un 1 o un 2 nel primo lancio» e <span class="math notranslate nohighlight">\(B\)</span> = «il punteggio totale è 8». Gli eventi <span class="math notranslate nohighlight">\(A\)</span> e <span class="math notranslate nohighlight">\(B\)</span> sono indipendenti?</p>
<p>Calcoliamo <span class="math notranslate nohighlight">\(P(A)\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">r</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">sample</span> <span class="o">=</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">r</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">r</span><span class="p">]</span>
<span class="n">A</span> <span class="o">=</span> <span class="p">[</span><span class="n">roll</span> <span class="k">for</span> <span class="n">roll</span> <span class="ow">in</span> <span class="n">sample</span> <span class="k">if</span> <span class="n">roll</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">roll</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="si">}</span><span class="s2"> / </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6)]
12 / 36
</pre></div>
</div>
</div>
</div>
<p>Calcoliamo <span class="math notranslate nohighlight">\(P(B)\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">B</span> <span class="o">=</span> <span class="p">[</span><span class="n">roll</span> <span class="k">for</span> <span class="n">roll</span> <span class="ow">in</span> <span class="n">sample</span> <span class="k">if</span> <span class="n">roll</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">roll</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">8</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">B</span><span class="p">)</span><span class="si">}</span><span class="s2"> / </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(2, 6), (3, 5), (4, 4), (5, 3), (6, 2)]
5 / 36
</pre></div>
</div>
</div>
</div>
<p>Calcoliamo <span class="math notranslate nohighlight">\(P(A \cap B)\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">I</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">roll</span>
    <span class="k">for</span> <span class="n">roll</span> <span class="ow">in</span> <span class="n">sample</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">roll</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">roll</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">roll</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">roll</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">8</span><span class="p">)</span>
<span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">I</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">I</span><span class="p">)</span><span class="si">}</span><span class="s2"> / </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(2, 6)]
1 / 36
</pre></div>
</div>
</div>
</div>
<p>Gli eventi <span class="math notranslate nohighlight">\(A\)</span> e <span class="math notranslate nohighlight">\(B\)</span> non sono statisticamente indipendenti dato che <span class="math notranslate nohighlight">\(P(A \cap B) \neq P(A)P(B)\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="mi">12</span><span class="o">/</span><span class="mi">36</span> <span class="o">*</span> <span class="mi">5</span><span class="o">/</span><span class="mi">36</span> <span class="o">==</span> <span class="mi">1</span><span class="o">/</span><span class="mi">36</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>False
</pre></div>
</div>
</div>
</div>
</section>
</div>
</section>
</section>
</section>
<section id="commenti-e-considerazioni-finali">
<h2>Commenti e considerazioni finali<a class="headerlink" href="#commenti-e-considerazioni-finali" title="Link to this heading">#</a></h2>
<p>La probabilità condizionata riveste un ruolo fondamentale poiché ci permette di definire in modo preciso il concetto di indipendenza statistica. Uno degli aspetti cruciali dell’analisi statistica riguarda la valutazione dell’associazione tra due variabili. Nel capitolo attuale, ci siamo concentrati sul concetto di indipendenza, che indica l’assenza di relazione tra le variabili. Tuttavia, in futuro, esploreremo come fare inferenze sulla correlazione tra variabili, ovvero come determinare se le variabili sono associate tra loro o se esiste una relazione statistica credibile tra di esse.</p>
<p>Nell’ambito dell’inferenza bayesiana, il condizionamento emerge come uno strumento essenziale. L’inferenza bayesiana è un approccio statistico che sfrutta proprio il condizionamento per rivedere e aggiornare le credenze o le incertezze relative a determinate ipotesi, basandosi sull’introduzione di nuove informazioni.</p>
<p>Il processo inizia stabilendo una probabilità iniziale, denominata probabilità a priori (<span class="math notranslate nohighlight">\(P(A)\)</span>), che esprime la nostra convinzione o supposizione iniziale riguardo all’ipotesi <span class="math notranslate nohighlight">\(A\)</span>, prima di ricevere qualsiasi dato aggiuntivo. Questa probabilità a priori si fonda su conoscenze già acquisite o su supposizioni precedentemente formulate.</p>
<p>Il cuore dell’inferenza bayesiana si trova nell’aggiornamento di questa credenza iniziale in risposta all’acquisizione di nuove informazioni, rappresentate dalla variabile <span class="math notranslate nohighlight">\(E\)</span>. L’aggiornamento avviene mediante il condizionamento, culminando nella determinazione di una probabilità a posteriori (<span class="math notranslate nohighlight">\(P(A | E)\)</span>). Questa nuova probabilità rappresenta la nostra credenza aggiornata sull’ipotesi <span class="math notranslate nohighlight">\(A\)</span> dopo aver preso in esame l’evidenza <span class="math notranslate nohighlight">\(E\)</span> appena acquisita. In questo modo, l’inferenza bayesiana permette di affinare le nostre supposizioni e le nostre previsioni su determinati fenomeni, incorporando sistematicamente nuove prove nel nostro quadro di conoscenza.</p>
<p>La formula di Bayes governa questo processo di aggiornamento:</p>
<div class="math notranslate nohighlight">
\[
P(A | E) = \frac{P(E | A) \times P(A)}{P(E)}
\]</div>
<p>In questa formula, troviamo:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(A | E)\)</span>: la probabilità a posteriori, che è la probabilità dell’ipotesi <span class="math notranslate nohighlight">\(A\)</span> date le nuove prove <span class="math notranslate nohighlight">\(E\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(E | A)\)</span>: la verosimiglianza, ovvero la probabilità di osservare le prove <span class="math notranslate nohighlight">\(E\)</span> se l’ipotesi <span class="math notranslate nohighlight">\(A\)</span> fosse vera.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(A)\)</span>: la probabilità a priori, che indica il nostro livello di convinzione iniziale nell’ipotesi <span class="math notranslate nohighlight">\(A\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(E)\)</span>: la probabilità di osservare le prove <span class="math notranslate nohighlight">\(E\)</span>, tenendo conto di tutte le ipotesi possibili.</p></li>
</ul>
<p>In questo capitolo esploreremo alcuni concetti chiave per una comprensione approfondita dell’aggiornamento bayesiano:</p>
<ul class="simple">
<li><p><strong>Probabilità Congiunta</strong>: Questa è la probabilità che due eventi avvengano insieme. Per esempio, potrebbe riferirsi alla probabilità di estrarre una pallina rossa e poi una verde da un’urna in sequenza.</p></li>
<li><p><strong>Probabilità Marginale</strong>: Si tratta della probabilità di verificarsi di un singolo evento, considerato a prescindere da altri eventi. Ad esempio, potremmo voler calcolare la probabilità di estrarre una pallina verde da un’urna, senza considerare altri eventi.</p></li>
<li><p><strong>Probabilità Condizionata</strong>: Indica la probabilità che un evento si verifichi, dato che un altro evento correlato è già accaduto. Un esempio potrebbe essere la probabilità di estrarre una seconda pallina verde, sapendo che la prima estratta era verde.</p></li>
</ul>
<p>Questi concetti sono fondamentali per navigare nel processo di inferenza bayesiana e per comprendere come le probabilità si aggiornano in risposta a nuove informazioni. Inoltre, esamineremo i principali teoremi legati alla probabilità condizionata.</p>
</section>
<section id="informazioni-sull-ambiente-di-sviluppo">
<h2>Informazioni sull’Ambiente di Sviluppo<a class="headerlink" href="#informazioni-sull-ambiente-di-sviluppo" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> watermark
<span class="o">%</span><span class="k">watermark</span> -n -u -v -iv -w -m 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Last updated: Sun Jun 16 2024

Python implementation: CPython
Python version       : 3.12.3
IPython version      : 8.25.0

Compiler    : Clang 16.0.6 
OS          : Darwin
Release     : 23.4.0
Machine     : arm64
Processor   : arm
CPU cores   : 8
Architecture: 64bit

pandas: 2.2.2
numpy : 1.26.4

Watermark: 2.4.3
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter_3"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="E_prob.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">precedente</p>
        <p class="prev-next-title">✏️ Esercizi</p>
      </div>
    </a>
    <a class="right-next"
       href="E_cond_prob_1.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">successivo</p>
        <p class="prev-next-title">✏️ Esercizi</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contenuti
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparazione-del-notebook">Preparazione del Notebook</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#indipendenza-stocastica">Indipendenza Stocastica</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#indipendenza-di-due-eventi">Indipendenza di Due Eventi</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#indipendenza-di-un-insieme-di-eventi">Indipendenza di un Insieme di Eventi</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#eventi-disgiunti-e-indipendenza">Eventi Disgiunti e Indipendenza</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilita-condizionata-su-altri-eventi">Probabilità condizionata su altri eventi</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#il-paradosso-di-simpson">Il paradosso di Simpson</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#teorema-della-probabilita-composta">Teorema della probabilità composta</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#il-teorema-della-probabilita-totale">Il teorema della probabilità totale</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#indipendenza-e-probabilita-condizionata">Indipendenza e probabilità condizionata</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#indipendenza-di-tre-eventi">Indipendenza di Tre Eventi</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#commenti-e-considerazioni-finali">Commenti e considerazioni finali</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#informazioni-sull-ambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
Di Corrado Caudek
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>