
<!DOCTYPE html>


<html lang="it" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Apprendimento per rinforzo &#8212; ds4p</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css?v=ca93fcec" />
    <link rel="stylesheet" type="text/css" href="../_static/exercise.css?v=20b57f81" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=3ee479438cf8b5e0d341"></script>

    <script src="../_static/documentation_options.js?v=8d586cc4"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="../_static/translations.js?v=0173e136"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-TP2WLBPMS6"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-TP2WLBPMS6');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-TP2WLBPMS6');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter_5/05_40_rescorla_wagner';</script>
    <link rel="canonical" href="https://ccaudek.github.io/ds4p/chapter_5/05_40_rescorla_wagner.html" />
    <link rel="icon" href="../_static/increasing.png"/>
    <link rel="index" title="Indice" href="../genindex.html" />
    <link rel="search" title="Cerca" href="../search.html" />
    <link rel="next" title="Inferenza frequentista" href="../chapter_6/introduction_part_6.html" />
    <link rel="prev" title="Dati mancanti" href="05_35_missing.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="it"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="ds4p - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="ds4p - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Cerca" aria-label="Cerca" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Cerca</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Benvenuti
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_1/introduction_chapter_1.html">Python</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/00_prelims.html">Preliminari</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/01_python_1.html">Python (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/02_python_2.html">Python (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_python.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/03_numpy.html">NumPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_numpy.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/04_pandas.html">Pandas (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/05_pandas_aggregate.html">Pandas (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/06_pandas_functions.html">Pandas (3)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_pandas.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/07_matplotlib.html">Matplotlib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/08_seaborn.html">Seaborn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_matplotlib.html">✏️ Esercizi</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_2/introduction_chapter_2.html">Statistica descrittiva</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/00_scientific_method.html">La scienza dei dati e il metodo scientifico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/01_key_notions.html">Concetti chiave</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_key_notions.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/02_measurement.html">La misurazione in psicologia</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_scales.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/03_freq_distr.html">Dati e frequenze</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_sums.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/04_loc_scale.html">Indici di posizione e di scala</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/05_correlation.html">Le relazioni tra variabili</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/06_causality.html">Lo studio delle cause dei fenomeni</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_eda.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_mehr_song_spelke.html">✏️ Esercizi</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_3/introduction_chapter_3.html">Probabilità</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/01_intro_prob.html">Introduzione al calcolo delle probabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/02_conditional_prob.html">Probabilità condizionata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_cond_prob_1.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_cond_prob_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_discrete_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/03_bayes_theorem.html">Il teorema di Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_bayes_theorem.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_bayes_theorem_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/04a_random_var.html">Introduzione alle variabili casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/04b_expval_var.html">Proprietà delle variabili casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_exp_val_variance.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/04c_sampling_distr.html">Stime, stimatori e parametri</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_rv_discrete.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/05_joint_prob.html">Probabilità congiunta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_joint_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_covariance.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/06_density_func.html">La funzione di densità di probabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/07_discr_rv_distr.html">Distribuzioni di v.c. discrete</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_binomial.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/08_cont_rv_distr.html">Distribuzioni di v.c. continue</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_gaussian.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_beta_distr.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/09_likelihood.html">La verosimiglianza</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_likelihood.html">✏️ Esercizi</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_4/introduction_part_4.html">Inferenza bayesiana</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/01_intro_bayes.html">Modellazione bayesiana</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/02_subj_prop.html">Pensare ad una proporzione in termini soggettivi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/02_grid_gauss.html">Verosimiglianza Gaussiana: Metodo Basato su Griglia</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/03_conjugate_families_1.html">Distribuzioni coniugate</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/E_conjugate_families_1.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/04_conjugate_families_2.html">Distribuzioni coniugate (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/05_summary_posterior.html">Sintesi a posteriori</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/E_conjugate.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/06_balance-prior-post.html">L’influenza della distribuzione a priori</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/10_metropolis.html">Monte Carlo a Catena di Markov</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/15_stan_beta_binomial.html">Introduzione a Stan</a></li>

<li class="toctree-l2"><a class="reference internal" href="../chapter_4/E_stan_beta_binomial.html">✏️ Esercizio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/16_stan_summary_posterior.html">Metodi di sintesi della distribuzione a posteriori</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/17_stan_diagnostics.html">Diagnostica delle catene markoviane</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/18_stan_prediction.html">La predizione bayesiana</a></li>

<li class="toctree-l2"><a class="reference internal" href="../chapter_4/19_stan_odds_ratio.html">Analisi bayesiana dell’odds-ratio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/22_stan_normal_normal.html">Inferenza bayesiana su una media</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/23_stan_two_groups.html">Confronto tra due gruppi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/24_stan_hier_beta_binom.html">Modello gerarchico beta-binomiale con Stan</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="introduction_part_5.html">Analisi della regressione</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="05_03_reglin_bayesian.html">Analisi bayesiana del modello di regressione lineare bivariato</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_reglin_1.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_04_synt_sugar.html">Zucchero sintattico</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_05_two_means.html">Confronto tra le medie di due gruppi</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_reglin_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_reglin_3.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_reglin_4.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_06_hier_regr.html">Il modello lineare gerarchico</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_07_robust_regr.html">Regressione robusta</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_08_specification_error.html">Errore di specificazione</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_09_causal_inference.html">Inferenza causale</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_causal_inference.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_22_stan_logistic_regr.html">Regressione logistica con Stan</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_24_stan_mixed_models.html">Modelli misti con Stan</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_25_stan_rct.html">Incorporare dati storici di controllo in una RCT</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_26_stan_mediation.html">Modello di mediazione con Stan</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_30_entropy.html">Entropia</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_31_kl.html">La divergenza di Kullback-Leibler</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_kl.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_32_stan_loo.html">Validazione Incrociata Leave-One-Out</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_35_missing.html">Dati mancanti</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Apprendimento per rinforzo</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_6/introduction_part_6.html">Inferenza frequentista</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/01_intro_frequentist.html">Introduzione all’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_estimation.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/02_conf_interv.html">Intervallo di confidenza</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_conf_interv.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/03_test_ipotesi.html">Significatività statistica</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_t_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_interpretation_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_significato_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/04_two_ind_samples.html">Test t di Student per campioni indipendenti</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_test_media_pop.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_medie_pop_ampie.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_medie_pop_piccoli.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_campioni_appaiati.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_confronto_proporzioni.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/05_crisis.html">La crisi della generalizzabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/06_limiti_stat_frequentista.html">Limiti dell’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/07_effect_size.html">La grandezza dell’effetto</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/09_s_m_errors.html">Crisi della replicabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/10_integrity.html">Integrità della ricerca</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../references/bibliography.html">Bibliografia</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_7/introduction_appendix.html">Appendici</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a00_installation.html">Ambiente di lavoro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a01_markdown.html">Jupyter Notebook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a02_shell.html">La Shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a03_colab_tutorial.html">Colab: un breve tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a04_virtual_env.html">Ambienti virtuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a10_math_symbols.html">Simbologia di base</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a11_numbers.html">Numeri binari, interi, razionali, irrazionali e reali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a12_sum_notation.html">Simbolo di somma (sommatorie)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a13_sets.html">Insiemi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a13a_probability.html">Sigma algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a14_combinatorics.html">Calcolo combinatorio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a15_calculus.html">Per liberarvi dai terrori preliminari</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a20_kde_plot.html">Kernel Density Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a30_prob_tutorial.html">Esercizi di probabilità discreta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a40_rng.html">Generazione di numeri casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a44_montecarlo.html">Simulazione Monte Carlo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a45_mcmc.html">Catene di Markov</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a46_stan.html">Linguaggio Stan</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a50_lin_fun.html">La funzione lineare</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a50_reglin_ml.html">Modello di Regressione Bivariato e ML</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a51_reglin_1.html">Regressione lineare bivariata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a60_ttest_exercises.html">Esercizi sull’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a70_predict_counts.html">La predizione delle frequenze</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/ccaudek/ds4p/blob/main/docs/chapter_5/05_40_rescorla_wagner.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Scarica questa pagina">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapter_5/05_40_rescorla_wagner.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Scarica il file sorgente"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Stampa in PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Modalità schermo intero"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Cerca" aria-label="Cerca" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Apprendimento per rinforzo</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contenuti </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#two-armed-bandits">Two-armed bandits</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulare-l-apprendimento">Simulare l’Apprendimento</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parametri-del-problema">Parametri del Problema</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#esempio-pratico">Esempio Pratico</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modello-di-apprendimento-di-rescorla-wagner">Modello di Apprendimento di Rescorla-Wagner</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#la-regola-di-apprendimento-delta-rule">La Regola di Apprendimento (<span class="math notranslate nohighlight">\(\delta\)</span>-rule)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#softmax-la-regola-decisionale">Softmax: La Regola Decisionale</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#esempio-di-calcolo-della-softmax">Esempio di Calcolo della Softmax</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#variazione-di-theta-con-valori-fissi-di-q">Variazione di <span class="math notranslate nohighlight">\(\theta\)</span> con Valori Fissi di <span class="math notranslate nohighlight">\(Q\)</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulazione-del-modello-di-rescorla-wagner">Simulazione del Modello di Rescorla-Wagner</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adattamento-del-modello">Adattamento del Modello</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#la-massima-verosimiglianza">La Massima Verosimiglianza</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#calcolo-del-logaritmo-della-verosimiglianza">Calcolo del Logaritmo della Verosimiglianza</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#minimizzazione-del-logaritmo-negativo-della-verosimiglianza">Minimizzazione del Logaritmo Negativo della Verosimiglianza</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Esempio Pratico</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#validazione">Validazione</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stima-con-stan">Stima con Stan</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sezione-data">Sezione <code class="docutils literal notranslate"><span class="pre">data</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sezione-transformed-data">Sezione <code class="docutils literal notranslate"><span class="pre">transformed</span> <span class="pre">data</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sezione-parameters">Sezione <code class="docutils literal notranslate"><span class="pre">parameters</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sezione-model">Sezione <code class="docutils literal notranslate"><span class="pre">model</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#priori">Priori</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ciclo-sui-tentativi">Ciclo sui Tentativi</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inferenza">Inferenza</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretazione-delle-stime-dei-parametri">Interpretazione delle Stime dei Parametri</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#informazioni-sull-ambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="apprendimento-per-rinforzo">
<h1>Apprendimento per rinforzo<a class="headerlink" href="#apprendimento-per-rinforzo" title="Link to this heading">#</a></h1>
<p>In questa sezione delle dispense abbiamo esaminato il modello di regressione. Sebbene il modello di regressione sia estremamente popolare in psicologia e nelle scienze sociali, presenta dei limiti sostanziali. È utile per descrivere le associazioni tra variabili, ma non è adatto per scoprire nessi causali, che rappresentano l’obiettivo principale delle teorie scientifiche. Come afferma Richard McElreath: «Le persone una volta facevano teoria. Ora fanno solo regressioni».</p>
<p>Trovare associazioni nei dati osservazionali non è un buon metodo per costruire teorie. Abbiamo bisogno di una motivazione per esaminare determinate variabili, poiché le associazioni tra variabili non sono rare, ma raramente sono causali. Il fatto che nessuno abbia esaminato l’associazione tra certe variabili in precedenza non è un buon motivo per farlo in un nuovo progetto di ricerca.</p>
<p>Un approccio preferibile, che una volta era comune, è utilizzare una teoria formale per sviluppare aspettative sui dati osservati, misurare le variabili corrette e utilizzare modelli statistici specifici per testare la teoria, non solo regressioni.</p>
<p>In questo capitolo, forniremo un esempio di questo approccio implementando un modello che rappresenta un processo cognitivo sottostante, piuttosto che limitarsi a descrivere le associazioni tra variabili. Nello specifico, esamineremo uno dei modelli psicologici più influenti: il modello di apprendimento di Rescorla-Wagner. Analizzeremo la definizione del modello, il significato dei suoi parametri e i metodi per stimarli dai dati osservati, con particolare attenzione all’uso della massima verosimiglianza e del software Stan.</p>
<p>Il presente tutorial trae ispirazione dall’articolo di <a class="reference external" href="https://elifesciences.org/articles/49547">Wilson &amp; Collins (2019)</a> e utilizza il codice fornito da <a class="reference external" href="https://shawnrhoads.github.io/gu-psyc-347/index.html">Rhoads, S. A. &amp; Gan, L. (2022)</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> ../_config/config.py # Import the configuration settings
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>  <span class="c1"># finding optimal params in models</span>
<span class="kn">import</span> <span class="nn">cmdstanpy</span>
<span class="kn">from</span> <span class="nn">cmdstanpy</span> <span class="kn">import</span> <span class="n">CmdStanModel</span>
<span class="n">cmdstanpy</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">get_logger</span><span class="p">()</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="two-armed-bandits">
<h2>Two-armed bandits<a class="headerlink" href="#two-armed-bandits" title="Link to this heading">#</a></h2>
<p>Le nostre aspettative modellano il modo in cui ricordiamo il passato, viviamo il presente e prevediamo il futuro. Queste aspettative sono costruite su esperienze precedenti e sono fortemente influenzate da eventi inaspettati. Gli eventi inaspettati creano errori di previsione, definiti come deviazioni positive o negative dalle aspettative, e guidano l’apprendimento. La misura in cui i singoli errori di previsione influenzano le aspettative è chiamata tasso di apprendimento.</p>
<p>L’errore di previsione è il meccanismo su cui si basa il modello di apprendimento di Rescorla-Wagner, e il tasso di apprendimento è uno dei suoi parametri fondamentali. Il tipo di apprendimento che il modello di Rescorla-Wagner intende spiegare è quello che descrive il comportamento di un agente di fronte al problema del «two-armed bandits».</p>
<p>In questo problema, un partecipante deve fare ripetutamente delle scelte tra due opzioni o azioni. Dopo ogni scelta, riceve una ricompensa numerica estratta da una distribuzione di probabilità dipendente dall’azione selezionata. L’obiettivo del partecipante è massimizzare la ricompensa totale attesa durante un certo periodo di tempo, ad esempio, durante 100 scelte.</p>
<p>Una metafora comune per descrivere questa situazione è quella di un giocatore che deve fare una serie di scelte tra due slot machine (chiamate anche «two-armed bandits») per massimizzare le sue vincite. Se nella scelta <span class="math notranslate nohighlight">\( t \)</span> viene selezionata la slot machine <span class="math notranslate nohighlight">\( k \)</span>, il partecipante ottiene una ricompensa <span class="math notranslate nohighlight">\( r_t \)</span>. Questa ricompensa ha valore <code class="docutils literal notranslate"><span class="pre">1</span></code> con una probabilità di successo <span class="math notranslate nohighlight">\( \mu^k_t \)</span> specifica per quella slot machine, altrimenti ha valore <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p>
<p>In altre parole:</p>
<ul class="simple">
<li><p>Ogni volta che il partecipante sceglie una slot machine, può vincere (ottenendo una ricompensa di <code class="docutils literal notranslate"><span class="pre">1</span></code>) o perdere (ottenendo una ricompensa di <code class="docutils literal notranslate"><span class="pre">0</span></code>).</p></li>
<li><p>La probabilità di vincita varia tra le due diverse slot machine.</p></li>
<li><p>Queste probabilità di successo sono inizialmente sconosciute al partecipante.</p></li>
</ul>
<p>Nella versione più semplice di questo problema, le probabilità di successo <span class="math notranslate nohighlight">\( \mu^k_t \)</span> rimangono costanti nel tempo. Questo significa che la probabilità di vincere su una determinata slot machine non cambia durante il periodo di osservazione.</p>
</section>
<section id="simulare-l-apprendimento">
<h2>Simulare l’Apprendimento<a class="headerlink" href="#simulare-l-apprendimento" title="Link to this heading">#</a></h2>
<p>Nel problema del two-armed bandit, ogni azione (cioè la scelta di una specifica slot machine) ha un valore associato che rappresenta la ricompensa attesa quando quella specifica azione viene selezionata. Questo valore è chiamato «valore dell’azione». Conoscendo il valore di ogni azione, il problema di apprendimento si riduce a scegliere sempre l’azione con il valore più alto per massimizzare la ricompensa totale.</p>
<section id="parametri-del-problema">
<h3>Parametri del Problema<a class="headerlink" href="#parametri-del-problema" title="Link to this heading">#</a></h3>
<p>Per simulare il problema, dobbiamo considerare tre parametri principali:</p>
<ol class="arabic simple">
<li><p><strong>Il numero di tentativi, <span class="math notranslate nohighlight">\( T \)</span></strong>: Questo rappresenta quante volte il partecipante farà una scelta. Ad esempio, se <span class="math notranslate nohighlight">\( T = 100 \)</span>, il partecipante farà 100 scelte.</p></li>
<li><p><strong>Il numero di slot machine, <span class="math notranslate nohighlight">\( K \)</span></strong>: Questo indica quante opzioni di scelta sono disponibili. Ad esempio, se <span class="math notranslate nohighlight">\( K = 2 \)</span>, ci sono due slot machine tra cui scegliere.</p></li>
<li><p><strong>Le probabilità di ricompensa delle diverse opzioni, <span class="math notranslate nohighlight">\( \mu^k_t \)</span></strong>: Queste sono le probabilità che ogni slot machine offra una ricompensa. Queste probabilità possono variare nel tempo, ma nella versione più semplice del problema, rimangono costanti.</p></li>
</ol>
</section>
<section id="esempio-pratico">
<h3>Esempio Pratico<a class="headerlink" href="#esempio-pratico" title="Link to this heading">#</a></h3>
<p>In questo tutorial, simuleremo il comportamento di un partecipante che sceglie tra due slot machine, utilizzando il modello di apprendimento di Rescorla-Wagner. Ecco come configureremo la simulazione:</p>
<ul class="simple">
<li><p>Imposteremo il numero di tentativi a <span class="math notranslate nohighlight">\( T = 100 \)</span>. Questo significa che il partecipante farà 100 scelte.</p></li>
<li><p>Imposteremo il numero di slot machine a <span class="math notranslate nohighlight">\( K = 2 \)</span>. Ci saranno quindi due slot machine tra cui scegliere.</p></li>
<li><p>Imposteremo le probabilità di ricompensa delle slot machine a <span class="math notranslate nohighlight">\( \mu = [0.2, 0.8] \)</span>. Questo significa che la slot machine 1 ha una probabilità del 20% di offrire una ricompensa, mentre la slot machine 2 ha una probabilità dell’80% di offrire una ricompensa.</p></li>
</ul>
<p>Ogni azione ha un valore che rappresenta la ricompensa attesa. In altre parole, il valore dell’azione è la media delle ricompense che ci si aspetta di ottenere scegliendo quella particolare azione. Se si conosce questo valore per ogni azione, il partecipante dovrebbe sempre scegliere l’azione con il valore più alto per massimizzare le sue ricompense.</p>
<p>L’obiettivo di questo tutorial è mostrare come si può simulare il processo di apprendimento e come si possono usare modelli come quello di Rescorla-Wagner per capire meglio come le persone prendono decisioni in situazioni di incertezza. Attraverso la simulazione, vedremo come il partecipante può apprendere e adattarsi alle probabilità di ricompensa delle slot machine per massimizzare le sue vincite nel corso del tempo.</p>
</section>
</section>
<section id="modello-di-apprendimento-di-rescorla-wagner">
<h2>Modello di Apprendimento di Rescorla-Wagner<a class="headerlink" href="#modello-di-apprendimento-di-rescorla-wagner" title="Link to this heading">#</a></h2>
<p>Il modello di apprendimento di Rescorla-Wagner è stato sviluppato per spiegare come gli organismi apprendono le associazioni tra eventi, ed è particolarmente utile nel modellare l’apprendimento associativo come il condizionamento classico. Il modello propone che l’apprendimento avvenga attraverso l’aggiornamento delle aspettative in base agli errori di previsione, ovvero le discrepanze tra ciò che è atteso e ciò che viene effettivamente osservato.</p>
<section id="la-regola-di-apprendimento-delta-rule">
<h3>La Regola di Apprendimento (<span class="math notranslate nohighlight">\(\delta\)</span>-rule)<a class="headerlink" href="#la-regola-di-apprendimento-delta-rule" title="Link to this heading">#</a></h3>
<p>Secondo il modello di Rescorla-Wagner, il valore atteso di una scelta (<span class="math notranslate nohighlight">\( Q^k_t \)</span>) viene aggiornato dopo ogni tentativo utilizzando la seguente formula:</p>
<div class="math notranslate nohighlight">
\[ 
Q^k_{t+1} = Q^k_t + \alpha (r_t - Q^k_t),
\]</div>
<p>dove:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( Q^k_t \)</span> è il valore atteso della scelta <span class="math notranslate nohighlight">\( k \)</span> al tempo <span class="math notranslate nohighlight">\( t \)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\( \alpha \)</span> è il tasso di apprendimento, compreso tra 0 e 1, che determina quanto rapidamente si adattano le aspettative.</p></li>
<li><p><span class="math notranslate nohighlight">\( r_t \)</span> è la ricompensa ottenuta dopo aver fatto la scelta <span class="math notranslate nohighlight">\( k \)</span> al tempo <span class="math notranslate nohighlight">\( t \)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\( r_t - Q^k_t \)</span> rappresenta l’errore di previsione, cioè la differenza tra la ricompensa ottenuta e quella attesa.</p></li>
</ul>
<p>Un valore più alto di <span class="math notranslate nohighlight">\( \alpha \)</span> significa che l’aggiornamento delle aspettative è più rapido, mentre un valore più basso implica un aggiornamento più lento.</p>
</section>
<section id="softmax-la-regola-decisionale">
<h3>Softmax: La Regola Decisionale<a class="headerlink" href="#softmax-la-regola-decisionale" title="Link to this heading">#</a></h3>
<p>Per decidere quale scelta fare, utilizziamo la regola <em>softmax</em>, che permette ai partecipanti di scegliere più frequentemente l’opzione con il valore atteso più alto, ma anche di esplorare occasionalmente altre opzioni. La regola di scelta <em>softmax</em> converte i valori attesi <span class="math notranslate nohighlight">\( Q \)</span> in probabilità di scelta:</p>
<div class="math notranslate nohighlight">
\[
p^k_t = \frac{\exp(\theta Q^k_t)}{\sum_{i=1}^K \exp(\theta Q^i_t)},
\]</div>
<p>dove:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( p^k_t \)</span> è la probabilità di scegliere l’opzione <span class="math notranslate nohighlight">\( k \)</span> al tempo <span class="math notranslate nohighlight">\( t \)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\( \theta \)</span> è un parametro chiamato “temperatura” che controlla il livello di esplorazione rispetto alla scelta deterministica. Valori alti di <span class="math notranslate nohighlight">\( \theta \)</span> portano a scelte più deterministiche (sempre scegliere l’opzione con il valore atteso più alto), mentre valori bassi portano a scelte più casuali.</p></li>
</ul>
<p>Il modello di Rescorla-Wagner, con la sua enfasi sull’errore di previsione, fornisce una spiegazione chiara e matematica di come gli organismi aggiornano le loro aspettative e prendono decisioni basate su esperienze passate e ricompense ricevute.</p>
<section id="esempio-di-calcolo-della-softmax">
<h4>Esempio di Calcolo della Softmax<a class="headerlink" href="#esempio-di-calcolo-della-softmax" title="Link to this heading">#</a></h4>
<p>Per capire come funziona la softmax, consideriamo alcuni valori di <span class="math notranslate nohighlight">\(Q\)</span> e <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span> <span class="o">*</span> <span class="n">Q</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span> <span class="o">*</span> <span class="n">Q</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">p</span>

<span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">])</span>
<span class="n">theta</span> <span class="o">=</span> <span class="mf">3.5</span>
<span class="nb">print</span><span class="p">(</span><span class="n">softmax</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">theta</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.1480472 0.8519528]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">theta</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="nb">print</span><span class="p">(</span><span class="n">softmax</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">theta</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.4378235 0.5621765]
</pre></div>
</div>
</div>
</div>
<p>La funzione softmax trasforma i valori <span class="math notranslate nohighlight">\(Q\)</span> e <span class="math notranslate nohighlight">\(\theta\)</span> in una distribuzione di probabilità, mostrando come la probabilità di scelta cambia al variare di <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
</section>
</section>
<section id="variazione-di-theta-con-valori-fissi-di-q">
<h3>Variazione di <span class="math notranslate nohighlight">\(\theta\)</span> con Valori Fissi di <span class="math notranslate nohighlight">\(Q\)</span><a class="headerlink" href="#variazione-di-theta-con-valori-fissi-di-q" title="Link to this heading">#</a></h3>
<p>Manteniamo fissi i valori di <span class="math notranslate nohighlight">\(Q\)</span> e facciamo variare <span class="math notranslate nohighlight">\(\theta\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">])</span>
<span class="n">theta_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="n">probabilities_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">theta</span> <span class="ow">in</span> <span class="n">theta_values</span><span class="p">:</span>
    <span class="n">probabilities</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span>
    <span class="n">probabilities_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)</span>
    
<span class="n">probabilities_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">probabilities_list</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

<span class="n">option_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Opzione 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Opzione 2&#39;</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">option_labels</span><span class="p">)):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">theta_values</span><span class="p">,</span> <span class="n">probabilities_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">option_labels</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Theta&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Probabilità&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Funzione Softmax - Modello Rescorla-Wagner&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/af49c5e93d801e379d9762bcf05677a150aa6a3951d8b3347a36c1e2c50d30e7.png"><img alt="../_images/af49c5e93d801e379d9762bcf05677a150aa6a3951d8b3347a36c1e2c50d30e7.png" src="../_images/af49c5e93d801e379d9762bcf05677a150aa6a3951d8b3347a36c1e2c50d30e7.png" style="width: 731px; height: 491px;" /></a>
</div>
</div>
<p>Il grafico risultante mostra come le probabilità di scelta cambiano al variare del parametro <span class="math notranslate nohighlight">\(\theta\)</span>. Quando <span class="math notranslate nohighlight">\(\theta\)</span> è vicino a zero, la scelta è quasi casuale. Quando <span class="math notranslate nohighlight">\(\theta\)</span> è molto grande, la scelta è quasi sempre l’opzione con il valore più alto.</p>
</section>
</section>
<section id="simulazione-del-modello-di-rescorla-wagner">
<h2>Simulazione del Modello di Rescorla-Wagner<a class="headerlink" href="#simulazione-del-modello-di-rescorla-wagner" title="Link to this heading">#</a></h2>
<p>Combiniamo la regola di apprendimento e la regola decisionale per simulare il comportamento del partecipante:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">simulate_RescorlaWagner</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">noisy_choice</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

    <span class="n">alpha</span><span class="p">,</span> <span class="n">theta</span> <span class="o">=</span> <span class="n">params</span>
    
    <span class="c1"># Un array di zeri di lunghezza T</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

    <span class="c1"># Un array multidimensionale di zeri di dimensione 2xT</span>
    <span class="n">Q_stored</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="n">T</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    
    <span class="c1"># Inizializza Q per t == 0</span>
    <span class="n">Q</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>

        <span class="c1"># Salva i valori Q per Q_{t+1}</span>
        <span class="n">Q_stored</span><span class="p">[:,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">Q</span>

        <span class="c1"># Calcola le probabilità di scelta</span>
        <span class="n">p0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span><span class="o">*</span><span class="n">Q</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span><span class="o">*</span><span class="n">Q</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span><span class="o">*</span><span class="n">Q</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">p1</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">p0</span>
        
        <span class="c1"># Se noisy_choice è vero, viene simulato un comportamento di scelta rumoroso in </span>
        <span class="c1"># cui l&#39;opzione 0 è scelta con probabilità p0, mentre l&#39;opzione 1 è scelta con </span>
        <span class="c1"># probabilità 1-p0.</span>
        <span class="k">if</span> <span class="n">noisy_choice</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random_sample</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">p0</span><span class="p">:</span>
                <span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># la scelta viene effettuata senza rumore</span>
            <span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">([</span><span class="n">p0</span><span class="p">,</span> <span class="n">p1</span><span class="p">])</span>

        <span class="c1"># Genera la ricompensa sulla base delle probabilità di ricompensa</span>
        <span class="n">r</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">mu</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span>

        <span class="c1"># Aggiorna le aspettative di valore</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">Q</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span>
        <span class="n">Q</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">delta</span>

    <span class="k">return</span> <span class="n">c</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">Q_stored</span>
</pre></div>
</div>
</div>
</div>
<p>Simuliamo <code class="docutils literal notranslate"><span class="pre">T</span></code> = 100 prove utilizzando il modello generativo dei dati definito in precedenza.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">T</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">mu</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">c</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">Q</span> <span class="o">=</span> <span class="n">simulate_RescorlaWagner</span><span class="p">([</span><span class="mf">.1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">],</span> <span class="n">T</span><span class="o">=</span><span class="n">T</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Rappresentiamo graficamente i risultati ottenuti dalla simulazione.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">r</span><span class="p">,</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">c</span><span class="p">,</span> <span class="s1">&#39;+&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;scelta&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Prove&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Feedback (1=Ricompensa,</span><span class="se">\n</span><span class="s1"> 0=Nessuna ricompensa)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Apprendimento di Rescorla-Wagner&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/914521cc5b36d63f3883c9e76c9f6a05da08d3b7c682aa91ee6d248d70f1d251.png"><img alt="../_images/914521cc5b36d63f3883c9e76c9f6a05da08d3b7c682aa91ee6d248d70f1d251.png" src="../_images/914521cc5b36d63f3883c9e76c9f6a05da08d3b7c682aa91ee6d248d70f1d251.png" style="width: 731px; height: 491px;" /></a>
</div>
</div>
<p>Come possiamo osservare, le scelte per la slot machine che produce meno ricompense diventano meno frequenti nel corso delle prove.</p>
<p>Possiamo anche rappresentare graficamente le aspettative di valore <span class="math notranslate nohighlight">\(Q\)</span> delle due slot machine nel corso delle prove.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">Q</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;80% machine&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">Q</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="s1">&#39;m-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;20% machine&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">c</span><span class="p">,</span> <span class="s1">&#39;b+&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;choice&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;trials&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;value&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Rescorla-Wagner Learning&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/263f81310c3ea54f3ba8253a5e61b93b9a870447d237283816aebfc393e42933.png"><img alt="../_images/263f81310c3ea54f3ba8253a5e61b93b9a870447d237283816aebfc393e42933.png" src="../_images/263f81310c3ea54f3ba8253a5e61b93b9a870447d237283816aebfc393e42933.png" style="width: 731px; height: 491px;" /></a>
</div>
</div>
<p>Si noti come nel corso delle prove i valori delle slot macchine convergano lentamente verso le probabilità di ricompensa (20% e 80%).</p>
<p>In sintesi, il modello di Rescorla-Wagner ci permette di simulare come le persone apprendono e prendono decisioni basate su ricompense. Utilizzando la regola di apprendimento (<span class="math notranslate nohighlight">\(\delta\)</span>-rule) e la regola decisionale softmax, possiamo vedere come le aspettative di valore e le scelte cambiano nel tempo in risposta alle ricompense ottenute.</p>
</section>
<section id="adattamento-del-modello">
<h2>Adattamento del Modello<a class="headerlink" href="#adattamento-del-modello" title="Link to this heading">#</a></h2>
<p>Dopo aver visto come funziona il modello di Rescorla-Wagner, il passo successivo è stimare i parametri del modello a partire dai dati osservati. Questo processo è fondamentale nella modellazione computazionale perché ci permette di capire quali valori dei parametri descrivono meglio il comportamento osservato. Esistono diversi metodi per stimare i parametri, ma ci concentreremo sull’approccio della <em>Massima Verosimiglianza</em>.</p>
<section id="la-massima-verosimiglianza">
<h3>La Massima Verosimiglianza<a class="headerlink" href="#la-massima-verosimiglianza" title="Link to this heading">#</a></h3>
<p>L’approccio della massima verosimiglianza cerca di trovare i valori dei parametri del modello che massimizzano la probabilità dei dati osservati. In altre parole, vogliamo trovare i parametri <span class="math notranslate nohighlight">\((\alpha, \theta)\)</span> che rendono i dati osservati <span class="math notranslate nohighlight">\(d_{1:T}\)</span> più probabili secondo il modello Rescorla-Wagner.</p>
</section>
<section id="calcolo-del-logaritmo-della-verosimiglianza">
<h3>Calcolo del Logaritmo della Verosimiglianza<a class="headerlink" href="#calcolo-del-logaritmo-della-verosimiglianza" title="Link to this heading">#</a></h3>
<p>Massimizzare la verosimiglianza è spesso più facile se si lavora con il logaritmo della verosimiglianza, perché le moltiplicazioni di probabilità diventano somme. La log-verosimiglianza può essere espressa come:</p>
<div class="math notranslate nohighlight">
\[ 
\log \mathcal{L} = \log p(d_{1:T} | (\alpha, \theta)_m, m) = \sum_{t=1}^T \log p(c_t | d_{1:t-1}, s_t, (\alpha, \theta)_m, m)
\]</div>
<p>In questa equazione:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( \log \mathcal{L} \)</span> è il logaritmo della verosimiglianza.</p></li>
<li><p><span class="math notranslate nohighlight">\( p(d_{1:T} | (\alpha, \theta)_m, m) \)</span> è la probabilità dei dati osservati dato il modello e i parametri.</p></li>
<li><p><span class="math notranslate nohighlight">\( p(c_t | d_{1:t-1}, s_t, (\alpha, \theta)_m, m) \)</span> è la probabilità di ogni singola scelta <span class="math notranslate nohighlight">\( c_t \)</span> data la storia delle scelte e dei feedback fino al tempo <span class="math notranslate nohighlight">\( t \)</span> e i parametri del modello.</p></li>
</ul>
</section>
<section id="minimizzazione-del-logaritmo-negativo-della-verosimiglianza">
<h3>Minimizzazione del Logaritmo Negativo della Verosimiglianza<a class="headerlink" href="#minimizzazione-del-logaritmo-negativo-della-verosimiglianza" title="Link to this heading">#</a></h3>
<p>In pratica, massimizzare la log-verosimiglianza è equivalente a minimizzare il logaritmo negativo della verosimiglianza. Questo ci porta alla seguente equazione:</p>
<div class="math notranslate nohighlight">
\[ 
-\log \mathcal{L} = -\sum_{t=1}^T \log p(c_t | d_{1:t-1}, s_t, (\alpha, \theta)_m, m)
\]</div>
<p>Per applicare questa procedura al modello di Rescorla-Wagner, dobbiamo definire la funzione di log-verosimiglianza negativa specifica per il nostro modello. Questa funzione ci permette di calcolare quanto bene i parametri <span class="math notranslate nohighlight">\(\alpha\)</span> e <span class="math notranslate nohighlight">\(\theta\)</span> spiegano i dati osservati. Durante il processo di stima, l’obiettivo è minimizzare questa funzione per trovare i valori ottimali dei parametri.</p>
</section>
<section id="id1">
<h3>Esempio Pratico<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p>Immaginiamo di avere dati osservati da un esperimento in cui un partecipante ha fatto 100 scelte tra due slot machine. Il nostro obiettivo è stimare i parametri <span class="math notranslate nohighlight">\(\alpha\)</span> (tasso di apprendimento) e <span class="math notranslate nohighlight">\(\theta\)</span> (temperatura) che meglio spiegano queste scelte. Per fare ciò, utilizziamo il metodo della massima verosimiglianza.</p>
<p>La seguente funzione <code class="docutils literal notranslate"><span class="pre">negll_RescorlaWagner</span></code> calcola il negativo della log-verosimiglianza per il modello di apprendimento di Rescorla-Wagner. Questo ci permette di capire quanto bene i parametri del modello (<span class="math notranslate nohighlight">\(\alpha\)</span> e <span class="math notranslate nohighlight">\(\theta\)</span>) spiegano le scelte osservate. Ecco una spiegazione passo passo per capire come funziona questa funzione.</p>
<p>I parametri della Funzione sono:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">params</span></code>: una lista che contiene i valori dei parametri <span class="math notranslate nohighlight">\(\alpha\)</span> (tasso di apprendimento) e <span class="math notranslate nohighlight">\(\theta\)</span> (temperatura).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">c</span></code>: un array che contiene le scelte effettuate dal partecipante (0 o 1).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">r</span></code>: un array che contiene le ricompense ricevute dopo ogni scelta (1 per ricompensa, 0 per nessuna ricompensa).</p></li>
</ul>
<p>Esaminiamo ora il corpo della funzione.</p>
<ol class="arabic">
<li><p><strong>Inizializzazione dei Parametri</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">alpha</span><span class="p">,</span> <span class="n">theta</span> <span class="o">=</span> <span class="n">params</span>
<span class="n">Q</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>
<span class="n">T</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
<span class="n">choiceProb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">alpha</span></code> e <code class="docutils literal notranslate"><span class="pre">theta</span></code> sono estratti dalla lista <code class="docutils literal notranslate"><span class="pre">params</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Q</span></code> è una lista che tiene traccia delle aspettative di valore per le due slot machine, inizializzate a 0.5.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">T</span></code> è il numero di scelte effettuate.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">choiceProb</span></code> è un array che memorizza la probabilità di ogni scelta effettuata.</p></li>
</ul>
</li>
<li><p><strong>Calcolo delle Probabilità di Scelta e Aggiornamento dei Valori</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
    <span class="n">p0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span> <span class="o">*</span> <span class="n">Q</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span> <span class="o">*</span> <span class="n">Q</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span> <span class="o">*</span> <span class="n">Q</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">p</span> <span class="o">=</span> <span class="p">[</span><span class="n">p0</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">p0</span><span class="p">]</span>
    <span class="n">choiceProb</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">Q</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span>
    <span class="n">Q</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">delta</span>
</pre></div>
</div>
<ul class="simple">
<li><p><strong>Calcolo delle Probabilità di Scelta</strong>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">p0</span></code> è la probabilità di scegliere la prima slot machine.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">p</span></code> è una lista delle probabilità di scegliere ciascuna delle due slot machine.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">choiceProb[t]</span></code> memorizza la probabilità della scelta effettivamente fatta al tempo <span class="math notranslate nohighlight">\( t \)</span>.</p></li>
</ul>
</li>
<li><p><strong>Aggiornamento delle Aspettative di Valore</strong>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">delta</span></code> è la differenza tra la ricompensa effettiva <code class="docutils literal notranslate"><span class="pre">r[t]</span></code> e l’aspettativa di valore <code class="docutils literal notranslate"><span class="pre">Q[c[t]]</span></code> per la scelta fatta.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Q[c[t]]</span></code> viene aggiornata secondo la regola di Rescorla-Wagner: il nuovo valore atteso è il vecchio valore atteso più una frazione (determinata da <span class="math notranslate nohighlight">\(\alpha\)</span>) dell’errore di previsione.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Calcolo del Negativo della Log-Verosimiglianza</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">negLL</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">choiceProb</span><span class="p">))</span>
<span class="k">return</span> <span class="n">negLL</span>
</pre></div>
</div>
<ul class="simple">
<li><p><strong>Log-Verosimiglianza</strong>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">np.log(choiceProb)</span></code> calcola il logaritmo delle probabilità di scelta.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">np.sum(np.log(choiceProb))</span></code> somma questi logaritmi.</p></li>
</ul>
</li>
<li><p><strong>Negativo della Log-Verosimiglianza</strong>:</p>
<ul>
<li><p>Il risultato è moltiplicato per -1 per ottenere il negativo della log-verosimiglianza, poiché nella stima dei parametri cerchiamo di minimizzare questa funzione.</p></li>
</ul>
</li>
</ul>
</li>
</ol>
<p>In sintesi, la funzione <code class="docutils literal notranslate"><span class="pre">negll_RescorlaWagner</span></code>:</p>
<ol class="arabic simple">
<li><p>Calcola le probabilità di scelta basate sui parametri <span class="math notranslate nohighlight">\(\alpha\)</span> e <span class="math notranslate nohighlight">\(\theta\)</span>.</p></li>
<li><p>Aggiorna le aspettative di valore in base alle scelte e alle ricompense osservate.</p></li>
<li><p>Calcola il negativo della log-verosimiglianza per valutare quanto bene i parametri spiegano i dati osservati.</p></li>
</ol>
<p>Ecco la funzione completa con commenti per facilitarne la comprensione:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">negll_RescorlaWagner</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
    <span class="n">alpha</span><span class="p">,</span> <span class="n">theta</span> <span class="o">=</span> <span class="n">params</span>
    <span class="n">Q</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>
    <span class="n">T</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
    <span class="n">choiceProb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
        <span class="c1"># Calcola le probabilità di scelta per k = 2</span>
        <span class="n">p0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span> <span class="o">*</span> <span class="n">Q</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span> <span class="o">*</span> <span class="n">Q</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span> <span class="o">*</span> <span class="n">Q</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="c1"># &quot;p&quot; è una lista di probabilità di scelta per le due opzioni disponibili</span>
        <span class="n">p</span> <span class="o">=</span> <span class="p">[</span><span class="n">p0</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">p0</span><span class="p">]</span>

        <span class="c1"># Memorizza la probabilità della scelta effettuata</span>
        <span class="n">choiceProb</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span>

        <span class="c1"># Aggiorna le aspettative di valore secondo la regola di Rescorla-Wagner</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">Q</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span>
        <span class="n">Q</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">delta</span>

    <span class="c1"># Calcola il negativo della log-verosimiglianza</span>
    <span class="n">negLL</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">choiceProb</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">negLL</span>
</pre></div>
</div>
</div>
</div>
<p>Simuliamo ora un set di dati.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># simulate choices from RW Model</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">.2</span>
<span class="n">theta</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="n">c</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">Q2</span> <span class="o">=</span> <span class="n">simulate_RescorlaWagner</span><span class="p">([</span><span class="n">alpha</span><span class="p">,</span> <span class="n">theta</span><span class="p">],</span> <span class="n">T</span><span class="o">=</span><span class="n">T</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="p">[</span><span class="mf">.2</span><span class="p">,</span> <span class="mf">.8</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Per fare un esempio, valutiamo la log-verosimiglianza negativa per i dati simulati in corrispondenza dei valori <code class="docutils literal notranslate"><span class="pre">alpha</span></code> e <code class="docutils literal notranslate"><span class="pre">theta</span></code> indicati di seguito.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alpha_hat</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">theta_hat</span> <span class="o">=</span> <span class="mf">2.5</span>
<span class="n">negLL</span> <span class="o">=</span> <span class="n">negll_RescorlaWagner</span><span class="p">([</span><span class="n">alpha_hat</span><span class="p">,</span> <span class="n">theta_hat</span><span class="p">],</span> <span class="n">c</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">alpha_hat</span><span class="p">,</span> <span class="n">theta_hat</span><span class="p">,</span> <span class="n">negLL</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.3 2.5 68.2432720060257
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alpha_hat</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">theta_hat</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="n">negLL</span> <span class="o">=</span> <span class="n">negll_RescorlaWagner</span><span class="p">([</span><span class="n">alpha_hat</span><span class="p">,</span> <span class="n">theta_hat</span><span class="p">],</span> <span class="n">c</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">alpha_hat</span><span class="p">,</span> <span class="n">theta_hat</span><span class="p">,</span> <span class="n">negLL</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.2 1.5 62.04159854003673
</pre></div>
</div>
</div>
</div>
<p>Un metodo per trovare i parametri di massima verosimiglianza è effettuare una ricerca esaustiva su tutto lo spazio dei parametri. Questo significa selezionare i valori di <code class="docutils literal notranslate"><span class="pre">alpha</span></code> e <code class="docutils literal notranslate"><span class="pre">theta</span></code> per i quali la funzione <code class="docutils literal notranslate"><span class="pre">negLL</span></code> assume il valore più basso.</p>
<p>Per illustrare questo metodo, applichiamolo a un set di dati simulato. Per semplicità, assumiamo di conoscere il valore di <span class="math notranslate nohighlight">\(\theta\)</span> e di dover trovare solo il valore di <span class="math notranslate nohighlight">\(\alpha\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nLL</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">alpha_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="k">for</span> <span class="n">alpha_val</span> <span class="ow">in</span> <span class="n">alpha_vals</span><span class="p">:</span>
    <span class="n">nLL</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">negll_RescorlaWagner</span><span class="p">([</span><span class="n">alpha_val</span><span class="p">,</span> <span class="n">theta</span><span class="p">],</span> <span class="n">c</span><span class="p">,</span> <span class="n">r</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">alpha_vals</span><span class="p">,</span> <span class="n">nLL</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">alpha_vals</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">nLL</span><span class="p">)],</span> <span class="n">nLL</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">nLL</span><span class="p">)],</span>
    <span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;optimal $\hat \alpha$&#39;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;negative log likelihood&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">fr</span><span class="s1">&#39;learning rate, $\hat \alpha$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Rescorla-Wagner Learning&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/81a6c6c963f848935700966a6f7e7b56b50a889fafee66c2bffb8c8ec4aceffc.png"><img alt="../_images/81a6c6c963f848935700966a6f7e7b56b50a889fafee66c2bffb8c8ec4aceffc.png" src="../_images/81a6c6c963f848935700966a6f7e7b56b50a889fafee66c2bffb8c8ec4aceffc.png" style="width: 731px; height: 491px;" /></a>
</div>
</div>
</section>
<section id="validazione">
<h3>Validazione<a class="headerlink" href="#validazione" title="Link to this heading">#</a></h3>
<p>Una volta stabilito un metodo per stimare i parametri del modello dai dati, dobbiamo valutare quanto accuratamente queste stime riflettano i veri valori dei parametri del modello. Per rispondere a questa domanda, possiamo condurre uno studio di simulazione.</p>
<p>I parametri della simulazione sono i seguenti.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">T</span> <span class="o">=</span> <span class="mi">250</span>
<span class="n">mu</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]</span>
<span class="n">num_subjects</span> <span class="o">=</span> <span class="mi">20</span>
</pre></div>
</div>
</div>
</div>
<p>Calcolimo i valori di massima verosimiglianza dei parametri <code class="docutils literal notranslate"><span class="pre">alpha</span></code> e <code class="docutils literal notranslate"><span class="pre">theta</span></code> usando la funzione <code class="docutils literal notranslate"><span class="pre">minimize</span></code> per minimizzare la funzione di log-verosimiglianza. Simuliamo i dati di un soggetto.</p>
<p>Specifichiamo poi le stime iniziali per i valori dei parametri e i valori margine delle possibili soluzioni. I risultati saranno salvati nell’oggetto <code class="docutils literal notranslate"><span class="pre">result</span></code>. Le stime dei due parametri si estraggono con <code class="docutils literal notranslate"><span class="pre">result.x</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">c</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">Q</span> <span class="o">=</span> <span class="n">simulate_RescorlaWagner</span><span class="p">([</span><span class="mf">0.15</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span> <span class="n">T</span><span class="o">=</span><span class="n">T</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>

<span class="n">init_guess</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

<span class="c1"># minimize neg LL</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span>
    <span class="n">negll_RescorlaWagner</span><span class="p">,</span>
    <span class="n">init_guess</span><span class="p">,</span>
    <span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">r</span><span class="p">),</span>
    <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)),</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1.76044404e-03 9.63868119e+00]
</pre></div>
</div>
</div>
</div>
<p>Simuliamo i dati per 500 soggetti, con 250 osservazioni ciascuno, utilizzando valori casuali di <code class="docutils literal notranslate"><span class="pre">alpha</span></code> e <code class="docutils literal notranslate"><span class="pre">theta</span></code>. Successivamente, eseguiamo la stima di massima verosimiglianza per i dati di ogni soggetto, inizializzando casualmente i parametri per ciascuno di essi. Infine, salviamo i risultati ottenuti nel DataFrame <code class="docutils literal notranslate"><span class="pre">df</span></code>. Ecco il codice corrispondente:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">NREP</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">index</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">NREP</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;true_alpha&quot;</span><span class="p">,</span> <span class="s2">&quot;alpha&quot;</span><span class="p">,</span> <span class="s2">&quot;true_theta&quot;</span><span class="p">,</span> <span class="s2">&quot;theta&quot;</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># loop through subjects</span>
<span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NREP</span><span class="p">):</span>

    <span class="n">true_alpha</span> <span class="o">=</span> <span class="mf">0.95</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
    <span class="n">true_theta</span> <span class="o">=</span> <span class="mf">4.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>

    <span class="n">c</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">Q</span> <span class="o">=</span> <span class="n">simulate_RescorlaWagner</span><span class="p">([</span><span class="n">true_alpha</span><span class="p">,</span> <span class="n">true_theta</span><span class="p">],</span> <span class="n">T</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>

    <span class="n">init_guess</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(),</span> <span class="mf">1.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">())</span>
    <span class="c1"># minimize neg LL</span>
    <span class="n">param_fits</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span>
        <span class="n">negll_RescorlaWagner</span><span class="p">,</span>
        <span class="n">init_guess</span><span class="p">,</span>
        <span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">r</span><span class="p">),</span>
        <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)),</span>
    <span class="p">)</span>

    <span class="c1"># store in dataframe</span>
    <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="s2">&quot;true_alpha&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">true_alpha</span>
    <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="s2">&quot;true_theta&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">true_theta</span>
    <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="s2">&quot;alpha&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">param_fits</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="s2">&quot;theta&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">param_fits</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>La figura successiva mostra una corrispondenza tra i valori stimati di alpha e i valori veri. È importante notare che la corrispondenza non è perfetta a causa della presenza di una componente di casualità nei dati. Inoltre, in alcuni casi si possono osservare valori stimati di alpha pari a 0 o 1, che corrispondono a risultati spurii dell’algoritmo. Il numero di risultati spurii aumenta con il diminuire del numero di osservazioni per ciascun soggetto.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">true_alpha</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="s1">&#39;ob&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;True alpha&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Estimated alpha&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;ML estimation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/54d28a3a2377f9384a6c8c0686d40245ea0e3deb725a8273f146f4b89be4c505.png"><img alt="../_images/54d28a3a2377f9384a6c8c0686d40245ea0e3deb725a8273f146f4b89be4c505.png" src="../_images/54d28a3a2377f9384a6c8c0686d40245ea0e3deb725a8273f146f4b89be4c505.png" style="width: 731px; height: 491px;" /></a>
</div>
</div>
<p>Un discorso analogo si può fare per theta, anche se in questo caso vi è una migliore corrispondenza tra i valori stimati e i valori veri.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="s1">&#39;or&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;True theta&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Estimated theta&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;ML estimation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/9ebcafe42609482688b9b8ea70015fce882badee7b786a594ef184d73ee24fd7.png"><img alt="../_images/9ebcafe42609482688b9b8ea70015fce882badee7b786a594ef184d73ee24fd7.png" src="../_images/9ebcafe42609482688b9b8ea70015fce882badee7b786a594ef184d73ee24fd7.png" style="width: 731px; height: 491px;" /></a>
</div>
</div>
<p>In sintesi, possiamo affermare che il metodo della massima verosimiglianza è in grado di recuperare i valori simulati dei parametri <span class="math notranslate nohighlight">\(\alpha\)</span> e <span class="math notranslate nohighlight">\(\theta\)</span> del modello di Rescorla-Wagner, ma solo quando il numero di osservazioni per soggetto è considerevole. Tuttavia, è importante notare che questo metodo può produrre risultati imprecisi in determinate circostanze.</p>
<p>Esistono altri metodi di stima che offrono risultati migliori anche con un numero inferiore di osservazioni per soggetto. Tra questi, il metodo gerarchico bayesiano è ampiamente utilizzato nella pratica. Va precisato che l’obiettivo di questo tutorial era principalmente illustrare in modo semplice come sia possibile ottenere con buona accuratezza i parametri del modello di Rescorla-Wagner dai dati generati da una simulazione, considerando condizioni ottimali in cui i valori dei parametri del modello sono noti.</p>
<p>È importante sottolineare che, nella pratica, la stima dei parametri può essere un processo complesso e che l’accuratezza delle stime dipende da molteplici fattori, come la dimensione del campione e la natura dei dati osservati. Pertanto, è sempre consigliabile valutare attentamente i risultati e considerare l’utilizzo di approcci più sofisticati, come il metodo gerarchico bayesiano, per ottenere stime più affidabili dei parametri del modello.</p>
</section>
</section>
<section id="stima-con-stan">
<h2>Stima con Stan<a class="headerlink" href="#stima-con-stan" title="Link to this heading">#</a></h2>
<p>Consideriamo ora la stima dei parametri del modello Rescorla-Wagner usando un metodo bayesiano, ovvero mediante Stan. Iniziamo ad importare il codice Stan.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stan_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;../stan&#39;</span><span class="p">,</span> <span class="s1">&#39;rescorla_wagner.stan&#39;</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">stan_file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>data {
  int&lt;lower=1&gt; nTrials; // numero di tentativi
  array[nTrials] int&lt;lower=1, upper=2&gt; choice; // scelte effettuate (1 o 2)
  array[nTrials] real&lt;lower=0, upper=1&gt; reward; // ricompense ricevute (0 o 1)
}
transformed data {
  vector[2] initV; // valori iniziali per V
  initV = rep_vector(0.5, 2); // inizializzati a 0.5
}
parameters {
  real&lt;lower=0, upper=1&gt; alpha; // tasso di apprendimento
  real&lt;lower=0&gt; theta; // temperatura
}
model {
  vector[2] v; // valori attesi
  real delta; // errore di previsione
  
  // Priori
  alpha ~ beta(1, 1); // prior uniforme su [0, 1]
  theta ~ normal(0, 10); // prior normale con media 0 e deviazione standard 10
  
  v = initV;
  
  for (t in 1 : nTrials) {
    // Calcolo delle probabilità di scelta usando la funzione softmax con limitazione
    vector[2] logits;
    logits = theta * v;
    logits = fmin(logits, 20); // Limita i valori massimi per evitare overflow
    logits = fmax(logits, -20); // Limita i valori minimi per evitare underflow
    
    choice[t] ~ categorical_logit(logits);
    
    // Errore di previsione
    delta = reward[t] - v[choice[t]];
    
    // Aggiornamento dei valori attesi (apprendimento)
    v[choice[t]] = v[choice[t]] + alpha * delta;
  }
}
</pre></div>
</div>
</div>
</div>
<section id="sezione-data">
<h3>Sezione <code class="docutils literal notranslate"><span class="pre">data</span></code><a class="headerlink" href="#sezione-data" title="Link to this heading">#</a></h3>
<p>Questa sezione definisce i dati che vengono forniti al modello:</p>
<div class="highlight-stan notranslate"><div class="highlight"><pre><span></span><span class="kn">data</span> <span class="p">{</span>
  <span class="kt">int</span><span class="o">&lt;</span><span class="k">lower</span><span class="p">=</span><span class="mf">1</span><span class="o">&gt;</span> <span class="n">nTrials</span><span class="p">;</span> <span class="c1">// numero di tentativi</span>
  <span class="kt">array</span><span class="p">[</span><span class="n">nTrials</span><span class="p">]</span> <span class="kt">int</span><span class="o">&lt;</span><span class="k">lower</span><span class="p">=</span><span class="mf">1</span><span class="p">,</span><span class="w"> </span><span class="k">upper</span><span class="p">=</span><span class="mf">2</span><span class="o">&gt;</span> <span class="n">choice</span><span class="p">;</span> <span class="c1">// scelte effettuate (1 o 2)</span>
  <span class="kt">array</span><span class="p">[</span><span class="n">nTrials</span><span class="p">]</span> <span class="kt">real</span><span class="o">&lt;</span><span class="k">lower</span><span class="p">=</span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="k">upper</span><span class="p">=</span><span class="mf">1</span><span class="o">&gt;</span> <span class="n">reward</span><span class="p">;</span> <span class="c1">// ricompense ricevute (0 o 1)</span>
<span class="p">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">nTrials</span></code>: Il numero totale di tentativi o scelte effettuate dal partecipante.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">choice</span></code>: Un array che contiene le scelte effettuate dal partecipante in ciascun tentativo (1 o 2).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">reward</span></code>: Un array che contiene le ricompense ricevute per ciascun tentativo (0 o 1).</p></li>
</ul>
</section>
<section id="sezione-transformed-data">
<h3>Sezione <code class="docutils literal notranslate"><span class="pre">transformed</span> <span class="pre">data</span></code><a class="headerlink" href="#sezione-transformed-data" title="Link to this heading">#</a></h3>
<p>Questa sezione prepara alcuni dati iniziali trasformati per il modello:</p>
<div class="highlight-stan notranslate"><div class="highlight"><pre><span></span><span class="kn">transformed data</span> <span class="p">{</span>
  <span class="kt">vector</span><span class="p">[</span><span class="mf">2</span><span class="p">]</span> <span class="n">initV</span><span class="p">;</span> <span class="c1">// valori iniziali per V</span>
  <span class="n">initV</span> <span class="o">=</span> <span class="nb">rep_vector</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">2</span><span class="p">);</span> <span class="c1">// inizializzati a 0.5</span>
<span class="p">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">initV</span></code>: Un vettore di lunghezza 2 che rappresenta i valori iniziali delle aspettative di ricompensa per le due opzioni, entrambi inizializzati a 0.5.</p></li>
</ul>
</section>
<section id="sezione-parameters">
<h3>Sezione <code class="docutils literal notranslate"><span class="pre">parameters</span></code><a class="headerlink" href="#sezione-parameters" title="Link to this heading">#</a></h3>
<p>Questa sezione definisce i parametri del modello che Stan cercherà di stimare:</p>
<div class="highlight-stan notranslate"><div class="highlight"><pre><span></span><span class="kn">parameters</span> <span class="p">{</span>
  <span class="kt">real</span><span class="o">&lt;</span><span class="k">lower</span><span class="p">=</span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="k">upper</span><span class="p">=</span><span class="mf">1</span><span class="o">&gt;</span> <span class="n">alpha</span><span class="p">;</span> <span class="c1">// tasso di apprendimento</span>
  <span class="kt">real</span><span class="o">&lt;</span><span class="k">lower</span><span class="p">=</span><span class="mf">0</span><span class="o">&gt;</span> <span class="n">theta</span><span class="p">;</span> <span class="c1">// temperatura</span>
<span class="p">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">alpha</span></code>: Il tasso di apprendimento, che determina quanto rapidamente il partecipante aggiorna le proprie aspettative. Questo valore è compreso tra 0 e 1.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">theta</span></code>: La temperatura, che controlla il livello di esplorazione (quanto spesso il partecipante sceglie l’opzione con il valore atteso più alto rispetto a esplorare altre opzioni). Questo valore è positivo.</p></li>
</ul>
</section>
<section id="sezione-model">
<h3>Sezione <code class="docutils literal notranslate"><span class="pre">model</span></code><a class="headerlink" href="#sezione-model" title="Link to this heading">#</a></h3>
<p>Questa è la sezione principale che definisce come il modello effettua le stime e aggiorna i valori:</p>
<div class="highlight-stan notranslate"><div class="highlight"><pre><span></span><span class="kn">model</span> <span class="p">{</span>
  <span class="kt">vector</span><span class="p">[</span><span class="mf">2</span><span class="p">]</span> <span class="n">v</span><span class="p">;</span> <span class="c1">// valori attesi</span>
  <span class="kt">real</span> <span class="n">delta</span><span class="p">;</span> <span class="c1">// errore di previsione</span>
  
  <span class="c1">// Priori</span>
  <span class="n">alpha</span> <span class="o">~</span><span class="w"> </span><span class="nb">beta</span><span class="p">(</span><span class="mf">1</span><span class="p">,</span> <span class="mf">1</span><span class="p">);</span> <span class="c1">// prior uniforme su [0, 1]</span>
  <span class="n">theta</span> <span class="o">~</span><span class="w"> </span><span class="nb">normal</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span> <span class="mf">10</span><span class="p">);</span> <span class="c1">// prior normale con media 0 e deviazione standard 10</span>
  
  <span class="n">v</span> <span class="o">=</span> <span class="n">initV</span><span class="p">;</span>
  
  <span class="k">for</span> <span class="p">(</span><span class="n">t</span> <span class="k">in</span> <span class="mf">1</span> <span class="o">:</span> <span class="n">nTrials</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Calcolo delle probabilità di scelta usando la funzione softmax con limitazione</span>
    <span class="kt">vector</span><span class="p">[</span><span class="mf">2</span><span class="p">]</span> <span class="n">logits</span><span class="p">;</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">*</span> <span class="n">v</span><span class="p">;</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="nb">fmin</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="mf">20</span><span class="p">);</span> <span class="c1">// Limita i valori massimi per evitare overflow</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="nb">fmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="o">-</span><span class="mf">20</span><span class="p">);</span> <span class="c1">// Limita i valori minimi per evitare underflow</span>
    
    <span class="n">choice</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">~</span><span class="w"> </span><span class="nb">categorical_logit</span><span class="p">(</span><span class="n">logits</span><span class="p">);</span>
    
    <span class="c1">// Errore di previsione</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="n">reward</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">v</span><span class="p">[</span><span class="n">choice</span><span class="p">[</span><span class="n">t</span><span class="p">]];</span>
    
    <span class="c1">// Aggiornamento dei valori attesi (apprendimento)</span>
    <span class="n">v</span><span class="p">[</span><span class="n">choice</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">=</span> <span class="n">v</span><span class="p">[</span><span class="n">choice</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">delta</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">v</span></code>: Un vettore che contiene i valori attesi delle ricompense per le due opzioni.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">delta</span></code>: La differenza tra la ricompensa ricevuta e il valore atteso (errore di previsione).</p></li>
</ul>
<section id="priori">
<h4>Priori<a class="headerlink" href="#priori" title="Link to this heading">#</a></h4>
<p>Le distribuzioni prior definiscono le nostre convinzioni iniziali sui parametri prima di vedere i dati:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">~</span> <span class="pre">beta(1,</span> <span class="pre">1)</span></code>: Una distribuzione beta uniforme per <code class="docutils literal notranslate"><span class="pre">alpha</span></code>, che assegna uguale probabilità a tutti i valori tra 0 e 1.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">theta</span> <span class="pre">~</span> <span class="pre">normal(0,</span> <span class="pre">10)</span></code>: Una distribuzione normale per <code class="docutils literal notranslate"><span class="pre">theta</span></code> con media 0 e deviazione standard 10.</p></li>
</ul>
</section>
<section id="ciclo-sui-tentativi">
<h4>Ciclo sui Tentativi<a class="headerlink" href="#ciclo-sui-tentativi" title="Link to this heading">#</a></h4>
<p>Per ogni tentativo, il modello:</p>
<ol class="arabic">
<li><p><strong>Calcola le probabilità di scelta</strong> utilizzando la funzione softmax, limitando i valori per evitare overflow numerici:</p>
<div class="highlight-stan notranslate"><div class="highlight"><pre><span></span><span class="n">logits</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">*</span> <span class="n">v</span><span class="p">;</span>
<span class="n">logits</span> <span class="o">=</span> <span class="nb">fmin</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="mf">20</span><span class="p">);</span>
<span class="n">logits</span> <span class="o">=</span> <span class="nb">fmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="o">-</span><span class="mf">20</span><span class="p">);</span>
<span class="n">choice</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">~</span><span class="w"> </span><span class="nb">categorical_logit</span><span class="p">(</span><span class="n">logits</span><span class="p">);</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">logits</span> <span class="pre">=</span> <span class="pre">theta</span> <span class="pre">*</span> <span class="pre">v;</span></code>: <code class="docutils literal notranslate"><span class="pre">logits</span></code> è un vettore che contiene i valori trasformati <code class="docutils literal notranslate"><span class="pre">theta</span> <span class="pre">*</span> <span class="pre">v</span></code>.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">theta</span></code> è la temperatura, che controlla quanto il partecipante esplora rispetto a sfruttare (scegliere l’opzione con il valore atteso più alto).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">v</span></code> sono i valori attesi delle ricompense per le due opzioni.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">logits</span> <span class="pre">=</span> <span class="pre">fmin(logits,</span> <span class="pre">20);</span></code>: Questa funzione assicura che nessun valore in <code class="docutils literal notranslate"><span class="pre">logits</span></code> sia maggiore di 20. Se un valore è maggiore di 20, viene impostato a 20.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">logits</span> <span class="pre">=</span> <span class="pre">fmax(logits,</span> <span class="pre">-20);</span></code>: Questa funzione assicura che nessun valore in <code class="docutils literal notranslate"><span class="pre">logits</span></code> sia minore di -20. Se un valore è minore di -20, viene impostato a -20.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">choice[t]</span> <span class="pre">~</span> <span class="pre">categorical_logit(logits);</span></code>: <code class="docutils literal notranslate"><span class="pre">categorical_logit(logits)</span></code> è una distribuzione che assegna probabilità alle scelte (1 o 2) in base ai valori <code class="docutils literal notranslate"><span class="pre">logits</span></code>.</p></li>
</ul>
<p><strong>Motivazione</strong>: Limitare i valori dei <code class="docutils literal notranslate"><span class="pre">logits</span></code> è importante per evitare problemi numerici (overflow) quando si calcolano le probabilità. Valori estremi di <code class="docutils literal notranslate"><span class="pre">theta</span> <span class="pre">*</span> <span class="pre">v</span></code> possono causare risultati non definiti o infiniti, quindi li limitiamo a un intervallo ragionevole (-20 a 20).</p>
<p><strong>Funzionamento della Funzione <code class="docutils literal notranslate"><span class="pre">categorical_logit</span></code></strong>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">categorical_logit(logits)</span></code> utilizza la funzione softmax per convertire i <code class="docutils literal notranslate"><span class="pre">logits</span></code> in probabilità.</p></li>
<li><p>La funzione softmax è definita come:
$<span class="math notranslate nohighlight">\(
\text{softmax}(z_i) = \frac{\exp(z_i)}{\sum_{j=1}^{K} \exp(z_j)}
\)</span>$
dove <code class="docutils literal notranslate"><span class="pre">z_i</span></code> sono i <code class="docutils literal notranslate"><span class="pre">logits</span></code> per ciascuna opzione.</p></li>
<li><p>Questa funzione garantisce che le probabilità siano comprese tra 0 e 1 e che la loro somma sia 1.</p></li>
</ul>
<p><strong>Esempio Pratico</strong>:
Supponiamo che <code class="docutils literal notranslate"><span class="pre">theta</span> <span class="pre">=</span> <span class="pre">1</span></code> e i valori attesi siano <code class="docutils literal notranslate"><span class="pre">v</span> <span class="pre">=</span> <span class="pre">[0.3,</span> <span class="pre">0.7]</span></code>. I <code class="docutils literal notranslate"><span class="pre">logits</span></code> sarebbero calcolati come:</p>
<div class="highlight-stan notranslate"><div class="highlight"><pre><span></span><span class="n">logits</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">*</span> <span class="n">v</span><span class="p">;</span> <span class="c1">// logits = [1 * 0.3, 1 * 0.7] = [0.3, 0.7]</span>
<span class="n">logits</span> <span class="o">=</span> <span class="nb">fmin</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="mf">20</span><span class="p">);</span> <span class="c1">// nessun valore è maggiore di 20, quindi rimane [0.3, 0.7]</span>
<span class="n">logits</span> <span class="o">=</span> <span class="nb">fmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="o">-</span><span class="mf">20</span><span class="p">);</span> <span class="c1">// nessun valore è minore di -20, quindi rimane [0.3, 0.7]</span>
</pre></div>
</div>
<p>Applicando la funzione softmax:</p>
<div class="math notranslate nohighlight">
\[
   \text{softmax}(0.3, 0.7) = \left( \frac{\exp(0.3)}{\exp(0.3) + \exp(0.7)}, \frac{\exp(0.7)}{\exp(0.3) + \exp(0.7)} \right)
   \]</div>
<p>Calcolando le esponenziali e le probabilità:</p>
<div class="math notranslate nohighlight">
\[
   \exp(0.3) \approx 1.35, \quad \exp(0.7) \approx 2.01
   \]</div>
<div class="math notranslate nohighlight">
\[
   \text{softmax}(0.3, 0.7) \approx \left( \frac{1.35}{1.35 + 2.01}, \frac{2.01}{1.35 + 2.01} \right) = \left( 0.40, 0.60 \right)
   \]</div>
<p>Quindi, le probabilità di scegliere l’opzione 1 e l’opzione 2 sono circa 0.40 e 0.60, rispettivamente. Il modello usa queste probabilità per determinare quale scelta viene effettivamente fatta al tempo <code class="docutils literal notranslate"><span class="pre">t</span></code>.</p>
</li>
<li><p><strong>Calcola l’errore di previsione</strong> come la differenza tra la ricompensa ricevuta e il valore atteso:</p>
<div class="highlight-stan notranslate"><div class="highlight"><pre><span></span><span class="n">delta</span> <span class="o">=</span> <span class="n">reward</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">v</span><span class="p">[</span><span class="n">choice</span><span class="p">[</span><span class="n">t</span><span class="p">]];</span>
</pre></div>
</div>
</li>
<li><p><strong>Aggiorna i valori attesi</strong> utilizzando l’errore di previsione e il tasso di apprendimento <code class="docutils literal notranslate"><span class="pre">alpha</span></code>:</p>
<div class="highlight-stan notranslate"><div class="highlight"><pre><span></span><span class="n">v</span><span class="p">[</span><span class="n">choice</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">=</span> <span class="n">v</span><span class="p">[</span><span class="n">choice</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">delta</span><span class="p">;</span>
</pre></div>
</div>
</li>
</ol>
<p>In sintesi,</p>
<ul class="simple">
<li><p>I <code class="docutils literal notranslate"><span class="pre">logits</span></code> sono valori calcolati come <code class="docutils literal notranslate"><span class="pre">theta</span> <span class="pre">*</span> <span class="pre">v</span></code> e limitati tra -20 e 20 per evitare problemi numerici.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">categorical_logit(logits)</span></code> converte questi <code class="docutils literal notranslate"><span class="pre">logits</span></code> in probabilità utilizzando la funzione softmax.</p></li>
<li><p>La scelta al tempo <code class="docutils literal notranslate"><span class="pre">t</span></code> (<code class="docutils literal notranslate"><span class="pre">choice[t]</span></code>) è modellata come una variabile categoriale con queste probabilità, riflettendo la probabilità che il partecipante scelga ciascuna delle opzioni.</p></li>
<li><p>L’errore di previsione (<code class="docutils literal notranslate"><span class="pre">delta</span></code>) è calcolato come la differenza tra la ricompensa ricevuta e il valore atteso.</p></li>
<li><p>I valori attesi (<code class="docutils literal notranslate"><span class="pre">v</span></code>) vengono aggiornati utilizzando l’errore di previsione e il tasso di apprendimento (<code class="docutils literal notranslate"><span class="pre">alpha</span></code>).</p></li>
</ul>
<p>Questo modello Stan implementa il processo di apprendimento del modello di Rescorla-Wagner. Utilizza le scelte e le ricompense osservate per stimare i parametri <code class="docutils literal notranslate"><span class="pre">alpha</span></code> e <code class="docutils literal notranslate"><span class="pre">theta</span></code>, aggiornando le aspettative di ricompensa in base ai risultati di ogni tentativo.</p>
</section>
</section>
<section id="inferenza">
<h3>Inferenza<a class="headerlink" href="#inferenza" title="Link to this heading">#</a></h3>
<p>Compiliamo il modello Stan:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">CmdStanModel</span><span class="p">(</span><span class="n">stan_file</span><span class="o">=</span><span class="n">stan_file</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Definiamo i parametri della simulazione:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">]</span>  <span class="c1"># alpha, theta</span>
<span class="n">T</span> <span class="o">=</span> <span class="mi">300</span>  <span class="c1"># numero di tentativi</span>
<span class="n">mu</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]</span>  <span class="c1"># probabilità di ricompensa per le due opzioni</span>
</pre></div>
</div>
</div>
</div>
<p>Simuliamo i dati:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">choices</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">Q_stored</span> <span class="o">=</span> <span class="n">simulate_RescorlaWagner</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Prepariamo i dati per Stan. Si noti che abbiamo sommato 1 a <code class="docutils literal notranslate"><span class="pre">choices</span></code> per adattarsi agli indici di Stan che partono da 1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">c</span> <span class="o">=</span> <span class="n">choices</span> <span class="o">+</span> <span class="mi">1</span>

<span class="n">stan_data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;nTrials&#39;</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span>
    <span class="s1">&#39;choice&#39;</span><span class="p">:</span> <span class="n">c</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
    <span class="s1">&#39;reward&#39;</span><span class="p">:</span> <span class="n">rewards</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="p">}</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stan_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;nTrials&#39;: 300, &#39;choice&#39;: [2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1], &#39;reward&#39;: [1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]}
</pre></div>
</div>
</div>
</div>
<p>Eseguiamo il campionamento:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trace</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">stan_data</span><span class="p">,</span>
    <span class="n">iter_warmup</span><span class="o">=</span><span class="mi">1_000</span><span class="p">,</span>
    <span class="n">iter_sampling</span><span class="o">=</span><span class="mi">2_000</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
    <span class="n">show_progress</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">show_console</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Esaminiamo le distribuzioni a posteriori dei due parametri oggetto dell’inferenza insieme alle loro tracce (cioè i vettori dei campioni dei parametri <span class="math notranslate nohighlight">\(\alpha\)</span> e <span class="math notranslate nohighlight">\(\theta\)</span> prodotti dalla procedura di campionamento MCMC) mediante un <em>trace plot</em> .</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/f4f2e5a8bb4d0ce6efc6839d68b655a1619f78d89e27e4b98fd8dc64375585b9.png"><img alt="../_images/f4f2e5a8bb4d0ce6efc6839d68b655a1619f78d89e27e4b98fd8dc64375585b9.png" src="../_images/f4f2e5a8bb4d0ce6efc6839d68b655a1619f78d89e27e4b98fd8dc64375585b9.png" style="width: 1211px; height: 411px;" /></a>
</div>
</div>
</section>
<section id="interpretazione-delle-stime-dei-parametri">
<h3>Interpretazione delle Stime dei Parametri<a class="headerlink" href="#interpretazione-delle-stime-dei-parametri" title="Link to this heading">#</a></h3>
<p>Utilizzando <code class="docutils literal notranslate"><span class="pre">az.summary(trace,</span> <span class="pre">hdi_prob=0.94,</span> <span class="pre">round_to=2)</span></code>, otteniamo un riassunto delle stime dei parametri del modello, che include la media, la deviazione standard, gli intervalli di credibilità (HDI) e altre statistiche diagnostiche:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="n">hdi_prob</span><span class="o">=</span><span class="mf">0.94</span><span class="p">,</span> <span class="n">round_to</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
      <th>mcse_mean</th>
      <th>mcse_sd</th>
      <th>ess_bulk</th>
      <th>ess_tail</th>
      <th>r_hat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>alpha</th>
      <td>0.13</td>
      <td>0.06</td>
      <td>0.04</td>
      <td>0.23</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3866.76</td>
      <td>3931.39</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>theta</th>
      <td>2.40</td>
      <td>0.29</td>
      <td>1.88</td>
      <td>2.95</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3640.88</td>
      <td>4084.60</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Con 300 prove, le stime dei parametri fornite dal modello sono adeguate:</p>
<ul class="simple">
<li><p><strong>Intervallo di credibilità</strong>: L’intervallo di credibilità al 94% (hdi_3% - hdi_97%) include il valore simulato del parametro. Questo significa che le stime del modello sono coerenti con i parametri originali usati nella simulazione.</p></li>
<li><p><strong>Deviazione standard</strong>: La deviazione standard della stima a posteriori è relativamente piccola, indicando che le stime sono precise.</p></li>
<li><p><strong>r_hat</strong>: I valori di <code class="docutils literal notranslate"><span class="pre">r_hat</span></code> sono vicini a 1, indicando che le catene di campionamento sono ben mescolate e hanno ottenuto la convergenza.</p></li>
</ul>
<p>Questi risultati suggeriscono che il modello di apprendimento di Rescorla-Wagner ha stimato correttamente i parametri <span class="math notranslate nohighlight">\(\alpha\)</span> e <span class="math notranslate nohighlight">\(\theta\)</span> dai dati simulati.</p>
</section>
</section>
<section id="informazioni-sull-ambiente-di-sviluppo">
<h2>Informazioni sull’Ambiente di Sviluppo<a class="headerlink" href="#informazioni-sull-ambiente-di-sviluppo" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> watermark
<span class="o">%</span><span class="k">watermark</span> -n -u -v -iv -w -m
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Last updated: Tue Jun 25 2024

Python implementation: CPython
Python version       : 3.12.3
IPython version      : 8.25.0

Compiler    : Clang 16.0.6 
OS          : Darwin
Release     : 23.5.0
Machine     : arm64
Processor   : arm
CPU cores   : 8
Architecture: 64bit

logging   : 0.5.1.2
seaborn   : 0.13.2
pandas    : 2.2.2
matplotlib: 3.8.4
numpy     : 1.26.4
cmdstanpy : 1.2.3
scipy     : 1.13.1
arviz     : 0.18.0

Watermark: 2.4.3
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter_5"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="05_35_missing.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">precedente</p>
        <p class="prev-next-title">Dati mancanti</p>
      </div>
    </a>
    <a class="right-next"
       href="../chapter_6/introduction_part_6.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">successivo</p>
        <p class="prev-next-title">Inferenza frequentista</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contenuti
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#two-armed-bandits">Two-armed bandits</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulare-l-apprendimento">Simulare l’Apprendimento</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parametri-del-problema">Parametri del Problema</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#esempio-pratico">Esempio Pratico</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modello-di-apprendimento-di-rescorla-wagner">Modello di Apprendimento di Rescorla-Wagner</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#la-regola-di-apprendimento-delta-rule">La Regola di Apprendimento (<span class="math notranslate nohighlight">\(\delta\)</span>-rule)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#softmax-la-regola-decisionale">Softmax: La Regola Decisionale</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#esempio-di-calcolo-della-softmax">Esempio di Calcolo della Softmax</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#variazione-di-theta-con-valori-fissi-di-q">Variazione di <span class="math notranslate nohighlight">\(\theta\)</span> con Valori Fissi di <span class="math notranslate nohighlight">\(Q\)</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulazione-del-modello-di-rescorla-wagner">Simulazione del Modello di Rescorla-Wagner</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adattamento-del-modello">Adattamento del Modello</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#la-massima-verosimiglianza">La Massima Verosimiglianza</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#calcolo-del-logaritmo-della-verosimiglianza">Calcolo del Logaritmo della Verosimiglianza</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#minimizzazione-del-logaritmo-negativo-della-verosimiglianza">Minimizzazione del Logaritmo Negativo della Verosimiglianza</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Esempio Pratico</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#validazione">Validazione</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stima-con-stan">Stima con Stan</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sezione-data">Sezione <code class="docutils literal notranslate"><span class="pre">data</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sezione-transformed-data">Sezione <code class="docutils literal notranslate"><span class="pre">transformed</span> <span class="pre">data</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sezione-parameters">Sezione <code class="docutils literal notranslate"><span class="pre">parameters</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sezione-model">Sezione <code class="docutils literal notranslate"><span class="pre">model</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#priori">Priori</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ciclo-sui-tentativi">Ciclo sui Tentativi</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inferenza">Inferenza</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretazione-delle-stime-dei-parametri">Interpretazione delle Stime dei Parametri</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#informazioni-sull-ambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
Di Corrado Caudek
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>