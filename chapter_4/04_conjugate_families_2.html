
<!DOCTYPE html>


<html lang="it" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Distribuzioni coniugate (2) &#8212; ds4p</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css?v=ca93fcec" />
    <link rel="stylesheet" type="text/css" href="../_static/exercise.css?v=20b57f81" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=3ee479438cf8b5e0d341"></script>

    <script src="../_static/documentation_options.js?v=8d586cc4"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="../_static/translations.js?v=0173e136"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-TP2WLBPMS6"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-TP2WLBPMS6');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-TP2WLBPMS6');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter_4/04_conjugate_families_2';</script>
    <link rel="canonical" href="https://ccaudek.github.io/ds4p/chapter_4/04_conjugate_families_2.html" />
    <link rel="icon" href="../_static/increasing.png"/>
    <link rel="index" title="Indice" href="../genindex.html" />
    <link rel="search" title="Cerca" href="../search.html" />
    <link rel="next" title="Sintesi a posteriori" href="05_summary_posterior.html" />
    <link rel="prev" title="✏️ Esercizi" href="E_conjugate_families_1.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="it"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="ds4p - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="ds4p - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Cerca" aria-label="Cerca" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Cerca</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Benvenuti
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_1/introduction_chapter_1.html">Python</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/00_prelims.html">Preliminari</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/01_python_1.html">Python (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/02_python_2.html">Python (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_python.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/03_numpy.html">NumPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_numpy.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/04_pandas.html">Pandas (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/05_pandas_aggregate.html">Pandas (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/06_pandas_functions.html">Pandas (3)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_pandas.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/07_matplotlib.html">Matplotlib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/08_seaborn.html">Seaborn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_matplotlib.html">✏️ Esercizi</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_2/introduction_chapter_2.html">Statistica descrittiva</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/00_scientific_method.html">La scienza dei dati e il metodo scientifico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/01_key_notions.html">Concetti chiave</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_key_notions.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/02_measurement.html">La misurazione in psicologia</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_scales.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/03_freq_distr.html">Dati e frequenze</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_sums.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/04_loc_scale.html">Indici di posizione e di scala</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/05_correlation.html">Le relazioni tra variabili</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/06_causality.html">Lo studio delle cause dei fenomeni</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_eda.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_mehr_song_spelke.html">✏️ Esercizi</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_3/introduction_chapter_3.html">Probabilità</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/01_intro_prob.html">Introduzione al calcolo delle probabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/02_conditional_prob.html">Probabilità condizionata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_cond_prob_1.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_cond_prob_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_discrete_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/03_bayes_theorem.html">Il teorema di Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_bayes_theorem.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_bayes_theorem_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/04a_random_var.html">Introduzione alle variabili casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/04b_expval_var.html">Proprietà delle variabili casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_exp_val_variance.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/04c_sampling_distr.html">Stime, stimatori e parametri</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_rv_discrete.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/05_joint_prob.html">Probabilità congiunta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_joint_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_covariance.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/06_density_func.html">La funzione di densità di probabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/07_discr_rv_distr.html">Distribuzioni di v.c. discrete</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_binomial.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/08_cont_rv_distr.html">Distribuzioni di v.c. continue</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_gaussian.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_beta_distr.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/09_likelihood.html">La verosimiglianza</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_likelihood.html">✏️ Esercizi</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="introduction_part_4.html">Inferenza bayesiana</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_intro_bayes.html">Modellazione bayesiana</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_subj_prop.html">Pensare ad una proporzione in termini soggettivi</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_grid_gauss.html">Verosimiglianza Gaussiana: Metodo Basato su Griglia</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_conjugate_families_1.html">Distribuzioni coniugate</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_conjugate_families_1.html">✏️ Esercizi</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Distribuzioni coniugate (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_summary_posterior.html">Sintesi a posteriori</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_conjugate.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="06_balance-prior-post.html">L’influenza della distribuzione a priori</a></li>
<li class="toctree-l2"><a class="reference internal" href="10_metropolis.html">Monte Carlo a Catena di Markov</a></li>
<li class="toctree-l2"><a class="reference internal" href="15_stan_beta_binomial.html">Introduzione a Stan</a></li>

<li class="toctree-l2"><a class="reference internal" href="E_stan_beta_binomial.html">✏️ Esercizio</a></li>
<li class="toctree-l2"><a class="reference internal" href="16_stan_summary_posterior.html">Metodi di sintesi della distribuzione a posteriori</a></li>
<li class="toctree-l2"><a class="reference internal" href="17_stan_diagnostics.html">Diagnostica delle catene markoviane</a></li>
<li class="toctree-l2"><a class="reference internal" href="18_stan_prediction.html">La predizione bayesiana</a></li>

<li class="toctree-l2"><a class="reference internal" href="19_stan_odds_ratio.html">Analisi bayesiana dell’odds-ratio</a></li>
<li class="toctree-l2"><a class="reference internal" href="22_stan_normal_normal.html">Inferenza bayesiana su una media</a></li>
<li class="toctree-l2"><a class="reference internal" href="23_stan_two_groups.html">Confronto tra due gruppi</a></li>
<li class="toctree-l2"><a class="reference internal" href="24_stan_hier_beta_binom.html">Modello gerarchico beta-binomiale con Stan</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_5/introduction_part_5.html">Analisi della regressione</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_03_reglin_bayesian.html">Analisi bayesiana del modello di regressione lineare bivariato</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_1.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_04_synt_sugar.html">Zucchero sintattico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_05_two_means.html">Confronto tra le medie di due gruppi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_3.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_4.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_06_hier_regr.html">Il modello lineare gerarchico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_07_robust_regr.html">Regressione robusta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_08_specification_error.html">Errore di specificazione</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_09_causal_inference.html">Inferenza causale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_causal_inference.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_22_stan_logistic_regr.html">Regressione logistica con Stan</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_24_stan_mixed_models.html">Modelli misti con Stan</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_25_stan_rct.html">Incorporare dati storici di controllo in una RCT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_26_stan_mediation.html">Modello di mediazione con Stan</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_30_entropy.html">Entropia</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_31_kl.html">La divergenza di Kullback-Leibler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_kl.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_32_stan_loo.html">Validazione Incrociata Leave-One-Out</a></li>

<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_35_missing.html">Dati mancanti</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_40_rescorla_wagner.html">Apprendimento per rinforzo</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_6/introduction_part_6.html">Inferenza frequentista</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/01_intro_frequentist.html">Introduzione all’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_estimation.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/02_conf_interv.html">Intervallo di confidenza</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_conf_interv.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/03_test_ipotesi.html">Significatività statistica</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_t_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_interpretation_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_significato_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/04_two_ind_samples.html">Test t di Student per campioni indipendenti</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_test_media_pop.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_medie_pop_ampie.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_medie_pop_piccoli.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_campioni_appaiati.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_confronto_proporzioni.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/05_crisis.html">La crisi della generalizzabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/06_limiti_stat_frequentista.html">Limiti dell’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/07_effect_size.html">La grandezza dell’effetto</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/09_s_m_errors.html">Crisi della replicabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/10_integrity.html">Integrità della ricerca</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../references/bibliography.html">Bibliografia</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_7/introduction_appendix.html">Appendici</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a00_installation.html">Ambiente di lavoro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a01_markdown.html">Jupyter Notebook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a02_shell.html">La Shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a03_colab_tutorial.html">Colab: un breve tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a04_virtual_env.html">Ambienti virtuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a10_math_symbols.html">Simbologia di base</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a11_numbers.html">Numeri binari, interi, razionali, irrazionali e reali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a12_sum_notation.html">Simbolo di somma (sommatorie)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a13_sets.html">Insiemi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a13a_probability.html">Sigma algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a14_combinatorics.html">Calcolo combinatorio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a15_calculus.html">Per liberarvi dai terrori preliminari</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a20_kde_plot.html">Kernel Density Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a30_prob_tutorial.html">Esercizi di probabilità discreta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a40_rng.html">Generazione di numeri casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a44_montecarlo.html">Simulazione Monte Carlo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a45_mcmc.html">Catene di Markov</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a46_stan.html">Linguaggio Stan</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a50_lin_fun.html">La funzione lineare</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a50_reglin_ml.html">Modello di Regressione Bivariato e ML</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a51_reglin_1.html">Regressione lineare bivariata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a60_ttest_exercises.html">Esercizi sull’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a70_predict_counts.html">La predizione delle frequenze</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/ccaudek/ds4p/blob/main/docs/chapter_4/04_conjugate_families_2.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Scarica questa pagina">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapter_4/04_conjugate_families_2.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Scarica il file sorgente"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Stampa in PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Modalità schermo intero"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Cerca" aria-label="Cerca" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Distribuzioni coniugate (2)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contenuti </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparazione-del-notebook">Preparazione del Notebook</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perche-usare-la-distribuzione-normale">Perché Usare la Distribuzione Normale?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota">Distribuzione a Posteriori in un Contesto Normale con Varianza Nota</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#distribuzione-a-priori">Distribuzione a Priori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#funzione-di-verosimiglianza">Funzione di Verosimiglianza</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#teorema-di-bayes-e-distribuzione-a-posteriori">Teorema di Bayes e Distribuzione a Posteriori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#formula-per-la-media-a-posteriori-mu-p">Formula per la Media a Posteriori (<span class="math notranslate nohighlight">\(\mu_p\)</span>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#formula-per-la-varianza-a-posteriori-sigma-p-2">Formula per la Varianza a Posteriori (<span class="math notranslate nohighlight">\(\sigma_p^2\)</span>)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#un-esempio-concreto">Un esempio concreto</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#commenti-e-considerazioni-finali">Commenti e considerazioni finali</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#informazioni-sull-ambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="distribuzioni-coniugate-2">
<span id="distr-coniugate-2-notebook"></span><h1>Distribuzioni coniugate (2)<a class="headerlink" href="#distribuzioni-coniugate-2" title="Link to this heading">#</a></h1>
<p>La statistica bayesiana ci permette di aggiornare le nostre credenze iniziali o conoscenze a priori sulla distribuzione di un parametro (in questo caso, la media della popolazione) in base ai dati osservati. Questo processo di aggiornamento ci porta a ottenere una distribuzione a posteriori che riflette una nuova comprensione del parametro, integrata con le informazioni fornite dal campione.</p>
<p>Il concetto fondamentale è che, attraverso l’aggiornamento bayesiano, l’incertezza sulla stima del parametro si riduce. Questo è dovuto al fatto che l’informazione aggiuntiva fornita dai dati osservati consente di «restringere» la distribuzione a posteriori rispetto alla distribuzione a priori, riducendo così la varianza (o deviazione standard) della distribuzione del parametro di interesse.</p>
<p>In questo capitolo, approfondiremo il tema delle <a class="reference internal" href="03_conjugate_families_1.html#distr-coniugate-1-notebook"><span class="std std-ref">Distribuzioni coniugate</span></a>, focalizzandoci sul modello normale-normale. Una caratteristica distintiva di questo modello è la sua capacità di auto-coniugazione rispetto a una funzione di verosimiglianza gaussiana. In termini più semplici, se la funzione di verosimiglianza segue una distribuzione gaussiana, l’adozione di una distribuzione a priori gaussiana per la media garantisce che anche la distribuzione a posteriori mantenga la sua forma gaussiana.</p>
<section id="preparazione-del-notebook">
<h2>Preparazione del Notebook<a class="headerlink" href="#preparazione-del-notebook" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="nn">az</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># set seed to make the results fully reproducible</span>
<span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">ord</span><span class="p">,</span> <span class="s2">&quot;distribuzioni_coniugate_1&quot;</span><span class="p">))</span>
<span class="n">rng</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

<span class="n">az</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;arviz-darkgrid&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;figure.dpi&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;figure.facecolor&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;white&quot;</span>

<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &quot;retina&quot;
</pre></div>
</div>
</div>
</div>
</section>
<section id="perche-usare-la-distribuzione-normale">
<h2>Perché Usare la Distribuzione Normale?<a class="headerlink" href="#perche-usare-la-distribuzione-normale" title="Link to this heading">#</a></h2>
<p>Spesso, quando la distribuzione a posteriori è nota per essere unimodale e simmetrica, possiamo modellarla efficacemente con una distribuzione normale, anche se sappiamo che la sua forma è solo approssimativamente normale. Nei casi in cui il ricercatore abbia un’idea approssimativa di dove sia centrato un parametro sconosciuto, la distribuzione normale fornisce un metodo utile per modellare questa stima, permettendo di descrivere il livello di incertezza tramite il termine di varianza della distribuzione normale. Questa convenienza può offrire buone approssimazioni alla densità a posteriori desiderata, con la consapevolezza che, con l’aumentare dei dati osservati, tali assunzioni perdono di importanza.</p>
<p>Come dimostrato di seguito, il modello normale bayesiano possiede proprietà frequentiste desiderabili. Sebbene l’enfasi nell’analisi bayesiana non sia sulle stime puntuali, si può dimostrare che, con campioni sempre più grandi, la media della distribuzione a posteriori bayesiana si avvicina alla stima di massima verosimiglianza. Questa proprietà esiste perché la distribuzione a posteriori è un compromesso ponderato tra la distribuzione a priori specificata dall’utente, che in questo capitolo è normale, e la funzione di verosimiglianza derivata dai dati, anch’essa normale in questo capitolo. Con l’aumentare delle dimensioni del campione, la verosimiglianza diventa sempre più dominante in questa ponderazione.</p>
<p>Nel caso di una media normale, illustrato qui, la varianza della distribuzione di campionamento frequentista diminuisce con l’aumento della dimensione del campione. Nel contesto bayesiano, la riduzione della varianza media dalla funzione di verosimiglianza alla fine prevale anche su una varianza a priori deliberatamente grande. Pertanto, se si prevede che la dimensione del dataset sia grande, i ricercatori possono permettersi di essere liberali nella specificazione della varianza a priori.</p>
<section id="distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota">
<h3>Distribuzione a Posteriori in un Contesto Normale con Varianza Nota<a class="headerlink" href="#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota" title="Link to this heading">#</a></h3>
<p>Consideriamo un insieme di dati <span class="math notranslate nohighlight">\( y = [y_1, y_2, \ldots, y_n] \)</span>, composto da <span class="math notranslate nohighlight">\( n \)</span> osservazioni indipendenti e identicamente distribuite (i.i.d.) secondo una distribuzione normale <span class="math notranslate nohighlight">\(\mathcal{N}(\mu, \sigma^2)\)</span>. In questo scenario, il nostro obiettivo è stimare il valore del parametro <span class="math notranslate nohighlight">\(\mu\)</span>, che rappresenta la media della popolazione da cui provengono i dati.</p>
</section>
<section id="distribuzione-a-priori">
<h3>Distribuzione a Priori<a class="headerlink" href="#distribuzione-a-priori" title="Link to this heading">#</a></h3>
<p>Nell’approccio bayesiano, assumiamo una conoscenza iniziale sul parametro <span class="math notranslate nohighlight">\(\mu\)</span> mediante una distribuzione a priori. In questo caso, utilizziamo una distribuzione normale coniugata, ovvero una distribuzione normale con media <span class="math notranslate nohighlight">\(\mu_0\)</span> e varianza <span class="math notranslate nohighlight">\(\sigma_0^2\)</span>. Questa scelta riflette la nostra incertezza iniziale su <span class="math notranslate nohighlight">\(\mu\)</span>.</p>
</section>
<section id="funzione-di-verosimiglianza">
<h3>Funzione di Verosimiglianza<a class="headerlink" href="#funzione-di-verosimiglianza" title="Link to this heading">#</a></h3>
<p>La funzione di verosimiglianza, denotata da <span class="math notranslate nohighlight">\(p(y | \mu, \sigma)\)</span>, rappresenta la probabilità di osservare i dati <span class="math notranslate nohighlight">\(y\)</span> dato il valore del parametro <span class="math notranslate nohighlight">\(\mu\)</span> e la varianza nota <span class="math notranslate nohighlight">\(\sigma^2\)</span>. Per una distribuzione normale i.i.d., la funzione di verosimiglianza è data da:</p>
<div class="math notranslate nohighlight">
\[
p(y | \mu, \sigma) = \prod_{i=1}^n \frac{1}{\sigma \sqrt{2\pi}} \exp\left(-\frac{(y_i - \mu)^2}{2\sigma^2}\right).
\]</div>
</section>
<section id="teorema-di-bayes-e-distribuzione-a-posteriori">
<h3>Teorema di Bayes e Distribuzione a Posteriori<a class="headerlink" href="#teorema-di-bayes-e-distribuzione-a-posteriori" title="Link to this heading">#</a></h3>
<p>Il teorema di Bayes combina la distribuzione a priori con la funzione di verosimiglianza per ottenere la distribuzione a posteriori del parametro <span class="math notranslate nohighlight">\(\mu\)</span>, data l’evidenza osservata <span class="math notranslate nohighlight">\(y\)</span>:</p>
<div class="math notranslate nohighlight">
\[
p(\mu | y) = \frac{ p(y | \mu) p(\mu) }{ p(y) }.
\]</div>
<p>Poiché la distribuzione a priori e la funzione di verosimiglianza sono entrambe distribuzioni normali, la distribuzione a posteriori risulterà anch’essa una distribuzione normale con media a posteriori <span class="math notranslate nohighlight">\(\mu_p\)</span> e varianza a posteriori <span class="math notranslate nohighlight">\(\sigma_p^2\)</span>.</p>
</section>
<section id="formula-per-la-media-a-posteriori-mu-p">
<h3>Formula per la Media a Posteriori (<span class="math notranslate nohighlight">\(\mu_p\)</span>)<a class="headerlink" href="#formula-per-la-media-a-posteriori-mu-p" title="Link to this heading">#</a></h3>
<p>La media a posteriori <span class="math notranslate nohighlight">\(\mu_p\)</span> rappresenta la stima aggiornata del parametro <span class="math notranslate nohighlight">\(\mu\)</span> alla luce delle informazioni contenute nei dati osservati. La sua formula è:</p>
<div class="math notranslate nohighlight">
\[
\mu_p = \frac{\frac{1}{\sigma_0^2} \mu_0 + \frac{n}{\sigma^2} \bar{y}}{\frac{1}{\sigma_0^2} + \frac{n}{\sigma^2}},
\]</div>
<p>dove <span class="math notranslate nohighlight">\(\bar{y}\)</span> rappresenta la media campionaria:</p>
<div class="math notranslate nohighlight">
\[
\bar{y} = \frac{\sum_{i=1}^n y_i}{n}.
\]</div>
<p>Osserviamo che <span class="math notranslate nohighlight">\(\mu_p\)</span> è una combinazione ponderata tra la media a priori <span class="math notranslate nohighlight">\(\mu_0\)</span> e la media campionaria <span class="math notranslate nohighlight">\(\bar{y}\)</span>. Il peso di <span class="math notranslate nohighlight">\(\bar{y}\)</span> aumenta con il numero di osservazioni <span class="math notranslate nohighlight">\(n\)</span>, mentre il peso di <span class="math notranslate nohighlight">\(\mu_0\)</span> diminuisce. Questo riflette il fatto che con più dati, la nostra fiducia nella media campionaria cresce, mentre l’incertezza a priori diminuisce.</p>
</section>
<section id="formula-per-la-varianza-a-posteriori-sigma-p-2">
<h3>Formula per la Varianza a Posteriori (<span class="math notranslate nohighlight">\(\sigma_p^2\)</span>)<a class="headerlink" href="#formula-per-la-varianza-a-posteriori-sigma-p-2" title="Link to this heading">#</a></h3>
<p>La varianza a posteriori <span class="math notranslate nohighlight">\(\sigma_p^2\)</span> rappresenta l’incertezza residua sulla stima del parametro <span class="math notranslate nohighlight">\(\mu\)</span> dopo aver incorporato le informazioni dai dati. La sua formula è:</p>
<div class="math notranslate nohighlight">
\[
\sigma_p^2 = \frac{1}{\frac{1}{\sigma_0^2} + \frac{n}{\sigma^2}}.
\]</div>
<p>Rispetto alla varianza a priori <span class="math notranslate nohighlight">\(\sigma_0^2\)</span>, la varianza a posteriori <span class="math notranslate nohighlight">\(\sigma_p^2\)</span> è sempre inferiore o uguale. In altre parole, l’incertezza sulla stima di <span class="math notranslate nohighlight">\(\mu\)</span> si riduce con l’aumentare del numero di osservazioni. La varianza a posteriori rappresenta un bilanciamento tra l’incertezza a priori (<span class="math notranslate nohighlight">\(\sigma_0^2\)</span>) e l’informazione derivata dai dati (<span class="math notranslate nohighlight">\(\sigma^2/n\)</span>).</p>
<p>In sintesi, nel caso normale-normale con varianza nota, la distribuzione a posteriori risulta essere una distribuzione normale con una media e una varianza che riflettono un’integrazione bilanciata tra l’informazione a priori e quella ottenuta dai dati osservati. Questo approccio garantisce una stima aggiornata e affinata del parametro <span class="math notranslate nohighlight">\(\mu\)</span> che migliora con l’aumento del numero di osservazioni.</p>
</section>
</section>
<section id="un-esempio-concreto">
<h2>Un esempio concreto<a class="headerlink" href="#un-esempio-concreto" title="Link to this heading">#</a></h2>
<p>I test standard di QI sono progettati per misurare l’intelligenza con una media di 100 e una deviazione standard di 15. Tuttavia, si dice anche che questi test presentino bias culturali che favoriscono alcuni gruppi rispetto ad altri. Un’ulteriore complicazione si verifica quando i punteggi di QI vengono aggregati a livello nazionale, poiché le caratteristiche interne ai paesi vengono mascherate. Questo esempio analizza i dati di QI raccolti a livello internazionale (Lynn e Vanhanen, 2001) per 80 paesi da fonti nazionali pubblicate e discussi da <span id="id1">Gill [<a class="reference internal" href="../references/bibliography.html#id3" title="Jeff Gill. Bayesian methods: A social and behavioral sciences approach. Chapman and Hall/CRC, 3rd edition edition, 2015.">Gil15</a>]</span>. L’idea chiave nella descrizione della distribuzione a posteriori è se le differenze tra le nazioni alterano la parametrizzazione prevista.</p>
<p>I dati di Lynn e Vanhanen (2001) sono forniti di seguito:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Paese</p></th>
<th class="head"><p>IQ</p></th>
<th class="head"><p>Paese</p></th>
<th class="head"><p>IQ</p></th>
<th class="head"><p>Paese</p></th>
<th class="head"><p>IQ</p></th>
<th class="head"><p>Paese</p></th>
<th class="head"><p>IQ</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Argentina</p></td>
<td><p>96</p></td>
<td><p>Australia</p></td>
<td><p>98</p></td>
<td><p>Austria</p></td>
<td><p>102</p></td>
<td><p>Barbados</p></td>
<td><p>78</p></td>
</tr>
<tr class="row-odd"><td><p>Belgium</p></td>
<td><p>100</p></td>
<td><p>Brazil</p></td>
<td><p>87</p></td>
<td><p>Bulgaria</p></td>
<td><p>93</p></td>
<td><p>Canada</p></td>
<td><p>97</p></td>
</tr>
<tr class="row-even"><td><p>China</p></td>
<td><p>100</p></td>
<td><p>Congo (Br.)</p></td>
<td><p>73</p></td>
<td><p>Congo (Zr.)</p></td>
<td><p>65</p></td>
<td><p>Croatia</p></td>
<td><p>90</p></td>
</tr>
<tr class="row-odd"><td><p>Cuba</p></td>
<td><p>85</p></td>
<td><p>Czech Repub.</p></td>
<td><p>97</p></td>
<td><p>Denmark</p></td>
<td><p>98</p></td>
<td><p>Ecuador</p></td>
<td><p>80</p></td>
</tr>
<tr class="row-even"><td><p>Egypt</p></td>
<td><p>83</p></td>
<td><p>Eq. Guinea</p></td>
<td><p>59</p></td>
<td><p>Ethiopia</p></td>
<td><p>63</p></td>
<td><p>Fiji</p></td>
<td><p>84</p></td>
</tr>
<tr class="row-odd"><td><p>Finland</p></td>
<td><p>97</p></td>
<td><p>France</p></td>
<td><p>98</p></td>
<td><p>Germany</p></td>
<td><p>102</p></td>
<td><p>Ghana</p></td>
<td><p>71</p></td>
</tr>
<tr class="row-even"><td><p>Greece</p></td>
<td><p>92</p></td>
<td><p>Guatemala</p></td>
<td><p>79</p></td>
<td><p>Guinea</p></td>
<td><p>66</p></td>
<td><p>Hong Kong</p></td>
<td><p>107</p></td>
</tr>
<tr class="row-odd"><td><p>Hungary</p></td>
<td><p>99</p></td>
<td><p>India</p></td>
<td><p>81</p></td>
<td><p>Indonesia</p></td>
<td><p>89</p></td>
<td><p>Iran</p></td>
<td><p>84</p></td>
</tr>
<tr class="row-even"><td><p>Iraq</p></td>
<td><p>87</p></td>
<td><p>Ireland</p></td>
<td><p>93</p></td>
<td><p>Israel</p></td>
<td><p>94</p></td>
<td><p>Italy</p></td>
<td><p>102</p></td>
</tr>
<tr class="row-odd"><td><p>Jamaica</p></td>
<td><p>72</p></td>
<td><p>Japan</p></td>
<td><p>105</p></td>
<td><p>Kenya</p></td>
<td><p>72</p></td>
<td><p>Korea (S.)</p></td>
<td><p>106</p></td>
</tr>
<tr class="row-even"><td><p>Lebanon</p></td>
<td><p>86</p></td>
<td><p>Malaysia</p></td>
<td><p>92</p></td>
<td><p>Marshall I.</p></td>
<td><p>84</p></td>
<td><p>Mexico</p></td>
<td><p>87</p></td>
</tr>
<tr class="row-odd"><td><p>Morocco</p></td>
<td><p>85</p></td>
<td><p>Nepal</p></td>
<td><p>78</p></td>
<td><p>Netherlands</p></td>
<td><p>102</p></td>
<td><p>New Zealand</p></td>
<td><p>100</p></td>
</tr>
<tr class="row-even"><td><p>Nigeria</p></td>
<td><p>67</p></td>
<td><p>Norway</p></td>
<td><p>98</p></td>
<td><p>Peru</p></td>
<td><p>90</p></td>
<td><p>Philippines</p></td>
<td><p>86</p></td>
</tr>
<tr class="row-odd"><td><p>Poland</p></td>
<td><p>99</p></td>
<td><p>Portugal</p></td>
<td><p>95</p></td>
<td><p>Puerto Rico</p></td>
<td><p>84</p></td>
<td><p>Qatar</p></td>
<td><p>78</p></td>
</tr>
<tr class="row-even"><td><p>Romania</p></td>
<td><p>94</p></td>
<td><p>Russia</p></td>
<td><p>96</p></td>
<td><p>Samoa</p></td>
<td><p>87</p></td>
<td><p>Sierra Leone</p></td>
<td><p>64</p></td>
</tr>
<tr class="row-odd"><td><p>Singapore</p></td>
<td><p>103</p></td>
<td><p>Slovakia</p></td>
<td><p>96</p></td>
<td><p>Slovenia</p></td>
<td><p>95</p></td>
<td><p>South Africa</p></td>
<td><p>72</p></td>
</tr>
<tr class="row-even"><td><p>Spain</p></td>
<td><p>97</p></td>
<td><p>Sudan</p></td>
<td><p>72</p></td>
<td><p>Suriname</p></td>
<td><p>89</p></td>
<td><p>Sweden</p></td>
<td><p>101</p></td>
</tr>
<tr class="row-odd"><td><p>Switzerland</p></td>
<td><p>101</p></td>
<td><p>Taiwan</p></td>
<td><p>104</p></td>
<td><p>Tanzania</p></td>
<td><p>72</p></td>
<td><p>Thailand</p></td>
<td><p>91</p></td>
</tr>
<tr class="row-even"><td><p>Tonga</p></td>
<td><p>87</p></td>
<td><p>Turkey</p></td>
<td><p>90</p></td>
<td><p>Uganda</p></td>
<td><p>73</p></td>
<td><p>U.K.</p></td>
<td><p>100</p></td>
</tr>
<tr class="row-odd"><td><p>U.S.</p></td>
<td><p>98</p></td>
<td><p>Uruguay</p></td>
<td><p>96</p></td>
<td><p>Zambia</p></td>
<td><p>77</p></td>
<td><p>Zimbabwe</p></td>
<td><p>66</p></td>
</tr>
</tbody>
</table>
</div>
<p>Implementiamo le informazioni necessarie in Python.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dati IQ delle 80 nazioni</span>
<span class="n">iq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="mi">96</span><span class="p">,</span>
        <span class="mi">100</span><span class="p">,</span>
        <span class="mi">100</span><span class="p">,</span>
        <span class="mi">85</span><span class="p">,</span>
        <span class="mi">83</span><span class="p">,</span>
        <span class="mi">97</span><span class="p">,</span>
        <span class="mi">92</span><span class="p">,</span>
        <span class="mi">99</span><span class="p">,</span>
        <span class="mi">87</span><span class="p">,</span>
        <span class="mi">72</span><span class="p">,</span>
        <span class="mi">86</span><span class="p">,</span>
        <span class="mi">85</span><span class="p">,</span>
        <span class="mi">67</span><span class="p">,</span>
        <span class="mi">99</span><span class="p">,</span>
        <span class="mi">94</span><span class="p">,</span>
        <span class="mi">103</span><span class="p">,</span>
        <span class="mi">97</span><span class="p">,</span>
        <span class="mi">101</span><span class="p">,</span>
        <span class="mi">87</span><span class="p">,</span>
        <span class="mi">98</span><span class="p">,</span>
        <span class="mi">87</span><span class="p">,</span>
        <span class="mi">73</span><span class="p">,</span>
        <span class="mi">97</span><span class="p">,</span>
        <span class="mi">59</span><span class="p">,</span>
        <span class="mi">98</span><span class="p">,</span>
        <span class="mi">79</span><span class="p">,</span>
        <span class="mi">81</span><span class="p">,</span>
        <span class="mi">93</span><span class="p">,</span>
        <span class="mi">105</span><span class="p">,</span>
        <span class="mi">92</span><span class="p">,</span>
        <span class="mi">78</span><span class="p">,</span>
        <span class="mi">98</span><span class="p">,</span>
        <span class="mi">95</span><span class="p">,</span>
        <span class="mi">96</span><span class="p">,</span>
        <span class="mi">72</span><span class="p">,</span>
        <span class="mi">104</span><span class="p">,</span>
        <span class="mi">90</span><span class="p">,</span>
        <span class="mi">96</span><span class="p">,</span>
        <span class="mi">98</span><span class="p">,</span>
        <span class="mi">102</span><span class="p">,</span>
        <span class="mi">78</span><span class="p">,</span>
        <span class="mi">90</span><span class="p">,</span>
        <span class="mi">63</span><span class="p">,</span>
        <span class="mi">84</span><span class="p">,</span>
        <span class="mi">84</span><span class="p">,</span>
        <span class="mi">107</span><span class="p">,</span>
        <span class="mi">86</span><span class="p">,</span>
        <span class="mi">102</span><span class="p">,</span>
        <span class="mi">106</span><span class="p">,</span>
        <span class="mi">94</span><span class="p">,</span>
        <span class="mi">102</span><span class="p">,</span>
        <span class="mi">72</span><span class="p">,</span>
        <span class="mi">101</span><span class="p">,</span>
        <span class="mi">89</span><span class="p">,</span>
        <span class="mi">72</span><span class="p">,</span>
        <span class="mi">101</span><span class="p">,</span>
        <span class="mi">91</span><span class="p">,</span>
        <span class="mi">100</span><span class="p">,</span>
        <span class="mi">100</span><span class="p">,</span>
        <span class="mi">66</span><span class="p">,</span>
        <span class="mi">107</span><span class="p">,</span>
        <span class="mi">86</span><span class="p">,</span>
        <span class="mi">78</span><span class="p">,</span>
        <span class="mi">84</span><span class="p">,</span>
        <span class="mi">78</span><span class="p">,</span>
        <span class="mi">64</span><span class="p">,</span>
        <span class="mi">72</span><span class="p">,</span>
        <span class="mi">101</span><span class="p">,</span>
        <span class="mi">91</span><span class="p">,</span>
        <span class="mi">100</span><span class="p">,</span>
        <span class="mi">67</span><span class="p">,</span>
        <span class="mi">86</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Numero di osservazioni</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">iq</span><span class="p">)</span>

<span class="c1"># Media campionaria</span>
<span class="n">y_bar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">iq</span><span class="p">)</span>

<span class="c1"># Deviazione standard nota</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mi">15</span>

<span class="c1"># Parametri a priori</span>
<span class="n">mu_0</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">sigma_0</span> <span class="o">=</span> <span class="mi">15</span>
</pre></div>
</div>
</div>
</div>
<p>Calcoliamo la media a posteriori con la formula discussa in precedenza</p>
<div class="math notranslate nohighlight">
\[
\mu_p = \frac{\frac{1}{\sigma_0^2}\mu_0 + \frac{n}{\sigma^2}\bar{y}}{\frac {1}{\sigma_0^2} + \frac{n}{\sigma^2}}
\]</div>
<p>dove:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mu_0\)</span> è la media a priori</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma_0\)</span> è la deviazione standard a priori</p></li>
<li><p><span class="math notranslate nohighlight">\(n\)</span> è il numero di osservazioni</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma\)</span> è la deviazione standard delle osservazioni (nota)</p></li>
<li><p><span class="math notranslate nohighlight">\(\bar{y}\)</span> è la media campionaria</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mu_p</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span> <span class="o">/</span> <span class="n">sigma_0</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">mu_0</span> <span class="o">+</span> <span class="p">(</span><span class="n">n</span> <span class="o">/</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">y_bar</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span>
    <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">sigma_0</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">n</span> <span class="o">/</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Media a posteriori (mu_p): </span><span class="si">{</span><span class="n">mu_p</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Media a posteriori (mu_p): 89.35616438356165
</pre></div>
</div>
</div>
</div>
<p>Calcoliamo la varianza a posteriori</p>
<div class="math notranslate nohighlight">
\[
\sigma_p^2 = \frac{1}{\frac {1}{\sigma_0^2}+ \frac{n}{\sigma^2}}
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sigma_p_sq</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">((</span><span class="mi">1</span> <span class="o">/</span> <span class="n">sigma_0</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">n</span> <span class="o">/</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Varianza a posteriori (sigma_p_sq): </span><span class="si">{</span><span class="n">sigma_p_sq</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Varianza a posteriori (sigma_p_sq): 3.082191780821918
</pre></div>
</div>
</div>
</div>
<p>Generiamo una rappresentazione grafica della distribuzione a posteriori della media del IQ sulla base dei dati osservati, avendo assunto <code class="docutils literal notranslate"><span class="pre">mu_0</span></code> = 100 e <code class="docutils literal notranslate"><span class="pre">sigma_0</span></code> = 15 per la distribuzione a priori.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sigma_p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sigma_p_sq</span><span class="p">)</span>

<span class="c1"># Definizione dei valori sull&#39;asse x</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">mu_p</span> <span class="o">-</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">sigma_p</span><span class="p">,</span> <span class="n">mu_p</span> <span class="o">+</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">sigma_p</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># Calcolo della densità di probabilità</span>
<span class="n">pdf</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu_p</span><span class="p">,</span> <span class="n">sigma_p</span><span class="p">)</span>

<span class="c1"># Creazione del grafico</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pdf</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;N(</span><span class="si">{</span><span class="n">mu_p</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">sigma_p</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pdf</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distribuzione a Posteriori&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Media del Quoziente di Intelligenza&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Densità di probabilità&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/d159c1d359dd50040b872de59da6f1ed1be382135632f89ae3ec1610de83c290.png"><img alt="../_images/d159c1d359dd50040b872de59da6f1ed1be382135632f89ae3ec1610de83c290.png" src="../_images/d159c1d359dd50040b872de59da6f1ed1be382135632f89ae3ec1610de83c290.png" style="width: 731px; height: 491px;" /></a>
</div>
</div>
<p>L’analisi condotta mediante un modello bayesiano basato sulla distribuzione normale ha prodotto un risultato interessante: la media stimata della distribuzione a posteriori del QI si attesta a 89.36, un valore sensibilmente inferiore ai 100 punti previsti come media standard.</p>
<p>Tuttavia, per un’interpretazione completa di questo dato, è fondamentale adottare un approccio critico che consideri alcuni aspetti cruciali:</p>
<ul class="simple">
<li><p>La media a posteriori è ottenuta aggregando i dati QI di 80 nazioni diverse. Questo processo può innescare un <strong>effetto di aggregazione</strong>, dove la media «smussata» risultante non rispecchia accuratamente la distribuzione del QI a livello individuale in ogni singola nazione. Di conseguenza, le differenze tra le nazioni in termini di QI medio e variabilità potrebbero essere mascherate da questa media aggregata.</p></li>
<li><p>È importante sottolineare che la media a posteriori viene calcolata utilizzando dati <strong>non ponderati</strong> per ogni nazione. Ciò significa che nazioni con popolazioni più piccole, anche se con punteggi QI mediamente più alti o più bassi, hanno lo stesso impatto sulla media aggregata rispetto a nazioni con popolazioni più grandi. Questo aspetto potrebbe ulteriormente distorcere la rappresentazione della vera distribuzione globale del QI.</p></li>
<li><p>La deviazione osservata dalla media standard di 100 potrebbe non riflettere esclusivamente differenze nell’intelligenza media tra le nazioni, ma anche <strong>differenze nei contesti sanitari, sociologici e politici</strong> in cui i test sono stati somministrati. Fattori quali l’accesso all’istruzione, la qualità della nutrizione e l’esposizione a stimoli cognitivi possono influenzare i punteggi QI ottenuti e contribuire alla variabilità osservata tra le nazioni.</p></li>
<li><p>Inoltre, è fondamentale considerare la possibilità di un <strong>bias culturale</strong> intrinseco allo strumento stesso. I test del QI sono stati originariamente progettati per un contesto specifico (paese industrializzato di lingua inglese) e potrebbero non essere adatti o culturalmente sensibili a contesti differenti. Questo potrebbe portare a una sottostima dei punteggi QI in alcune nazioni e influenzare la media a posteriori aggregata.</p></li>
</ul>
<p>Questi risultati evidenziano l’importanza di un’attenta considerazione dei fattori metodologici quando si interpretano dati di test del QI a livello trans-culturale. L’effetto di aggregazione, l’utilizzo di medie non ponderate, le differenze nei contesti e il potenziale bias culturale richiedono un’analisi più approfondita che consideri questi fattori e utilizzi metodi statistici più sofisticati per ottenere una comprensione più completa delle differenze nel QI tra le nazioni.</p>
</section>
<section id="commenti-e-considerazioni-finali">
<h2>Commenti e considerazioni finali<a class="headerlink" href="#commenti-e-considerazioni-finali" title="Link to this heading">#</a></h2>
<p>In questa sezione, abbiamo approfondito il meccanismo dell’aggiornamento bayesiano attraverso l’implementazione del modello normale-normale.</p>
<p>Il processo inizia definendo una distribuzione a priori per <span class="math notranslate nohighlight">\( \mu \)</span>, specificata da una media <span class="math notranslate nohighlight">\( \mu_0 \)</span> e una varianza <span class="math notranslate nohighlight">\( \sigma_0^2 \)</span>. Dopo l’acquisizione di nuovi dati, ipotizzando che seguano una distribuzione Normale con media campionaria <span class="math notranslate nohighlight">\( \bar{y} \)</span> e varianza nota <span class="math notranslate nohighlight">\( \sigma^2 \)</span>, implementiamo il teorema normale-normale per derivare la distribuzione a posteriori del parametro.</p>
<p>La media della distribuzione a posteriori, denotata come <span class="math notranslate nohighlight">\( \mu_{\text{post}} \)</span>, si configura come una media ponderata tra la media a priori <span class="math notranslate nohighlight">\( \mu_0 \)</span> e la media campionaria <span class="math notranslate nohighlight">\( \bar{y} \)</span>, dove il peso assegnato a ciascuna media è determinato dalle rispettive varianze <span class="math notranslate nohighlight">\( \sigma_0^2 \)</span> e <span class="math notranslate nohighlight">\( \sigma^2 \)</span> della distribuzione a priori e dei dati osservati. Analogamente, la varianza a posteriori <span class="math notranslate nohighlight">\( \sigma_{\text{post}}^2 \)</span> è determinata utilizzando un’espressione che incorpora entrambe le varianze.</p>
<p>In sintesi, l’adozione del modello normale-normale in un contesto bayesiano facilita il calcolo delle distribuzioni a posteriori, grazie alla scelta di una distribuzione a priori Normale che mantiene la proprietà di coniugatezza, semplificando così l’intero processo analitico.</p>
</section>
<section id="informazioni-sull-ambiente-di-sviluppo">
<h2>Informazioni sull’Ambiente di Sviluppo<a class="headerlink" href="#informazioni-sull-ambiente-di-sviluppo" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> watermark
<span class="o">%</span><span class="k">watermark</span> -n -u -v -iv -w -m
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Last updated: Thu Jul 04 2024

Python implementation: CPython
Python version       : 3.12.3
IPython version      : 8.25.0

Compiler    : Clang 16.0.6 
OS          : Darwin
Release     : 23.5.0
Machine     : arm64
Processor   : arm
CPU cores   : 8
Architecture: 64bit

numpy     : 1.26.4
scipy     : 1.13.1
matplotlib: 3.8.4
arviz     : 0.18.0

Watermark: 2.4.3
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter_4"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="E_conjugate_families_1.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">precedente</p>
        <p class="prev-next-title">✏️ Esercizi</p>
      </div>
    </a>
    <a class="right-next"
       href="05_summary_posterior.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">successivo</p>
        <p class="prev-next-title">Sintesi a posteriori</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contenuti
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparazione-del-notebook">Preparazione del Notebook</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perche-usare-la-distribuzione-normale">Perché Usare la Distribuzione Normale?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota">Distribuzione a Posteriori in un Contesto Normale con Varianza Nota</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#distribuzione-a-priori">Distribuzione a Priori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#funzione-di-verosimiglianza">Funzione di Verosimiglianza</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#teorema-di-bayes-e-distribuzione-a-posteriori">Teorema di Bayes e Distribuzione a Posteriori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#formula-per-la-media-a-posteriori-mu-p">Formula per la Media a Posteriori (<span class="math notranslate nohighlight">\(\mu_p\)</span>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#formula-per-la-varianza-a-posteriori-sigma-p-2">Formula per la Varianza a Posteriori (<span class="math notranslate nohighlight">\(\sigma_p^2\)</span>)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#un-esempio-concreto">Un esempio concreto</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#commenti-e-considerazioni-finali">Commenti e considerazioni finali</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#informazioni-sull-ambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
Di Corrado Caudek
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>